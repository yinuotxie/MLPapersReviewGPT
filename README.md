# Machine Learning Paper Reviews GPT
![pipeline](assets/pipeline.png)

## Description
This project, developed as a final project for the [UPenn CIS6200 Advanced Topics in Deep Learning](https://docs.google.com/document/d/1dkQ4XRhaiZFjGu5i_8Qcoi6MkHwOfivmFFWhBrBF30I/edit), aims to investigate the use of large language models (LLMs) for generating machine learning paper reviews. It is inspired by the study ["Can large language models provide useful feedback on research papers? A large-scale empirical analysis"](https://arxiv.org/pdf/2310.01783.pdf) and utilizes similar techniques. For more details, please see our [project report](report.pdf).

## Methods
### Baselines
We employed GPT-3.5-turbo and GPT-4-turbo as baseline models for generating reviews of machine learning papers. Additionally, we experimented with one-shot learning using these models to explore different training paradigms.

### Fine-tuning
We also fine-tuned the [Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) model on a custom dataset comprised of papers and their reviews sourced from [OpenReview](https://openreview.net/). To aid in fine-tuning, GPT-4 was used to generate summary reviews. Due to computational constraints, we focused on tuning the models using only the paper abstracts. The dataset is available in the `data` directory and is also published on the Huggingface dataset hub [here](https://huggingface.co/datasets/travis0103/abstract_paper_review). The fine-tuned model is available on the Huggingface model hub [here](https://huggingface.co/travis0103/mistral_7b_paper_review_lora).


## Usage 
The project provides two pipelines for generating reviews:

### Installation
Clone the repository and set up the environment:
```bash
git clone git@github.com:yinuotxie/MLPapersReviewGPT.git
python3 -m venv env
source env/bin/activate
pip install -r requirements.txt
```

Note: The scipdf_parser package, required for PDF text extraction, must run within a Docker container. Instructions are available in the [scipdf_parser repository](https://github.com/titipata/scipdf_parser).

### Model Pipeline
Generate reviews using our fine-tuned model. Currently, only the abstracts of papers are supported:
```bash
python model_review.py 
    --pdf_file <path_to_pdf_file> 
    --device <device> 
    --model_id <model_id> 
    --quantize
```

### GPT Pipeline
Alternatively, use the GPT pipeline to generate reviews:
```bash
python gpt_review.py 
    --pdf_file <path_to_pdf_file> 
    --openai_api_key <your_openai_api_key> 
    --model <gpt-3.5-turbo or gpt-4-turbo> 
    --method <full or abstract> 
    --one_shot
```

You can also check the [`inferece.ipynb`](notebooks/inference.ipynb
) notebook for more details.

## Evaluation
We conducted retrospective evaluations to compare the overlap of comments between GPT-4 vs. Human and Human vs. Human setups. The hit rate, which measures the proportion of matching comments, was controlled by aligning the number of comments from humans to match those generated by GPT-4.

Additionally, we explored the robustness of our results using various overlap metrics such as the Szymkiewicz–Simpson Overlap Coefficient, the Jaccard Index, and the Sørensen–Dice Coefficient. These metrics confirmed that the overlap performance of GPT-4 vs. Human is comparable to Human vs. Human, demonstrating the effectiveness of the model across different datasets and conditions.

Check the [`evaluation.ipynb`](notebooks/evaluation.ipynb) notebook for more details of how the evaluation was conducted.

## Acknowledgements
We extend our deepest gratitude to our professor, [Prof. Lyle Ungar](https://www.cis.upenn.edu/~ungar/), for his invaluable guidance and support throughout the project. We also thank the teaching assistants, Visweswaran Baskaran, Haotong (Victor) Tian, and Royina Karegoudra Jayanth, for their helpful feedback and assistance. 

## References
* [Can large language models provide useful feedback on research papers? A large-scale empirical analysis](https://arxiv.org/pdf/2310.01783.pdf)
* [scipdf_parser](https://github.com/titipata/scipdf_parser)
* [Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)