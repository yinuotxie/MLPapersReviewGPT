{"title": "Planning for Implicit Coordination using FOND", "authors": "Thorsten Engesser; Tim Miller", "pub_date": "", "abstract": "Epistemic Planning can be used to achieve implicit coordination in cooperative multi-agent settings where knowledge and capabilities are distributed between the agents. In these scenarios, agents plan and act on their own without having to agree on a common plan or protocol beforehand. However, epistemic planning is undecidable in general. In this paper, we identify a decidable fragment of epistemic planning that allows for arbitrary initial state uncertainty and nondeterminism, but where actions can never increase the uncertainty of the agents. We show that in this fragment, planning with and without implicit coordination can be reduced to fully observable nondeterministic (FOND) planning and that it shares the same computational complexity. We also provide a small case study, modeling the problem of multi-agent path finding with destination uncertainty in FOND, to show that our compilation approach can be successfully applied in practice.", "sections": [{"heading": "Introduction", "text": "Epistemic planning has gained increasing interest in recent years (Baral et al. 2017). One of the main features of epistemic planning is the support of knowledge goals. For example, epistemic planning is well-suited to model problems in which information is to be confidentially passed between agents. The assumption is usually that there exists an explicit or implicit model about the distributed knowledge of the agents, as well as actions which can change the models.\nHowever, recent work has shown that epistemic planning can also be used to achieve implicit coordination in a setting where multiple agents plan and act for themselves towards a cooperative goal (Engesser et al. 2017). The idea is that the explicit modeling of the agents' knowledge can be exploited as a means to enforce coordination via perspective taking. In particular, by putting themselves into the shoes of the others, agents can account for possible contributions of other agents in their own plans. Bolander et al. (2018) showed under which conditions such plans are guaranteed to be successful. This problem of planning for implicit coordination was originally formalized as a variant of contingent planning in the space of epistemic states (i.e., Kripke models), with actions represented by the action models from Dynamic Epis-temic Logic (van Ditmarsch et al. 2007). The formalization is very similar to the one of Bolander and Andersen (2011), which produces action sequences that can be interpreted as centralized plans. Bolander and Andersen have shown that this type of epistemic planning is undecidable in general. However, some decidable fragments have been identified that rely on restricting the structure of action models and the form of allowed preconditions (Aucher and Bolander 2013;Bolander et al. 2015;Charrier et al. 2016). On the practical side, Kominis and Geffner (2015) and Muise et al. (2015) have identified fragments of epistemic planning that can be solved by compilation to classical planning.\nIn this paper, we define a decidable fragment that captures contingent epistemic planning and that can be compiled to fully-observable nondeterministic (FOND) planning. Our fragment generalizes the fragment of Kominis and Geffner. We then show how our compilation can be extended to capture planning for implicit coordination. The key insight is that we can use nondeterminism to simulate perspective taking and thus account for the imperfect knowledge of the agents.", "n_publication_ref": 10, "n_figure_ref": 0}, {"heading": "Theoretical Background", "text": "We will first recapitulate the DEL planning framework using the conventions of Bolander and Andersen (2011), but including conditional effects in the style of van Benthem et al. (2006). We will then review strong fully-observable nondeterministic planning (Cimatti et al. 2003;Ghallab et al. 2004) as well as planning for implicit coordination (Engesser et al. 2017;Bolander et al. 2018).", "n_publication_ref": 6, "n_figure_ref": 0}, {"heading": "The DEL Planning Framework", "text": "For a fixed set of agents A and a fixed set of atomic propositions P , the epistemic language L KC is given by the BNF\n\u03c6 ::= p | \u00ac\u03c6 | \u03c6 \u2227 \u03c6 | K i \u03c6 | C\u03c6,\nwhere p \u2208 P and i \u2208 A.\nWe read K i \u03c6 as \"agent i knows \u03c6\" and C\u03c6 as \"it is common knowledge between all agents that \u03c6\". The additional connectives \u2228, \u2190, \u2192, \u2194 can be defined as abbreviations, analogously to their definition in propositional logic.\nWe evaluate such formulas over epistemic models. An epistemic model is a tuple M = W, (R i ) i\u2208A , V , where W is a non-empty, finite set of worlds (the domain of M), R i \u2286 W \u00d7 W is an equivalence relation for each agent i \u2208 A (the indistinguishability relation of i), and with V : P \u2192 2 W (the valuation function). We write R * for the transitive closure of i\u2208A R i . The truth of a formula \u03c6 \u2208 L KC in a world w of a model M is then given as follows, where the propositional cases are standard and hence left out:\nM, w |= p iff w \u2208 V (p) M, w |= K i \u03c6 iff M, w |= \u03c6 for all wR i w M, w |= C\u03c6 iff M, w |= \u03c6 for all wR * w\nWe depict epistemic models as graphs where nodes correspond to the worlds in the model and are additionally labeled with the atomic propositions that are true in that particular world. The indistinguishability relations are given as labeled edges between the worlds. For readability, we will omit reflexive edges as well as edges that are implied by transitivity. Consider the following epistemic model:\nM 0 = w 1 : p w 2 :\n1, 2\nIn our example, both agents 1 and 2 do not know whether or not p is true (which is the case in w 1 ) or false (which is the case in w 2 ). Also, it is common knowledge between the two agents that they do not know. We will now define example actions for agent 1, first to sense the value of p and then to announce it to agent 2.\nTo define actions, we use event models. These can change the facts about the world as well as the knowledge of the agents. Analogous to epistemic models, an event model is a tuple E = E, (Q i ) i\u2208A , pre, eff , where E is a non-empty, finite set of events (the domain of E) and R i \u2286 W \u00d7 W is an equivalence relation for each agent i \u2208 A (the indistinguishability relation of i). Instead of a valuation function, we have two functions pre : E \u2192 L KC and eff : E \u2192 (P \u2192 L KC ), assigning a precondition and conditional effects to each event.\nWe depict event models analogously to epistemic models with the difference that nodes now correspond to events, which are additionally labeled with their respective preconditions and effects. Consider the following event model:\nE sense = e 1 : p, {p \u2192 p} e 2 : \u00acp, {p \u2192 p} 2\nAn event model updates an epistemic model by pairing up every world with every applicable event (i.e., of which the precondition is satisfied). Two updated worlds are indistinguishable for an agent if both the original worlds and the events are indistinguishable for that agent. Furthermore, a proposition is true in an updated world if and only if the event's conditional effect concerning that proposition evaluates to true in the original world.\nFor example, E sense consists of two events with preconditions p and \u00acp. For both events, the effect is {p \u2192 p} meaning p will be true if p was true before (from now on, we will omit these trivial effects that preserve the value of an atomic proposition in our depiction of event models). Since the events are distinguishable for agent 1, the agent will, after the execution of the action, be able to distinguish worlds in which p is true from worlds in which p is false.\nFormally, we define the product update M \u2297 E of model M = W, (R i ) i\u2208A , V with respect to an event model E = E, (Q i ) i\u2208A , pre, eff as model W , (R i ) i\u2208A , V where\n\u2022 W = {(w, e) \u2208 W \u00d7 E | M, w |= pre(e)},\n\u2022 R i = {((w, e), (w , e )) \u2208 W \u00d7 W | wR i w , eQ i e },\n\u2022 V (p) = {(w, e) \u2208 W | M, w |= eff(e, p)}.\nIn particular, if we apply E sense in M 0 , we obtain the following epistemic model:\nM 0 \u2297 E sense = (w 1 , e 1 ) : p (w 2 , e 2 ) :\n2\nAs intended, agent 1 knows now whether or not p is true. Note that additionally agent 2 is aware of this. The event model E sense represents semi-private sensing, meaning that even though the result of the sensing will only be known to agent 1, agent 2 will know that the sensing has taken place.\nFor planning, we usually consider pointed models (M, w), i.e., where one world w from the domain of M is designated as the actual world. In contrast, we model epistemic actions as multi-pointed event models (E, E d ) where E d is a subset of the domain of E. This is necessary, since sometimes we want the events to be deliberately chosen by the acting agents and sometimes by the environment. E.g., our semi-private sensing action should be defined as (E sense , {e 1 , e 2 }). Since both events are designated, it can be applied regardless of whether p is true or false. Applied in (M 0 , w 1 ), the action results in the pointed model (M 0 \u2297 E sense , (w 1 , e 1 )) and applied in (M 0 , w 2 ) it results in (M 0 \u2297 E sense , (w 2 , e 2 )). The similar action (E sense , {e 1 }) is only applicable in the case where p is true. It can, e.g., be used to model the action of a third agent semi-privately informing agent 1 that p is true.\nFormally, an epistemic action (E, E d ) is applicable in (M, w) if there is an applicable event e \u2208 E d , meaning that M, w |= pre(e). The application of (E, E d ) in (M, w) then nondeterministically leads to a pointed model (M \u2297 E(w, e)) such that M, w |= pre(e).\nNote that any epistemic state represented by a pointed model (M, w), has infinitely many epistemically equivalent representations (i.e., other pointed models that satisfy the exact same set of formulas). It is a central theorem of modal logic that finite models are epistemically equivalent if and only if they are bisimilar. In the following, when using pointed models as states in a transition system, we think of them as representatives of their whole equivalence class. I.e., we consider two epistemic states (M, w) and (M , w ) as identical if they are epistemically equivalent. And we say two epistemic states (M, w) and (M , w ) are indistinguishable for an agent i if there is a world w in M that is indistinguishable to w for agent i such that (M, w ) and (M , w ) are identical. An initial epistemic state together with a set of epistemic actions thus induces a nondeterministic transition system where all states are epistemically different from each other.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "FOND Planning", "text": "Our definition of FOND planning loosely follows the conventions of Ghallab et al. (2004). In particular, our actions consist of one common precondition and a set of possible effects, from which one will always be chosen nondeterministically. However, since we want to start out with a formalization that is as close as possible to our DEL formalism, we allow arbitrary propositional formulas as action preconditions and goals. We also use conditional effects which we restrict to effect normal form, which is a special case of Rintanens unary conditionality normal form (Rintanen 2003).\nWe define a FOND planning task as a tuple F, I, \u03b3, Act where F is a set of fluents (atomic propositions), I \u2286 F is the initial state, \u03b3 is a propositional goal formula over F and Act is a set of actions. Each action a = pre a , effs a \u2208 Act consists of a propositional formula pre a over F (the precondition) and a set effs a (the conditional effects). Each conditional effect e \u2208 effs a is of the form f \u2208F (\u03c7 e f \u00a3 f ) \u2227 (\u03c7 e \u00acf \u00a3 \u00acf ), where \u03c7 e f and \u03c7 e \u00acf are mutually inconsistent propositional formulas over F (i.e., their conjunction is unsatisfiable). They can be interpreted as \"effect e makes f true under the condition \u03c7 e f and false under the condition \u03c7 e \u00acf \". Such a FOND task induces a finite transition system starting with the initial state I and connecting two states S and S via action a iff S |= pre a and there is an effect e \u2208 effs a such that the conditional effects in e transform S to S . This gives us a trivial compilation from FOND to DEL. I.e., we compile the initial state into an epistemic state with exactly one world w 0 where V (p) = {w 0 } iff p \u2208 I, or \u2205 otherwise. And for each action a \u2208 Act, we construct an epistemic action with one event for each nondeterministic effect e \u2208 effs a , with precondition pre a and effect {f \u2192 \u03c7 e f \u2228 (f \u2227 \u00ac\u03c7 e \u00acf ) | f \u2208 F}. All events are designated and pairwise distinguishable for all agents. The transition system that we get from our compiled DEL state and actions is isomorphic to the FOND transition system and identified states share the same propositional valuation.\nOne solution to FOND planning tasks are strong plans. These are partial functions \u03c0 from states to actions which satisfy the following properties (Cimatti et al. 2003):\n\u2022 For every state s that is reachable via \u03c0 from I, there is some state s that is reachable from s via \u03c0, s.t. s |= \u03b3.\n\u2022 There are no cycles, i.e. states s and s such that s is reachable via \u03c0 from s and s is reachable via \u03c0 from s.\nSince the transition system is finite, following a strong policy always leads to a goal state in finitely many steps. It seems reasonable to assume that the concept of strong policies is also useful for contingent planning over epistemic states.", "n_publication_ref": 3, "n_figure_ref": 0}, {"heading": "Implicit Coordination in DEL", "text": "We define an epistemic planning task as a tuple s 0 , A, \u03c9, \u03b3 where s 0 is an epistemic state (the initial state), A is a finite set of epistemic actions (the action library), \u03c9 : A \u2192 A is a function mapping each action to its owner (the owner function), and \u03b3 \u2208 L KC is the goal formula. E.g., consider the planning task with s 0 = (M 0 , w 1 ), A = {sense, ann p , ann \u00acp } with sense = (E sense , {e 1 , e 2 }), ann p = (E annp , e 1 ) and ann \u00acp = (E ann\u00acp , e 1 ). The actions ann p and ann \u00acp are public announcement actions for agent 1, announcing that p is true, or respectively false. That is, the event models E ann\u00acp and E annp are given as follows:\nE annp = e 1 : p, \u2205 E ann\u00acp = e 1 : \u00acp, \u2205\nWe assume that all actions are owned by agent 1, i.e., \u03c9 = {sense \u2192 1, ann p \u2192 1, ann \u00acp \u2192 1}. The goal is for agent 2 to know whether or not p is true, i.e., \u03b3 = K 2 p \u2228 K 2 \u00acp.\nA strong policy in the sense of Cimatti et al. (2003) would be to just apply the action ann p in s 0 . This is because the action is applicable in (M 0 , w 1 ) and its application would lead to a successor state consisting of only one world (w 1 , e 1 ) in which p (and K 2 p) is true. We argue that from the perspective of the agents (who initially do not know whether p is true or false), this is not a reasonable solution. If we want agent 1 to be able to come up with the plan for himself, we must consider his incomplete knowledge about the situation. Intuitively, a good plan for agent 1 is to first apply the sensing action and then, depending on the sensing result, apply the action ann p or ann q . This plan works for both states (M, w 1 ) and (M, w 2 ), which agent 1 considers possible.\nTo capture this, we have to require uniform policies. A uniform policy is a partial function \u03c0 from epistemic states to sets of epistemic actions, satisfying the following constraints:\n\u2022 Applicability: for each state s, and action a \u2208 \u03c0(s), the action a has to be applicable in state s. \u2022 Uniformity: for each state s, and action a \u2208 \u03c0(s), and states s that are indistinguishable to s for the owner \u03c9(a) of the action, also a \u2208 \u03c0(s ). This definition ensures that the agents can always infer from their own knowledge whether or not and how the policy wants them to act. This also implies that an action is only applicable by an agent, if the agent knows that the action is applicable. Note that because of the uniformity constraint, it is necessary to allow policies to assign multiple actions per state. E.g., sometimes we want a policy to assign an action a of agent 1 to some state s and an action b of agent 2 to some state s . Then by uniformity, if there is a state s that is indistinguishable to s for agent 1 and to s for agent 2, we have to assign both a and b to s .\nWe then say a uniform policy is subjectively strong, if it satisfies the exact properties of strong plans, but based on subjective reachability: A state s is a subjective successor of s given an action a if there is a successor state of s and a that is indistinguishable to s for agent \u03c9(a). I.e., in our example, the subjective successors of (M 0 , w 1 ) and (E sense , {e 1 , e 2 }) are exactly the states (M 0 \u2297 E sense , (w 1 , e 1 )) and (M 0 \u2297 E sense , (w 2 , e 2 )). A state s is then subjectively reachable from s if either s is identical to s or s is subjectively reachable from a subjective successor of s.\nIn particular, a policy \u03c0 that is subjectively strong for an epistemic planning task s 0 , A, \u03c9, \u03b3 guarantees for each subjectively reachable state s and action a \u2208 \u03c0(s), that \u03c0 is also subjectively strong for s, A, \u03c9, \u03b3 , as well as for all planning tasks s , A, \u03c9, \u03b3 with an initial state s that is indistinguishable to s for \u03c9(a).", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "A Decidable Fragment of DEL Planning", "text": "A straight-forward way to obtain a decidable fragment of DEL planning is to ensure that the induced transition system is finite. This can be done by restricting the action set in such a way that the application of a single action can never lead to a state where the number of worlds is greater than in the state in which the action was applied. We achieve this by requiring our event models to be partitioned into disjoint connected components with mutually inconsistent preconditions. This allows us to think of each of the components as a single nondeterministic effect. Consider the following event model:\nE pp = e 1 : p, \u2205 e 2 : \u00acp, \u2205 e 3 : p, \u22052\nFor example, the action (E pp , {e 1 , e 3 }) could model an agent 3 trying to semi-privately announce p to agent 1. However, there is the possibility that the confidentiality of the announcement is compromised and p is thus effectively publicly announced. If we apply this action in\n(M 0 , w 1 ), it re- sults either in (M 0 \u2297 E pp , (w 1 , e 1 )) or (M 0 \u2297 E pp , (w 1 , e 3 ))where\nM 0 \u2297 E pp = (w 1 , e 1 ) : p (w 2 , e 2 ) : (w 1 , e 3 ) : p 2\nFormally, for actions ( E, (Q i ), pre, eff , E d ) from our action set, we require that the domain E can be partitioned into disjoint subsets E 1 , . . . , E k such that (1) for each pair of events e, e \u2208 E j from the same component j \u2208 {1, . . . , k}, the preconditions pre(e) and pre(e ) are mutually inconsistent, and (2) two events e, e \u2208 E are only allowed to be indistinguishable for an arbitrary agent i \u2208 A, i.e. eQ i e , if they belong to the same component, i.e if there exists a j \u2208 {1, . . . k} such that e, e \u2208 E j .\nWe can see that if we apply such an action to an arbitrary epistemic state, due to condition (1), each world will be paired up by maximally one of the events of each component. Furthermore, due to condition (2), two worlds can only be distinguishable for any agent if the events they were generated with are from the same component. Thus the state resulting from an action application will consist of at most k connected components which consist each of less or equally many worlds than the original state. Since we can throw away all components that do not contain the updated designated world, we obtain a state that can be represented by less than or equally many worlds as the original state.\nOur fragment is a generalization of the fragment introduced by Kominis and Geffner (2015), which allows exactly those actions that can be described with only mutually inconsistent preconditions (even between events from different components) and where all actions are thus deterministic.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Compilation to FOND", "text": "In the following we will show how to generate a FOND planning task F, I, \u03b3 * , Act , given an epistemic planning task s 0 , A, \u03c9, \u03b3 from our fragment.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Compilation of Epistemic States", "text": "We use the approach of Kominis and Geffner (2015) to represent epistemic states as classical states. The idea is that we generate fluents directly from the worlds and indistinguishability relation of the initial state s 0 , such that we can use them to encode the valuation functions and indistinguishability relations of arbitrary states reachable from s 0 .\nGiven the initial state s 0 = ( W, (R i ), V , w 0 ), we introduce a fluent p w \u2208 F (read: \"p is true in world w\") for each proposition p \u2208 P and world w \u2208 W . Similarly, we introduce a fluent D {w1,w2} i (read: \"w 1 is distinguishable to w 2 for agent i\") for each agent i \u2208 A and worlds w 1 , w 2 \u2208 W with w 1 R i w 2 . Finally, for each world w \u2208 W , we introduce the fluent w * \u2208 F (read: \"w is the designated world\").\nA propositional state S \u2286 F then represents an epistemic state ( W,\n(R i ), V , w) where (1) w \u2208 V (p) iff p w \u2208 S, (2) w 1 R i w 2 iff D {w1,w2} i\n\u2208 S, and (3) w = w iff w * \u2208 S. For example, if s 0 = (M 0 , w 1 ), we will generate the set of fluents F = {p w1 , p w2 , D\n{w1,w2} 1 , D {w1,w2} 2 , w * 1 , w * 2 }.\nThe initial state s 0 will then be I = {p w1 , w * 1 }.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Compilation of Epistemic Formulas", "text": "To check whether a propositional formula \u03c6 is true in world w of an epistemic state that is represented by a classical state S \u2286 F is simple. We replace the occurrences of each proposition p in \u03c6 by p w and check the resulting formula in S.\nChecking formulas with knowledge operators is slightly more complicated. Kominis and Geffner (2015) use axioms to compile away all knowledge subformulas into derived variables, the values of which can be inferred in polynomial time.\nWe will simply assume that all of this is given and that we can thus compile each epistemic formula to a formula \u03c6 w that evaluates to true in a classical state representing an epistemic state (M, w 0 ) iff M, w |= \u03c6.\nFor evaluating a formula directly in the designated world of a state (e.g., the goal formula), we use \u03c6 * , which we define as ( w\u2208W w * ) \u2227 w\u2208W (w * \u2192 \u03c6 w ).", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Compilation of Epistemic Actions", "text": "We now show how an action a = ( E, (Q i ), pre, eff , E d ) that can be partitioned into distinct components E 1 , . . . , E k accordingly to our fragment, can be compiled into a FOND action pre a , effs a .\nWe know that an action is applicable in a state (M, w) if there is some event e \u2208 E d such that M, w |= pre(e). We directly translate this to pre a = e\u2208E d pre(e) * . We can then translate each of the components of our event model into a different nondeterministic effect, i.e., we get effs a = {eff j | j = 1, ..., n}. These nondeterministic effects can make propositions true or false, as well as make worlds distinguishable or completely inaccessible. We construct each nondeterministic effect eff j as follows:\neff j = eff P + j \u2227 eff P \u2212 j \u2227 eff D+ j \u2227 eff \u00d7 j \u2227 eff \u00d7 \u00d7 j\nFirst, each fluent p w is made true or false accordingly to the effects of the event e \u2208 E j that is applied in w.\neff P + j = w\u2208W\np\u2208P (\u2228 e\u2208Ej (pre(e) w \u2227 eff(e, p) w ) \u00a3 p w ) eff P \u2212 j = w\u2208W p\u2208P (\u2228 e\u2208Ej (pre(e) w \u2227 \u00ac eff(e, p) w ) \u00a3 \u00acp w )\nTwo worlds w and w become distinguishable if the events e and e they were updated with are distinguishable:\neff D+ j = w,w \u2208W i\u2208A,w =w \uf8eb \uf8ec \uf8ec \uf8ec \uf8ed\ne,e \u2208Ej \u00aceQie (pre(e) w \u2227 pre(e ) w ) \u00a3D\n{w,w } i \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f8\nIf in some world w, none of the events from E j are applicable, the world should not have a successor. We simulate this by making w distinguishable from all other worlds.\neff \u00d7 j = w,w \u2208W w =w \u2227 e\u2208Ej \u00ac pre(e) w \u00a3 D {w,w } i\nIf for the designated world w, there is no applicable event in E j , there should not even be a corresponding successor state. We model this by completely removing the designation w * . Thus, while the effect is still applicable, it leads to a state where all formulas \u03c6 * evaluate to false and therefore no actions are applicable and the goal is not satisfied.\neff \u00d7 \u00d7 j = \u2227 e\u2208Ej \u00ac pre(e) w \u00a3 \u00acw *", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Compilation of Policies", "text": "Our compilation guarantees that the nondeterministic outcomes of an action that is applied in a propositional state corresponds exactly to the nondeterministic outcomes of the original epistemic action applied to the original epistemic state. Thus any strong policy for an epistemic planning task automatically corresponds to a strong policy in its FOND compilation. I.e., we can start in the initial state of the FOND compilation and extract a policy by successively applying the actions assigned by the original policy.\nFor the other direction, we can proceed similarly. However, we have to be careful about the fact that the policy can can contain multiple propositional states representing the same epistemic state. E.g., consider the states {p w1 , w * 1 } and {p w2 , w * 2 }. Having equivalent states in a policy is unproblematic, as long as one is never reachable from the other. To obtain a strong policy for the original problem, we can apply the same policy extraction procedure from above but ignore each state if we have seen an equivalent state before.\nIf the policy in our FOND compilation contains equivalent states such that one is reachable from the other, the extraction gets more difficult, as we have to take care of not introducing cycles into our policy. Fortunately, it is easy to argue that if there is no strong policy in the FOND compilation which doesn't include equivalent states that are reachable from each other, there will also be no strong policy that includes them. This is because the transition system looks exactly the same from these states and we do not gain anything from getting from one of the states to the other. This means that if there is a strong policy for the FOND compilation of an epistemic planning task, there also has to exist a strong policy that does not contain epistemically equivalent reachable states. Moreover, if the strong policy in the FOND compilation is optimal (i.e., its tree representation has minimal depth), it is clear that the policy cannot contain equivalent states that are reachable from each other. We thus obtain the following theorem.\nTheorem 1. Let \u03a0 be an epistemic planning task from our fragment. Then there exists a strong policy for \u03a0 if and only if there exists a strong policy for the FOND compilation of \u03a0. Any optimal strong policy for \u03a0 directly corresponds to an optimal strong policy for its compilation and vice versa.\nThe following theorem follows, given the EXPTIMEcompleteness of the plan existence problem for strong planning in FOND (Rintanen 2004).\nTheorem 2. In our epistemic planning fragment, the problem of deciding whether there exists a strong policy for a given planning task is EXPTIME-complete.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Planning for Implicit Coordination", "text": "As explained in our section about planning for implicit coordination, strong policies are not suitable if we want the agents to coordinate implicitly. In this section, we show how to use FOND planning to find subjectively strong plans for epistemic planning tasks from our fragment.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "The Compilation", "text": "We use the same compilation of states and formulas as before. However, we slightly modify the compilation of actions. The idea is to split each action from the action set into two: One auxiliary action for choosing the action that we want to apply in a state and one action that actually applies the effects of the previously selected action. In each choice action, we additionally simulate a perspective shift: We change the designated world nondeterministically to any of the worlds that are indistinguishable for the owner agent of the action. Thus, subjective successors of an action in the original problem are now objective successors.\nThis means that any strong policy in the compilation will correspond to a subjectively strong policy in the original problem. We can extract such a policy by taking all the apply-actions from our policy and and assigning the corresponding actions to the corresponding states in the original planning task.\nTheorem 3. In our epistemic planning fragment, the problem of deciding whether there exists a subjectively strong policy is EXPTIME-complete.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Example: MAPF/DU", "text": "We demonstrate our approach by modeling an instance of multi-agent path finding with destination uncertainty. The problem was first described by Bolander et al. (2018) and more thoroughly analyzed by Nebel et al. (2019). It is a generalization of the multi-agent path finding problem, relaxing the assumption that the agents' goals are commonly known. Instead, we assume that there are pairwise disjoint sets of plausible goal candidates for each agent, which are commonly known. Also, each agent can identify its own goal. As final action, each agent is allowed to announce that he has arrived at its true destination. The joint goal for the agents is that each agent is at his own true goal. Nebel et al. showed that the plan existence problem is PSPACE-complete. The naive algorithm they proposed has a runtime complexity of O(n a 2 +a ) where n is the number of graph vertices and a is the number of agents. Figure 1 shows an example of a MAPF/DU instance with two agents. The goal candidates of the square agent are r and b, and the goal candidates of the circle agent are l and m. One subjectively strong policy is for the square agent to first go to b and to let the circle agent move to l, independently of the actual destinations of the agents. Then, the square agent goes to its true destination (which, depending on the designated world, will be either r or b) and announces success there. Afterwards, the circle agent can go to his true destination (which will be either l or m). Note that after the initial movements of the square agent, the policy has to consider all 4 possible goal combinations. This is because the square agent does not know the actual goal of the circle agent and the circle agent will not know the actual goal of the square agent.\nWe now show how this problem can be modeled in PDDL (McDermott 1998). We will use the types agt for agents, pos for positions, and wld for worlds. We introduce fluents (at ?a ?p) to denote that agent ?a is at position ?p, (adj ?p ?q) to denote that an agent can step from position ?p to position ?q, and (announced ?a) to denote that the agent ?a has already announced success and will not move any longer. Furthermore, we use (goal ?w ?a ?p) to denote that the actual goal of agent ?a in world ?w is position ?p.\nTo denote indistinguishability of two worlds ?w1 and ?w2 for agent ?a, we use the fluent (ind ?a ?w1 ?w2). We mark the designated world ?w using the fluent (des ?w).\nFinally, we use the predicates (next-choose), (next-move ?a ?p1 ?p2) and (next-announce ?a) to enforce the alternation of auxiliary perspectiveshifting actions and actual actions.\nWe now show how to split up the movement actions into the actions choose-move and move. The action (choose-move ?a ?w ?p ?q) simulates a perspec-tive shift to agent ?a by nondeterministically switching to an arbitrary world that is indistinguishable from the designated world for agent ?a. Furthermore, by setting the fluent (next-move ?a ?p ?q) to true, it enforces a movement action for agent ?a from ?p to ?q in the successor state. (and (not (des ?w)) (des w2))) ; ... Unfortunately, we have to enumerate all possible worlds to simulate the perspective shift. This forces us to include the worlds as constants into the domain definition. It would be more convenient if we had a dedicated construct in PDDL to automatically generate nondeterministic effects, e.g., by explicitly quantifying over objects (in our case, worlds).\nThe move action, which has to be applied afterwards, performs the actual change of the agent's position. This action also contains the actual precondition for movement actions: the field to move to has to be adjacent and empty. Also, the action prescribes the next action to be again a choose action by setting the fluent next-choose to true. The actions choose-announce and announce can be defined similarly. Announcing works by making all worlds where the agent has a different goal than its current position distinguishable to any other world for all agents. E.g., our example instance from Figure 1 can then be defined using the following initial state and goal descriptions: We tested our MAPF/DU planning domain using the myND planner of Mattm\u00fcller et al. (2010), which is to the Experiment time 2 agents, 4 cells, and 4 worlds 0.55s 3 agents, 6 cells, and 8 worlds 11.5s best of our knowledge the only publicly available FOND planner that supports both strong acyclic plans as well as conditional effects. It also supports axioms, although we did not need them for our example. Table 1 shows the performance of the planner on the example instance from Figure 1 as well as on a slightly bigger version with three agents.", "n_publication_ref": 4, "n_figure_ref": 3}, {"heading": "Conclusion", "text": "In our paper, we have shown a decidable fragment of strong epistemic planning that has the same complexity than strong planning in FOND. We have also demonstrated how FOND planning can be used to generate subjectively strong plans. For future work, it is worth noticing that DEL can be used for modeling games. In particular, there is a translation from the game description language GDL-III to DEL (Engesser et al. 2018). There are some very interesting games which fall within our decidable fragment, one of which is Hanabi, which has gained some attention recently (Bard et al. 2019). While using a FOND planner does not seem to be feasible for problems of this size, it will be interesting to investigate how the idea of simulating perspective taking via nondeterminism can be incorporated into techniques such as Monte Carlo tree search or model-based reinforcement learning (e.g., value iteration in fully-observable MDPs).", "n_publication_ref": 2, "n_figure_ref": 0}], "references": [{"title": "Epistemic planning (Dagstuhl seminar 17231)", "journal": "", "year": "2013", "authors": "Guillaume Aucher; Thomas Bolander ; Thomas; Hans Bolander; Sheila A Van Ditmarsch; Marc G Mcilraith ; Hugo Larochelle; Michael Bellemare;  Bowling"}, {"title": "Better eager than lazy? How agent types impact the successfulness of implicit coordination", "journal": "AAAI Press", "year": "2011-07-25", "authors": "Thomas Bolander; Mikkel Birkegaard Andersen ; Thomas Bolander; Martin Holm Jensen; Fran\u00e7ois Schwarzentruber"}, {"title": "Weak, strong, and strong cyclic planning via symbolic model checking", "journal": "IJCAI/AAAI Press", "year": "2003", "authors": "Tristan Charrier; Bastien Maubert; Fran\u00e7ois Schwarzentruber ; Alessandro; Marco Cimatti; Marco Pistore; Paolo Roveri;  Traverso"}, {"title": "Robert Mattm\u00fcller, Manuela Ortlieb, Malte Helmert, and Pascal Bercher. Pattern database heuristics for fully observable nondeterministic planning", "journal": "Yale Center for Computational Vision and Control", "year": "1998", "authors": "Thorsten Engesser; Robert Mattm\u00fcller; Bernhard Nebel; Michael Thielscher ; Malik; Dana S Ghallab; Paolo Nau;  Traverso"}, {"title": "Implicitly coordinated multi-agent path finding under destination uncertainty: Success guarantees and computational complexity", "journal": "Johan van Benthem", "year": "2003", "authors": "Bernhard Nebel; Thomas Bolander; Thorsten Engesser; Robert Mattm\u00fcller ; Van Eijck; Barteld Kooi"}, {"title": "Dynamic Epistemic Logic", "journal": "Springer", "year": "2007", "authors": "P Hans; Wiebe Van Ditmarsch; Barteld Van Der Hoek;  Kooi"}], "figures": [{"figure_label": "", "figure_type": "", "figure_id": "fig_0", "figure_caption": "Figure 1: A MAPF/DU instance.", "figure_data": ""}, {"figure_label": "", "figure_type": "", "figure_id": "fig_1", "figure_caption": "(:objects a1 a2 -agt l m r b -pos) (:init (adj l m) (adj m l) (adj m r) ; ... (ind a1 w1 w2) (ind a1 w2 w1) ; ... (ind a2 w1 w3) (ind a2 w3 w1) ; ... (goal w1 a1 r) (goal w1 a2 l) ; ... (goals for w2, w3, w4) (des w1) (next-choose)) (:goal (forall (?w -wld ?a -agt ?p -pos) (imply (and (des ?w) (goal ?w ?a ?p)) (at ?a ?p))))", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Case study.", "figure_data": ""}], "formulas": [], "doi": ""}