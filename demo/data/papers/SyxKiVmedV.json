{"title": "EXPLANATION-BASED ATTENTION FOR SEMI-SUPERVISED DEEP ACTIVE LEARNING", "authors": "Denis Gudovskiy; Alec Hodgkinson; Takuya Yamaguchi; Sotaro Tsukizawa", "pub_date": "", "abstract": "We introduce an attention mechanism to improve feature extraction for deep active learning (AL) in the semi-supervised setting. The proposed attention mechanism is based on recent methods to visually explain predictions made by DNNs. We apply the proposed explanation-based attention to MNIST and SVHN classification. The conducted experiments show accuracy improvements for the original and class-imbalanced datasets with the same number of training examples and faster long-tail convergence compared to uncertainty-based methods.", "sections": [{"heading": "INTRODUCTION", "text": "Deep active learning (AL) minimizes the number of expensive annotations needed to train DNNs by selecting a subset of relevant data points from a large unlabeled dataset (Lewis & Gale, 1994). This subset is annotated and added to the training dataset in a single pool of data points or, more often, in an iterative fashion. The goal is to maximize prediction accuracy while minimizing the product of pool size \u00d7 number of iterations. A proxy for this goal could be the task of matching feature distributions between the validation and the AL-selected training datasets.\nIn density-based AL approaches, data selection is typically performed using a simple L 2 -distance metric (Sener & Savarese, 2018). The image retrieval field (Zhou et al., 2017) has advanced much further in this area. For example, recent state-of-the-art image retrieval systems are based on DNNbased feature extraction (Babenko & Lempitsky, 2015) with attention mechanisms (Noh et al., 2017). The latter estimates an attention mask to weight importance of the extracted features and it is trained along with the feature extraction.\nInspired by this, we employ image retrieval techniques and propose a novel attention mechanism for deep AL. Unlike supervised self-attention in (Noh et al., 2017;Vaswani et al., 2017), our attention mechanism is not trained with the model. It relies on recent methods to generate visual explanations and to attribute feature importance values (Sundararajan et al., 2017). We show the effectiveness of such explanation-based attention (EBA) mechanism for AL when combined with multi-scale feature extraction on a number of image classification datasets. We also conduct experiments for distorted class-imbalanced training data which is a more realistic assumption for unlabeled data.", "n_publication_ref": 8, "n_figure_ref": 0}, {"heading": "RELATED WORK", "text": "AL is a well-studied approach to decrease annotation costs in a traditional machine learning pipelines (Settles, 2010). Recently, AL has been applied to data-demanding DNN-based systems in semi-supervised or weakly-supervised settings. Though AL is an attractive direction, existing methods struggle to deal with high-dimensional data e.g. images. We believe this is related to the lack of class and instance-level feature importance information as well as the inability to capture spatially-localized features. To overcome these limitations, we are interested in estimating spatiallymultiscale features and using our EBA mechanism to select only the most discriminative features. softmax Figure 1: Conventional multi-scale feature extraction and the proposed EBA extension (dashed). Wang et al. (2017) proposed to augment the training dataset by labeling the least confident data points and heuristically pseudo-labeling high confidence predictions. We believe the softmax output is not a reliable proxy for the goals of AL i.e. for selecting images using feature distribution matching between validation and train data. Unlike (Wang et al., 2017), we use pseudo labels only to estimate EBA vectors and find similarities between discriminative features. Gal et al. (2017) introduced a measure of uncertainty for approximate Bayesian inference that can be estimated using stochastic forward passes through a DNN with dropout layers. An acquisition function then selects data points with the highest uncertainty which is measured at the output of softmax using several metrics. Recent work (Beluch et al., 2018) extended this method by using an ensemble of networks for uncertainty estimation and achieved superior accuracy.\nSener & Savarese (2018) formulated feature similarity-based selection as a geometric core-set approach which outperforms greedy k-center clustering. Though their method can complement our approach, we are focusing on the novel feature extraction. For instance, they employed a simple L 2 distance similarity measure for the activations of the last fully-connected layer.\nThe most similar work to ours, by Vodrahalli et al. (2018), uses the gradients as a measure of importance for dataset subsampling and analysis. However, our approach formulates the problem as a multi-scale EBA for AL application and goes beyond a less robust single-step gradient attention. Other related works are online importance sampling methods (Ren et al., 2018) and the influence functions approach in (Koh & Liang, 2017). Online importance sampling upweights samples within the mini-batch during supervised training using gradient similarity while influence functions analyze data point importance using computationally challenging second-order gradient information.", "n_publication_ref": 8, "n_figure_ref": 1}, {"heading": "METHOD", "text": "Pool-based AL. Let (X, y) be an input-label pair. There is a validation dataset {(X v i , y v i )} i\u2208M of size M and a collection of training pairs {(X i , y i )} i\u2208N of size N for which, initially, only a small random subset or pool of labels indexed by N 1 is known. The validation dataset approximates the distribution of test data. At every bth iteration the AL algorithm selects a pool of P new labels to be annotated and added to existing training pairs which creates a training dataset indexed by N b .\nA DNN \u03a6(X, \u03b8) is optimized by minimizing a loss function (N b ) \u22121 i\u2208N b L(\u0177 i , y i ) w.r.t. to model parameters \u03b8. However, the actual task is to minimize validation loss expressed by\nM \u22121 i\u2208M L(\u0177 v i , y v i ).\nTherefore, an oracle AL algorithm achieves minimum of validation loss using the smallest b \u00d7 P product. In this work, we are interested not in finding an oracle acquisition function, but in a method to extract relevant features for such function. We use a low-complexity greedy k-center algorithm to select the data points in the unlabeled training collection which are most similar to the misclassified entries in the validation dataset.\nFeature descriptors. Let F j i \u2208 R C\u00d7H\u00d7W , where C, H, and W are the number of channels, the height, and the width, respectively be the output of the jth layer of DNN for input image X i . Then, a feature vector or descriptor of length L can be defined as d i = \u03c6(F i ) \u2208 R L\u00d71 , where function \u03c6(\u2022) is a conventional average pooling operation from (Babenko & Lempitsky, 2015). In a multi-scale case, descriptor is a concatenation of multiple feature vectors\nd i = [\u03c6 j (F j i ), \u2022 \u2022 \u2022 , \u03c6 l (F l i )].\nA descriptor matrix for the validation dataset V d \u2208 R L\u00d7M and training dataset S d \u2208 R L\u00d7N can be calculated using forward passes. Practically, descriptors can be compressed for storage efficiency reasons using PCA, quantization, etc. Then, a match kernel (Lee, 1999), e.g. cosine similarity, can be used to match features in both datasets. Assuming that vectors d i are L 2 -normalized, the cosine-similarity matrix is simply R d = V T d S d . Explanation-based attention. Feature maps F i extracted by \u03a6(X, \u03b8) and pooled by \u03c6(\u2022) contain features that: a) are not class and instance-level discriminative (in other words, not disentangled), b) spatially represent features for a plurality of objects in the input. We would like to upweight discriminative features that satisfy a) and b) using an attention mechanism. One approach would be to use self-attention (Vaswani et al., 2017) at the cost of modifying network architecture and intervening into the training process. Instead, we propose to use EBA that is generated only for feature selection. The EBA mechanism attributes feature importance values w.r.t. to the output predictions. Unlike a visual explanation task, which estimates importance heatmaps in the input (image) space, we propose to estimate feature importance tensors A i of the internal DNN representations F i . Attention tensors A i can be efficiently calculated using a series of backpropagation passes. Using one of backpropagation-based methods called integrated gradients (IG) from (Sundararajan et al., 2017) ,  A j i can be estimated as\nA j i = 1 K K k=1 \u2202L(\u0177 i (k), y i ) \u2202F j i = 1 K K k=1 \u2202L(\u03a6(kX i /K, \u03b8), y i ) \u2202F j i ,(1)\nwhere K is the number of steps to approximate the continuous integral by a linear path. Other forms of (1) are possible: from the simplest saliency method for which K = 1 (Simonyan et al., 2014) to more advanced methods with randomly sampled input features (Gudovskiy et al., 2018).\nDue to lack of labels y i in (1), we use common pseudo-labeling strategy: y i = 1 arg max\u0177i . It is schematically shown in Figure 1. Unlike (Wang et al., 2017), pseudo-labels are used only to calculate similarity without additional hyperparameters rather than to perform a threshold-selected greedy augmentation. The EBA A i can be converted to multi-scale attention vector using the same processing a i = \u03c6(A i ) \u2208 R L\u00d71 , which, by analogy, forms validation V a \u2208 R L\u00d7M and train attention matrices S a \u2208 R L\u00d7N . The latter processing is implemented in most modern frameworks and, therefore, the complexity to generate A i is only K forward-backward passes.\nSummary for the proposed method. A random subset of N 1 training data points is annotated and a DNN \u03a6(X, \u03b8) optimized for this subset. Then, the AL algorithm iteratively (b = 2, 3 . . .) performs following steps: 1) generates descriptor-attention matrix pairs\n(V d , V a ), (S d , S a ), 2) calculates similarity matrix R = R d R a = (V T d S d ) (V T a S a )\n, where is element-wise product, 3) selects P relevant data points from the remaining subset using acquisition function arg max i\u2208N\\N b\u22121 (R(X i ), \u03a6) and 4) retrains \u03a6(X, \u03b8) using augmented subset N b .", "n_publication_ref": 7, "n_figure_ref": 2}, {"heading": "EXPERIMENTS", "text": "Our method as well as uncertainty-based methods from (Gal et al., 2017) are applied to the MNIST and SVHN classification. We evaluate AL with the original and distorted training data because unlabeled collection of data points cannot be a-priori perfectly selected. Hence, we introduce a class imbalance which is defined as the ratio of {0 . . . 4} to {5 . . . 9} digits. The following methods have been employed: random sampling, uncertainty-based (uncert), greedy selection using similarity matching without (top-P:none) and with EBA. The latter is estimated by saliency (top-P:grad) or IG (top-P:ig). We rerun experiments 10 times for MNIST and 5 times for SVHN with all-randomized initial parameters. Mean accuracy and standard deviation are reported. DNN parameters are trained from scratch initially and after each AL iteration. Mini-batch size is chosen by cross-validation.\nMNIST. The dataset train/val/test split is 50K/10K/10K. The LeNet is used with the following hyperparameters: epochs=50, batch-size=25, lr=0.05, lr-decay=0.1 every 15 epochs, uncert methods and IG EBA use K = 128 passes and L is 20 for single-scale (before fc1 layer) and 90 for multiscale descriptors (all layers are concatenated). Figure 2(a) shows that feature-only matching (top-P:none L20) outperforms random selection by \u2248 1% while EBA (top-P:ig L90) adds another 1% of accuracy when there is no class imbalance. High class imbalance (Figure 2(c)) increases that gap: up to 20% for feature-only matching and 25% with EBA. The highest accuracy is achieved by multi- Top-1 Accuracy, % full random uncert:varMC uncert:entMC top-P:none_L20 top-P:grad_L20 top-P:ig_L20 top-P:ig_L90 top-P:igAbl_L20 top-P:igAbl_L90 0.5 1.0 1.5 2.0 2.5 3.0 3. Top-1 Accuracy, % full random uncert:varMC uncert:entMC top-P:none_L20 top-P:grad_L20 top-P:ig_L20 top-P:ig_L90 top-P:igAbl_L20 top-P:igAbl_L90 0.5 1.0 1.5 2.0 2.5 3.0 3. Top-1 Accuracy, % full random uncert:varMC uncert:entMC top-P:none_L20 top-P:grad_L20 top-P:ig_L20 top-P:ig_L90 top-P:igAbl_L20 top-P:igAbl_L90 scale EBA estimated by IG. EBA-based methods outperform the best uncertainty-based variation ratio (uncert:varMC) approach for all class imbalance settings except the last one where its accuracy is higher by less than 1% when b = 4. This might be related to small-scale MNIST and pseudo-label noise for EBA. To study the effects of pseudo-labeling, we plot true-label configurations (marked by \"Abl\") as well. The accuracy gap between EBA using true-and pseudo-labels is small with no class imbalance, but much larger (up to 25%) when class imbalance ratio is 100 during first AL iterations. ", "n_publication_ref": 1, "n_figure_ref": 2}], "references": [{"title": "Aggregating local deep features for image retrieval", "journal": "", "year": "2015", "authors": "Artem Babenko; Victor Lempitsky"}, {"title": "The power of ensembles for active learning in image classification", "journal": "", "year": "2018", "authors": "H William; Tim Beluch; Andreas Genewein; Jan M N\u00fcrnberger;  K\u00f6hler"}, {"title": "Deep Bayesian active learning with image data", "journal": "", "year": "2017", "authors": "Yarin Gal; Riashat Islam; Zoubin Ghahramani"}, {"title": "Explain to fix: A framework to interpret and correct DNN object detector predictions", "journal": "", "year": "2018", "authors": "Denis Gudovskiy; Alec Hodgkinson; Takuya Yamaguchi; Yasunori Ishii; Sotaro Tsukizawa"}, {"title": "Understanding black-box predictions via influence functions", "journal": "", "year": "2017", "authors": "Wei Pang; Percy Koh;  Liang"}, {"title": "Simple and scalable predictive uncertainty estimation using deep ensembles", "journal": "", "year": "2017", "authors": "Balaji Lakshminarayanan; Alexander Pritzel; Charles Blundell"}, {"title": "Measures of distributional similarity", "journal": "", "year": "1999", "authors": "Lillian Lee"}, {"title": "A sequential algorithm for training text classifiers", "journal": "", "year": "1994", "authors": "D David; William A Lewis;  Gale"}, {"title": "Large-scale image retrieval with attentive deep local features", "journal": "", "year": "2017", "authors": "Hyeonwoo Noh; Andre Araujo; Jack Sim; Tobias Weyand; Bohyung Han"}, {"title": "Learning to reweight examples for robust deep learning", "journal": "", "year": "2018", "authors": "Mengye Ren; Wenyuan Zeng; Bin Yang; Raquel Urtasun"}, {"title": "Active learning for convolutional neural networks: A core-set approach", "journal": "", "year": "2018", "authors": "Ozan Sener; Silvio Savarese"}, {"title": "Active learning literature survey", "journal": "", "year": "2010", "authors": "Burr Settles"}, {"title": "Deep inside convolutional networks: Visualising image classification models and saliency maps", "journal": "", "year": "2014", "authors": "Karen Simonyan; Andrea Vedaldi; Andrew Zisserman"}, {"title": "Axiomatic attribution for deep networks", "journal": "", "year": "2017", "authors": "Mukund Sundararajan; Ankur Taly; Qiqi Yan"}, {"title": "Attention is all you need", "journal": "", "year": "2017", "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; Illia Kaiser;  Polosukhin"}, {"title": "Are all training examples created equal? an empirical study", "journal": "", "year": "2018", "authors": "Kailas Vodrahalli; Ke Li; Jitendra Malik"}, {"title": "Cost-Effective active learning for deep image classification", "journal": "", "year": "2017", "authors": "Keze Wang; Dongyu Zhang; Ya Li; Ruimao Zhang; Liang Lin"}, {"title": "Recent advance in content-based image retrieval: A literature survey", "journal": "", "year": "2017", "authors": "Wengang Zhou; Houqiang Li; Qi Tian"}], "figures": [{"figure_label": "23", "figure_type": "", "figure_id": "fig_3", "figure_caption": "Figure 2 :Figure 3 :23Figure 2: MNIST test dataset accuracy for 3 class imbalance ratios: a) 1 (no imbalance), b) 10 and c) 100. Total 9 AL iterations (b = 10) are performed each with P = 250 pool size.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "SVHN. The dataset train/validation/test split is 500K/104K/26K. A typical 8-layer CNN is used with the following hyperparameters: epochs=35, batch-size=25, lr=0.1, lr-decay=0.1 every 15 epochs, uncert methods and IG EBA use K = 128 and L is 256 for single-scale (before fc1 layer) and 384 for two-scale descriptors (+ layer before conv7). Figure3shows that the gap between random selection and the best EBA-based AL method grows from 2% to more than 12% when the unlabeled training collection has more class imbalance. The gap between full training dataset accuracy increases for larger-scale SVHN as well. This results in even faster convergence for the proposed AL relative to random selection. Accuracies of the uncert methods are closer to each other than for MNIST, which may signal their declining effectiveness for large-scale data. The proposed EBA-based methods outperform all uncertainty-based methods for SVHN in the first AL iterations (up to +2.5%) and later arrive at approximately equal results.5 CONCLUSIONS AND FUTURE WORKWe applied recent image retrieval feature-extraction techniques to deep AL and introduced a novel EBA mechanism to improve feature-similarity matching. First feasibility experiments on MNIST and SVHN datasets showed advantages of EBA to improve density-based AL. Rather than performing AL for the well-picked training datasets, we also considered more realistic and challenging scenarios with class-imbalanced training collections where the proposed method emphasized the importance of additional feature supervision. In future research, EBA could be evaluated with other types of data distortions and biases: within-class bias, adversarial examples, etc. Furthermore, such applications as object detection and image segmentation may benefit more from EBA because multiscale attention can focus on spatially-important features.", "figure_data": ""}], "formulas": [], "doi": ""}