{"title": "AN ADVERSARIAL LEARNING FRAMEWORK FOR A PERSONA-BASED MULTI-TURN DIALOGUE MODEL", "authors": "", "pub_date": "", "abstract": "In this paper, we extend the persona-based sequence-to-sequence (Seq2Seq) neural network conversation model to a multi-turn dialogue scenario by modifying the state-of-the-art hredGAN architecture to simultaneously capture utterance attributes such as speaker identity, dialogue topic, speaker sentiments and so on. The proposed system, phredGAN has a persona-based HRED generator (PHRED) and a conditional discriminator. We also explore two approaches to accomplish the conditional discriminator: (1) phredGAN a , a system that passes the attribute representation as an additional input into a traditional adversarial discriminator, and (2) phredGAN d , a dual discriminator system which in addition to the adversarial discriminator, collaboratively predicts the attribute(s) that generated the input utterance. To demonstrate the superior performance of phredGAN over the persona SeqSeq model, we experiment with two conversational datasets, the Ubuntu Dialogue Corpus (UDC) and TV series transcripts from the Big Bang Theory and Friends. Performance comparison is made with respect to a variety of quantitative measures as well as crowd-sourced human evaluation. We also explore the trade-offs from using either variant of phredGAN on datasets with many but weak attribute modalities (such as with Big Bang Theory and Friends) and ones with few but strong attribute modalities (customer-agent interactions in Ubuntu dataset).", "sections": [{"heading": "INTRODUCTION", "text": "Recent advances in machine learning especially with deep neural networks has lead to tremendous progress in natural language processing and dialogue modeling research (Sutskever et al., 2014;Vinyals & Le, 2015;Serban et al., 2016). Nevertheless, developing a good conversation model capable of fluent interaction between a human and a machine is still in its infancy stage. Most existing work relies on limited dialogue history to produce response with the assumption that the model parameters will capture all the modalities within a dataset. However, this is not true as dialogue corpora tend to be strongly multi-modal and practical neural network models find it difficult to disambiguate characteristics such as speaker personality, location and sub-topic in the data.\nMost work in this domain has primarily focused on optimizing dialogue consistency. For example, Serban et al. (Serban et al., 2016;2017b;a) and Xing et al. (2017) introduced a Hierarchical Recurrent Encoder-Decoder (HRED) network architecture that combines a series of recurrent neural networks to capture long-term context state within a dialogue. However, the HRED system suffers from lack of diversity and does not have any guarantee on the generator output since the output conditional probability is not calibrated. Olabiyi et al. (2018) tackles these problems by training a modified HRED generator alongside an adversarial discriminator in order to increase diversity and provide a strong and calibrated guarantee to the generator's output. While the hredGAN system improves upon response quality, it does not capture speaker and other attributes modality within a dataset and fails to generate persona specific responses in datasets with multiple modalities.\nOn the other hand, there has been some recent work on introducing persona into dialogue models. For example, Li et al. (2016b) integrates attribute embeddings into a single turn (Seq2Seq) generative dialogue model. In this work, Li et al. consider persona models one with Speaker-only representation and the other with Speaker and Addressee representations (Speaker-Addressee model), both of which capture certain speaker identity and interactions. Nguyen et al. (2018) continue along the Figure 1: The PHRED generator with local attention -The attributes C, allows the generator to condition its response on the utterance attributes such as speaker identity, subtopics and so on. same line of thought by considering a Seq2Seq dialogue model with Responder-only representation. In both of these cases, the attribute representation is learned during the system training. Zhang et al. (2018) proposed a slightly different approach. Here, the attributes are a set of sentences describing the profile of the speaker. In this case, the attributes representation is not learned. The system however learns how to attend to different parts of the attributes during training. Still, the above persona-based models have limited dialogue history (single turn); suffer from exposure bias worsening the trade-off between personalization and conversation quality and cannot generate multiple responses given a dialogue context. This is evident in the relatively short and generic responses produced by these systems, even though they generally capture the persona of the speaker.\nIn order to overcome these limitations, we propose two variants of an adversarially trained persona conversational generative system, phredGAN , namely phredGAN a and phredGAN d . Both systems aim to maintain the response quality of hredGAN and still capture speaker and other attribute modalities within the conversation. In fact, both systems use the same generator architecture (PHRED generator), i.e., an hredGAN generator (Olabiyi et al., 2018) with additional utterance attribute representation at its encoder and decoder inputs as depicted in Figure 1. Conditioning on external attributes can be seen as another input modality as is the utterance into the underlying system. The attribute representation is an embedding that is learned together with the rest of model parameters similar to Li et al. (2016b). Injecting attributes into a multi-turn dialogue system allows the model to generate responses conditioned on particular attribute(s) across conversation turns. Since the attributes are discrete, it also allows for exploring different what-if scenarios of model responses. The difference between the two systems is in the discriminator architecture based on how the attribute is treated.\nWe train and sample both variants of phredGAN similar to the procedure for hredGAN (Olabiyi et al., 2018). To demonstrate model capability, we train on a customer service related data such as the Ubuntu Dialogue Corpus (UDC) that is strongly bimodal between question poser and answerer, and transcripts from a multi-modal TV series The Big Bang Theory and Friends with quantitative and qualitative analysis. We examine the trade-offs between using either system in bi-modal or multi-modal datasets, and demonstrate system superiority over state-of-the-art persona conversational models in terms of dialogue response quality and quantitatively with perplexity, BLEU, ROUGE and distinct n-gram scores.", "n_publication_ref": 14, "n_figure_ref": 2}, {"heading": "MODEL ARCHITECTURE", "text": "In this section, we briefly introduce the state-of-the-art hredGAN model and subsequently show how we derive the two persona versions by combining it with the distributed representation of the dialogue speaker and utterance attributes, or with an attribute discrimination layer at the end of the model pipeline.\nFigure 2: The phredGAN d dual discriminator -Left: D adv is a word-level discriminator used by both phredGAN a and phredGAN d to judge normal dialogue coherency as in hredGAN . Right: D att , an utterance-level attribute discriminator is used only in phredGAN d to predict the likelihood a given utterance was generated from a particular attribute.", "n_publication_ref": 0, "n_figure_ref": 1}, {"heading": "hredGAN : ADVERSARIAL LEARNING FRAMEWORK", "text": "Problem Formulation: The hredGAN (Olabiyi et al., 2018) formulates multi-turn dialogue response generation as: given a dialogue history of sequence of utterances,\nX i = X 1 , X 2 , \u2022 \u2022 \u2022 , X i , where each utterance X i = X 1 i , X 2 i , \u2022 \u2022 \u2022 , X Mi i\ncontains a variable-length sequence of M i word tokens such that X i j \u2208 V for vocabulary V , the dialogue model produces an output\nY i = Y 1 i , Y 2 i , \u2022 \u2022 \u2022 , Y Ti i\n, where T i is the number of generated tokens. The framework uses conditional GAN structure to learn a mapping from an observed dialogue history to a sequence of output tokens. The generator, G, is trained to produce sequences that cannot be distinguished from the ground truth by an adversarially trained discriminator, D akin to a two-player min-max optimization problem. The generator is also trained to minimize the cross-entropy loss L M LE (G) between the ground truth X i+1 , and the generator output Y i . The following objective summarizes both goals:\nG * , D * = arg min G max D \u03bb G L cGAN (G, D) + \u03bb M L M LE (G) .\n(\n)1\nwhere \u03bb G and \u03bb M are training hyperparamters and L cGAN (G, D) and L M LE (G) are defined in Eqs.\n(5) and ( 7) of Olabiyi et al. (2018) respectively. Please note that the generator G and discriminator D share the same encoder and embedding representation of the word tokens.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "phredGAN : PERSONA ADVERSARIAL LEARNING FRAMEWORK", "text": "The proposed architecture of phredGAN is very similar to that of hredGAN (Olabiyi et al., 2018). The only difference is that the dialogue history is now\nX i = (X 1 , C 1 ), (X 2 , C 2 ), \u2022 \u2022 \u2022 , (X i , C i )\nwhere C i is additional input that represents the speaker and/or utterance attributes. Please note that C i can either be a sequence of tokens or single token such that C i j \u2208 V c for vocabulary V c. Also, at the ith turn, C i and C i+1 are the source/input attribute and target/output attribute to the generator respectively. The embedding for attribute tokens is also learned similar to that of word tokens.\nBoth versions of phredGAN shares the same generator architecture (PHRED) but different discriminators. Below is the highlight of how they are derived from the hredGAN architecture.\nEncoder: The context RNN, cRN N takes the source attribute C i as an additional input by concatenating its representation with the output of eRN N as in Figure 1. If the attribute C i is a sequence of tokens, then an attention (using the output of eRN N ) over the source attribute representations is concatenated with the output of eRN N . This output is used by the generator to create a context state for a turn i.\nGenerator: The generator decoder RNN, dRN N takes the target attribute C i+1 as an additional input as in Fig. 1. If the attribute C i+1 is a sequence of tokens, then an attention (using the output of dRN N ) over the attribute representations is concatenated with the rest of the decoder inputs. This forces the generator to draw a connection between the generated responses and the utterance attributes such as speaker identity.\nNoise Injection: As in Olabiyi et al. (2018), we also explore different noise injection methods.\nObjective: For phredGAN , the optimization objective in eq. ( 1) can be updated as:\nG * , D * adv , D * att = arg min G max D adv \u03bb G adv L adv cGAN (G, D adv ) (2) + min Datt \u03bb Gatt L att c (G, D att ) + \u03bb M L M LE (G) .\nwhere L adv cGAN (G, D adv ) and L att c (G, D att ) are the traditional adversarial and attribute prediction loss respectively and dependent on the architectural variation. It is worth to point out that while the former is adversarial, the later is collaborative in nature. The MLE loss is common and can be expressed as:\nL M LE (G) = E Xi+1 [\u2212log P G X i+1 |X i , C i+1 , Z i ].\n(3) where Z i the noise sample and depends on the choice of either utterance-level or word-level noise input into the generator (Olabiyi et al., 2018).", "n_publication_ref": 3, "n_figure_ref": 2}, {"heading": "phredGAN a : ATTRIBUTES AS A DISCRIMINATOR INPUT", "text": "phredGAN a shares the same discriminator architecture as the hredGAN but with additional input, C i+1 . Since it does not use attribute prediction, \u03bb Gatt = 0.\nThe adversarial loss, L adv cGAN (G, D) can then be expressed as:\nL adv cGAN (G, D adv ) = E X i ,Ci+1,Xi+1 [log D adv (X i , C i+1 , X i+1 )] (4) + E X i ,Ci+1,Zi [1 \u2212 log D adv (X i , C i+1 , G(X i , C i+1 , Z i ))]\nThe addition of speaker or utterance attributes allows the dialogue model to exhibit personality traits given consistent responses across style, gender, location, and so on.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "phredGAN d : ATTRIBUTES AS A DISCRIMINATOR TARGET", "text": "phredGAN d does not take the attribute representation at its input but rather use the attributes as the target of an additional discriminator D att . The adversarial and the attribute prediction losses can be respectively expressed as:\nL adv cGAN (G, D adv ) = E X i ,Xi+1 [log D adv (X i , X i+1 )] (5) + E X i ,Zi [1 \u2212 log D adv (X i , G(X i , C i+1 , Z i ))] L att c (G, D att ) = E Ci+1 [\u2212 log D att (C i+1 |X i , X i+1 )] (6) + E Ci+1 [\u2212 log D att (C i+1 |X i , G(X i , C i+1 , Z i ))]\nAttribute Discriminator: In addition to the existing word-level adversarial discriminator D adv from hredGAN , we add an attribute discriminator, D att , that discriminates on an utterance level to capture attribute modalities since attributes are assigned at utterance level. The discriminator uses a unidirectional RNN (D attRN N ) that maps the input utterance to the particular attribute(s) that generated it. The attributes can be seen as hidden states that inform or shape the generator outputs. The attribute discriminator can be expressed as:\nD att (C i+1 |X i , \u03c7) = D attRN N (h i , E(\u03c7))(7)\nwhere E(.) is the word embedding lookup (Olabiyi et al., 2018), \u03c7 = X i+1 for groundtruth and \u03c7 = Y i for the generator output.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "MODEL TRAINING AND INFERENCE", "text": "", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "MODEL TRAINING", "text": "We train both the generator and the discriminator (with shared encoder) of both variants of phredGAN using the training procedure in Algorithm 1 (Olabiyi et al., 2018). For both variants, \u03bb G adv = \u03bb M = 1, and for phredGAN a and phredGAN d , \u03bb Gatt = 0 and \u03bb Gatt = 1 respectively. Since the encoder, word embedding and attribute embedding are shared, we are able to train the system end-to-end with back-propagation.\nEncoder: The encoder RNN, eRN N , is bidirectional while cRRN is unidirectional. All RNN units are 3-layer GRU cell with hidden state size of 512. We use word vocabulary size, V = 50, 000 with word embedding size of 512. The number of attributes, V c is dataset dependent but we use an attribute embedding size of 512. In this study, we only use one attribute per utterance so that is no need to use attention to combine the attribute embeddings.\nGenerator: The generator decoder RNN, dRN N is also a 3-layer GRU cell with hidden state size of 512. The aRN N outputs are connected to the dRN N input using an additive attention mechanism (Bahdanau et al., 2015).\nAdversarial Discriminator: The word-level discriminator RNN, D RN N is a bidirectional RNN, each 3-layer GRU cell with hidden state size of 512. The output of both the forward and the backward cells for each word are concatenated and passed to a fully-connected layer with binary output.\nThe output is the probability that the word is from the ground truth given the past and future words of the sequence, and in the case of phredGAN a , the responding speaker's embedding.\nAttribute Discriminator: The attribute discriminator RNN, D attRN N is a unidirectional RNN with a 3-layer GRU cell, each of hidden state size 512. A softmax layer is then applied to project the final hidden state to a prespecified number of attributes, V c . The output is the probability distribution over the attributes.\nOthers: All parameters are initialized with Xavier uniform random initialization (Glorot & Bengio, 2010). Due to the large word vocabulary size, we use sampled softmax loss (Jean et al., 2015) for MLE loss to expedite the training process. However, we use full softmax for model evaluation. For both systems, parameters updates are conditioned on the word-level discriminator accuracy performance as in Olabiyi et al. (2018) with acc D th adv = 0.99 and acc G th = 0.75. The model is trained end-to-end using the stochastic gradient descent algorithm. Finally, the model is implemented, trained, and evaluated using the TensorFlow deep learning framework.", "n_publication_ref": 5, "n_figure_ref": 0}, {"heading": "MODEL INFERENCE", "text": "We use an inference strategy similar to the approach in Olabiyi et al. (2018).\nFor the modified noise sample, we perform a linear search for \u03b1 with sample size L = 1 based on the average word-level discriminator loss, \u2212logD adv (G(.)) (Olabiyi et al., 2018) using trained models run in autoregressive mode to reflect performance in actual deployment. The optimum \u03b1 value is then used for all inferences and evaluations. During inference, we condition the dialogue response generation on the encoder outputs, noise samples, word embedding and the attribute embedding of the intended responder. With multiple noise samples, L = 64, we rank the generator outputs by the discriminator which is also conditioned on encoder outputs, and the intended responder's attribute embedding. The final response is the response ranked highest by the discriminator. For phredGAN d , we average the confidences produced by D adv and D att .", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "EXPERIMENTS AND RESULTS", "text": "In this section, we explore the performance of PHRED, phredGAN a and phredGAN d on two conversational datasets and compare its performance to non-adversarial persona Seq2seq models Li et al. (2016b) as well as to the adversarial hredGAN (Olabiyi et al., 2018) with no explicit persona.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "DATASETS", "text": "TV Series Transcripts dataset (Serban et al., 2016). We train all models on transcripts from the two popular TV drama series, Big Bang Theory and Friends. Following a similar preprocessing setup in Li et al. (2016b), we collect utterances from the top 12 speakers from both series to construct a corpus of 5,008 lines of multi-turn dialogue. We split the corpus into training, development, and test set with a 94%, 3%, and 3% proportions, respectively, and pair each set with a corresponding attribute file that maps speaker IDs to utterances in the combined dataset.\nDue to the small size of the combined transcripts dataset, we first train our model on the larger Movie Triplets Corpus (MTC) by Banchs (2012) which consists of 240,000 dialogue triples. We pre-train  our model on this dataset to initialize our model parameters to avoid overfitting on a relatively small persona TV series dataset. After pre-training on MTC, we reinitialize the attribute embeddings in the generator from a uniform distribution following a Xavier initialization (Glorot & Bengio, 2010) for training on the combined person TV series dataset.\nUbuntu Dialogue Corpus (UDC) dataset (Serban et al., 2017b). We train our model on 1.85 million conversations of multi-turn dialogue from the Ubuntu community hub, with an average of 5 utterances per conversation. We assign two types of speaker IDs to utterances in this dataset: questioner and helper. We follow a similar training, development, and test split as the UDC dataset in Olabiyi et al. (2018), with 90%, 5%, and 5% proportions, respectively, and pair each set with a corresponding attribute file that maps speaker IDs to utterances in the combined dataset While the overwhelming majority of utterances in UDC follow two speaker types, the dataset does include utterances that do not classify under either a questioner or helper speaker type. In order to remain consistent, we assume that there are only two speaker types within this dataset and that the first utterance of every dialogue is from a questioner. This simplifying assumption does introduce a degree of noise into each persona model's ability to construct attribute embeddings. However, our experiment results demonstrate that both phredGAN a and phredGAN d is still able to differentiate between the larger two speaker types in the dataset.", "n_publication_ref": 6, "n_figure_ref": 0}, {"heading": "EVALUATION METRICS", "text": "We use similar evaluation metrics as in Olabiyi et al. (2018) including perplexity, BLEU (Papineni et al., 2002), ROUGE (Lin, 2014), distinct n-gram (Li et al., 2016a) and normalized average sequence length (NASL) scores. For human evaluation, we follow a similar setup as Li et al. (2016a), employing crowd-sourced judges to evaluate a random selection of 200 samples. We present both the multi-turn context and the generated responses from the models to 3 judges and asked them to rank the general response quality in terms of relevance, informativeness, and persona. For N models, the model with the lowest quality is assigned a score 0 and the highest is assigned a score N-1. Ties are not allowed. The scores are normalized between 0 and 1 and averaged over the total number of samples and judges. ", "n_publication_ref": 5, "n_figure_ref": 0}, {"heading": "BASELINE", "text": "We compare the non-adversarial persona HRED model, PHRED with the adversarially trained ones, i.e. hredGAN , phredGAN a and phredGAN d , to demonstrate the impact of adversarial training. Please note that no noise was added to the PHRED model.\nWe also compare the persona models to Li et al.'s work (Li et al., 2016b) which uses a Seq2Seq framework in conjunction with learnable persona embeddings. Their work explores two persona models in order to incorporate vector representations of speaker interaction and speaker attributes into the decoder of their Seq2Seq model i.e., Speaker model (SM) and Speaker-Addressee model (SAM). All reported results are based on our implementation of their models in Li et al. (2016b).", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "HYPERPARAMETER SEARCH", "text": "For both phredGAN a and phredGAN d , we determine the noise injection method and the optimum noise variance \u03b1 that allows for the best performance on both datasets. We find that phredGAN d performs optimally with word-level noise injection on both Ubuntu and TV transcripts, while phredGAN a performs the best with utterance-level noise injection on TV transcripts and word-level injection on UDC. For all phredGAN models, we perform a linear search for optimal noise variance values between 1 and 30 at an increment of 1, with a sample size of L = 1. For phredGAN d , we obtain an optimal \u03b1 of 4 and 6 for the UDC and TV Transcripts respectively. For phredGAN a , we obtain an optimal value of 2 and 5 for the combined TV series dataset and the much larger UDC respectively.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "RESULTS", "text": "We will now present our assessment of performance comparisons of phredGAN against the baselines, PHRED, hredGAN and Li et al.'s persona Seq2Seq models.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "QUANTITATIVE ANALYSIS", "text": "We first report the performance on TV series transcripts in table 1. The performance of both SM and SAM models in Li et al. (2016b) compared to the hredGAN shows a strong baseline and indicates that the effect of persona is more important than that of multi-turn and adversarial training for datasets with weak multiple persona. However, once the persona information is added to the hredGAN , the resulting phredGAN shows a significant improvement over the SM and SAM baselines with phredGAN a performing best. We also observe that PHRED performs worse than the baseline S(A)M models on a number of metrics but we attribute this to the effect of persona on a limited dataset that results into less informative responses. This behavior was also reported in Li et al. (2016b) where the persona models produce less informative responses than the non-personal Seq2seq models but it seems to be even worse in multi-turn context. However, unlike the Speaker-Addressee and PHRED models that suffer from lower response quality due to persona conditioning, we note that conditioning the generator and discriminator of phredGAN on speaker embeddings does not compromise the systems ability to produce diverse responses. This problem might have been alleviated by the adversarial training that encourages the generator model to produce longer, more informative, and diverse responses that have high persona relevance even with a limited dataset.\nWe also compare the models performances on the UDC. The evaluation result is summarized in table 2. While the deleterious effect of persona conditioning on response diversity is still worse with PHRED than with S(A)M models, we note that hredGAN performs much better than the S(A)M models. This is because, the external persona only provides just a little more information than is already available from the UDC utterances. We also note an improvement of phredGAN variants over the hredGAN in a variety of evaluation metrics including perplexity, ROUGE with the exception of distinct n-grams. This is expected as phredGAN should be generally less diverse than hredGAN since the number of distinct data distribution modes is more for phredGAN dataset due to the persona attributes. However, this leads to better response quality with persona, something not achievable with hredGAN . Also, the much better ROUGE(F1) score indicates that phredGAN is able to strike a better balance between diversity and precision while still capturing the characteristics of the speaker attribute modality in the UDC dataset. Within the phredGAN variants, phredGAN d seems to perform better. This is not surprising as speaker classification is much easier on UDC than on TV series. The attribute discriminator, D att is able to provide more informative feedback on UDC than on TV series where it is more difficult to accurately predict the speaker. Therefore, we recommend phredGAN a for datasets with weak attribute distinction and phredGAN d for strong attribute distinction.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "QUALITATIVE ANALYSIS", "text": "In addition to the quantitative analysis above, we report the results of the human evaluation in the last column of tables 1 and 2 for the TV Series and UDC datasets respectively. The human evaluation scores largely agrees with the automatic evaluations on the TV Series with phredGAN a clearly giving the best performance. However, on the UDC, both hredGAN and phredGAN d performs similarly which indicates that there is a trade off between diversity and persona by each model. We believe this is due to the strong persona information that already exists in the UDC utterances.\nAn additional qualitative assessment of these results are in Table 3 with responses from several characters in the TV series dataset and the two characters in UDC.\nWe see that for TV drama series, phredGAN responses are comparatively more informative than that of the Speaker-Addressee model of Li et al. (2016b). For example, all the characters in the TV series respond the same to the dialogue context. Similar behavior is reported in Li et al. (2016b) where for the Speaker-Addressee model, nearly all the characters in the TV series respond with We also see similar results with our model's output on UDC in table 4. We demonstrate that by conditioning as either a helper or questioner from the UDC dataset, phredGAN models are able to respond differently to input utterances as well as stay close to the context of the conversation.", "n_publication_ref": 2, "n_figure_ref": 0}, {"heading": "CONCLUSION AND FUTURE WORK", "text": "In this paper, we improve upon state-of-the-art persona-based response generation models by exploring two persona conversational models: phredGAN a which passes the attribute representation as an additional input into a traditional adversarial discriminator, and phredGAN d a dual discriminator system which in addition to the adversarial discriminator from hredGAN , collaboratively predicts the attribute(s) that are intrinsic to the input utterance. Both systems demonstrate quantitative improvements upon state-of-the-art persona conversational systems such as the work from Li et al. (2016b) with respect to both quantitative automatic and qualitative human measures.\nOur analysis also demonstrates how both variants of phredGAN perform differently on datasets with weak and strong modality. One of our future direction is to take advantage of phredGAN d 's ability to predict utterance attribute such as speaker identity from just the utterance. We believe its performance can be improved even with weak modality by further conditioning adversarial updates on both the attribute and adversarial discriminator accuracies. Overall, this paper demonstrates clear benefits from adversarial training of persona generative dialogue system and leaves the door open for more interesting work to be accomplished in this domain.  ", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "APPENDIX Algorithm 1 Adversarial Learning of phredGAN", "text": "Require: A generator G with parameters \u03b8 G . Require: An adversarial discriminator D adv with parameters \u03b8 D adv . Require: An attribute discriminator Datt with parameters \u03b8 D att . Require: Training hyperparameters, isT arget, \u03bb G att , \u03bb G adv , and \u03bb M .\nfor number of training iterations do Initialize cRN N to zero state, h0 Sample a mini-batch of conversations, X = {Xi, Ci} N i=1 , X i = (X1, C1), (X2, C2), \u2022 \u2022 \u2022 , (Xi, Ci) with N utterances. Each utterance mini batch i contains Mi word tokens.\nCompute the generator output similar to Eq. (11) in Olabiyi et al. (2018).\nSample a corresponding mini batch of utterance Yi.\nelse Update phredGANa's \u03b8 D adv with gradient of the discriminator loss.\nUpdate \u03b8 G with attribute, adversarial and MLE losses.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "RESULTS -DISCRIMINATOR", "text": "After training both phredGAN models on the TV series and UDC datasets, we ran inference on some example dialogue contexts. The responses and their discriminator scores from phredGAN s are listed in Tables 6, and 7. The tables shows that phredGAN (i) can handle multi-turn dialogue context with utterances and corresponding persona attributes; (ii) generates responses conditioned on a persona attribute; (iii) generates multiple responses per dialogue context and score their human likelihood by the discriminator; and (iv) in case of phredGAN d , can predict the attribute such as speaker identity that might have produced the utterance. We observe that the discriminator score(s) is/are generally reasonable with longer, more informative and more persona-related responses receiving higher scores. It worth to note that this behavior, although similar to the behavior of a human judge is learned without supervision. More so, we observe that phredGAN responses retain contextual consistency sometimes referencing background information that is inherent in the conversation between two speakers. For example, in the second sample of the TV series in Table 6, phredGAN a generator, conditioned on Leonard refers to Sheldon by name who is the second interlocutor. Also, in the third sample, phredGAN a , conditioned on Raj refers to Penny when responding to Leonard who happens to be Penny's boy friend. We see similar persona-based response generation for the UDC dataset with distinct communication style between the asker and the helper. For example, in Table 7, when the asker could not hear some music, phredGAN d , conditioned on helper suggested the asker might not be using the right driver. For the purpose of completion, we also show some samples from PHRED generator on both UDC and TV series dataset in Table 5. ", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "journal": "", "year": "2015", "authors": "D Bahdanau; K Cho; Y Bengio"}, {"title": "Movie-dic: A movie dialogue corpus for research and development", "journal": "", "year": "2012", "authors": "R E Banchs"}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "journal": "", "year": "2010", "authors": "X Glorot; Y Bengio"}, {"title": "On using very large target vocabulary for neural machine translation", "journal": "", "year": "2015", "authors": "S Jean; K Cho; R Memisevic; Y Bengio"}, {"title": "A diversity-promoting objective function for neural conversation models", "journal": "", "year": "2016", "authors": "J Li; M Galley; C Brockett; J Gao; B Dolan"}, {"title": "A persona-based neural conversation model", "journal": "", "year": "2016", "authors": "J Li; M Galley; C Brockett; G Spithourakis; J Gao; B Dolan"}, {"title": "Rouge: a package for automatic evaluation of summaries", "journal": "", "year": "2014", "authors": "C Y Lin"}, {"title": "A neural chatbot with personality", "journal": "", "year": "2018", "authors": "H Nguyen; D Morales; T Chin"}, {"title": "Multi-turn dialogue response generation in an adversarial learning framework", "journal": "", "year": "2018", "authors": "O Olabiyi; A Salimov; A Khazane; E Mueller"}, {"title": "Bleu: A method for automatic evalution of machine translation", "journal": "", "year": "2002", "authors": "K Papineni; S Roukos; T Ward; W Zhu"}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "journal": "", "year": "2016", "authors": "I Serban; A Sordoni; Y Bengio; A Courville; J Pineau"}, {"title": "Multiresolution recurrent neural networks: An application to dialogue response generation", "journal": "", "year": "2017", "authors": "I V Serban; T Klinger; G Tesauro; K Talamadupula; B Zhou; Y Bengio; A Courville"}, {"title": "A hierarchical latent variable encoder-decoder model for generating dialogue", "journal": "", "year": "2017", "authors": "I V Serban; A Sordoni; R Lowe; L Charlin; J Pineau; A Courville; Y Bengio"}, {"title": "Sequence to sequence learning with neural networks", "journal": "", "year": "2014", "authors": "I Sutskever; O Vinyals; Q Le"}, {"title": "A neural conversational model", "journal": "", "year": "2015", "authors": "O Vinyals; Q Le"}, {"title": "Hierarchical recurrent attention network for response generation", "journal": "", "year": "2017", "authors": "C Xing; W Wu; Y Wu; M Zhou; Y Huang; W Ma"}, {"title": "Personalizing dialogue agents: I have a dog", "journal": "", "year": "2018", "authors": "S Zhang; E Dinan; J Urbanek; A Szlam; D Kiela; J Weston"}], "figures": [{"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "phredGAN vs.Li et al. (2016b) on BBT Friends TV Transcripts.", "figure_data": "ModelTeacher Forcing PerplexityAutoregression BLEU ROUGE-2 DISTINCT-1/2 NASL Evaluation HumanTV SeriesSM22.131.76 %22.4 %2.50%/18.95% 0.7860.5566SAM23.061.86 % 20.52 %2.56%/18.91% 0.6890.5427hredGAN28.152.14 %6.81 %1.85 %/6.93 % 1.1350.5078phred30.942.41 % 14.03 %0.66 %/2.54 % 1.2160.3663phredGANa25.103.07 % 30.47 % 2.19 %/19.02 % 1.2180.6127phredGAN d28.192.76 % 14.68 %0.70 %/4.76 % 1.1630.4284"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "phredGAN vs. Li et al. (2016b) on UDC.", "figure_data": "ModelTeacher Forcing PerplexityBLEU-2/4Autoregression ROUGE-2 DISTINCT-1/2 NASL Evaluation HumanUDCSM28.320.437%/\u223c 0%9.19 %1.61%/5.79% 0.5060.4170SAM26.120.490%/\u223c 0% 10.23 %1.85%/6.85% 0.5120.4629hredGAN48.182.16%/\u223c 0%11.68 % 5.16%/18.21% 1.0980.5876phred34.670.16%/\u223c 0%7.41%0.56%/1.44% 0.3970.4718phredGANa31.251.94%/\u223c 0%19.15%1.05%/5.28% 1.5200.4558phredGAN d28.742.02%/0.10%16.82%1.38%/5.77% 1.3870.5817"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "hredGAN vs phredGAN vs Li et al. (2016b) on TV Transcripts", "figure_data": "ModelSpeakerResponseBig Bang Theory TV SeriesContext 0SheldonDo you like me?phredGANaLeonardYes ?phredGAN dLeonardYou can ' t do that ? !phredGANaPennyNo , you don ' t understand . You ' re an idiot .phredGAN dPennyYou ' re right . . .phredGANaHowardWell , I don ' t know what to say . This is the part I ' ve ever seen .phredGAN dHowardYou ' re right , you ' re just gonna go with this guy .phredGANaRajWell , you know , we could be a little more than my friends ' s friends .phredGAN dRajYou know , I can ' t can ' t do I can ' go , I can ' t do that . . .SMLeonard/Penny/Howard/RajYeah , I ' m sure . Oh , but I can ' t believe it . I ' m not gonna be in hereSAMLeonard/Penny/Howard/RajI ' m not going to be a good time .hredGANNAOkay , I ' m gonna go see my friend .Context 0HowardWe can't go home.Context 1LeonardAlright, I'll be right back.phredGANaHowardOkay , well , before you and Penny get out and get married with Penny just get married.phredGAN dHowardYou ' ll see , I ' ll just go .SMHowardOkay .SAMHowardOkay , well , you ' re really good at this .hredGANNAOkay , I ' m gonna go see my old .Context 0AmySpent a lot of my childhood throwing coins into wishing wells hoping for friends.Context 1PennyWhoa, whoa, give me a second to catch up here. Hold on.Context 2AmyThat'd be my boyfriend. Happier playing his dopey Star Trek game with his friends than hanging out withme.phredGANaPennyYou know , when you ' re being so nice about Sheldon and I want to take him to like his own girlfriendphredGAN dPennyYou , I ' m sorry , I didn ' t have it . d be back in the bathroom . .SMPennyI ' m sorry , I ' m sorry . I ' m just saying that you ' re going to have to answer toSAMPennyIt ' s not gonna happen .hredGANNAOkay , I ' m gonna go see my new .Context 0SheldonI recently read that during World War Two, Joseph Stalin had a research program to create supersoldiersby having women impregnated by gorillas.phredGANaHowardYou ' re right . I don ' t know what you ' re talking about , Sheldon .phredGAN dHowardYou ' re kidding . .SMHowardWell , my last was a little . I was just trying to be a good time .SAMHowardThat would be great .hredGANNAOkay , I ' m gonna go see my new friend , and then we ' ll go .Friends TV SeriesContext 0RachelDo you like me?phredGANaJoeyYeah .phredGAN dJoeyYou ' re right . . . .phredGANaRossWell , no , no , no . I mean , I just , I don ' t know . . .phredGAN dRossYou ' want to know sex . .phredGANaMonicaWell , I do . And I ' m not gonna tell you another guy .phredGAN dMonicaYou ' re a , you ' re really good . . . .phredGANaChandlerNo , I do not . You are a mean little man . .phredGAN dChandlerYou ' re right , I can ' t do that .SMJoey/Ross/Monica/ChandlerYeah , I ' m sure . Oh , but I can ' t believe it . I ' m not gonna be in hereSAMJoey/Ross/Monica/ChandlerI ' m not going to be a good time .hredGANNAOkay , I ' m gonna go see my friend ."}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "hredGAN vs phredGAN vsLi et al. (2016b) on UDC Of course I love you.\" to the dialogue context, \"Do you love me?\" despite the fact that some of the responders sometimes have unfriendly relationship with the addressee. Many of the novel situations explored by phredGAN are unachievable with the Speaker-Addressee model due to lack of informative responses. For example, by conditioning as Sheldon from The Big Bang Theory and asking \"Do you like me?\", our model responds with annoyance if conditioned as Penny (\"No, you don't understand. You're an idiot\"), brevity with Leonard (\"Yes?\") and sarcasm with Raj (\"Well , you know , we could be a little more than my friend's friends.\") The wide range of responses indicate our model's ability to construct distinct attribute embeddings for each character even from a limited dataset. The other interesting responses in table 3 indicate phredGAN 's ability to infer not only the context of the conversation but important character information about the addressee.", "figure_data": "ModelSpeakerResponseUDCContext 0askerall i need some quick amarok help. i cant hear my musicContext 1helperis amarok muted?Context 2askernophredGANahelperuse the UNK drivers , and then run the UNK command to get the UNKphredGAN dhelperok , so you re not using the right driver for the network card , you re using the UNK ?phredhelperyou can try to install the UNK packageSMhelperok , thanksSAMhelperok , thankshredGANhelperI have no idea why it would be a bit of a bit.Context 0askeranyone had problems with the kernel update from today? giving me a kernel panicContext 1helperyou can select previous kernels at the bootloader (grub) menu on booth.phredGANaaskerit says that it is not installed . . .phredGAN daskerok , so i ll have to reinstall the new kernel , i ll try that.phredaskeryou can try to install the drivers from the live cdSMaskerI ' m not sure what you mean . . .SAMaskerI ' m not sure how to do that . . .hredGANaskerI ' m not sure how to do that , but I can ' t boot from a CD . . .Context 0askerhow do I install Ubuntu?phredGANahelperuse the alternate cd , it should be in the repos , its a good place to get the source of the kernelphredGAN dhelperok , so you have to reinstall the kernel from the CD , and you can t install the iso to the CDphredhelperyesSMhelperyou can use the command lineSAMhelperwhat is your question ?hredGANhelperyou can use the UNK to install the UNK\""}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Sample of PHRED outputs on UDC and TV Series Howard Okay, you have to understand something, we're in a hospital right now. Response 0 Penny Oh , I ' m sorry . I was just trying to be a girl .Context 0 Sheldon Did I? Well, that can't be right. No one's ever done that before. Except me, because I just did it. Sheldon and his brain, yeah Response 0 Leonard I ' m sorry . I just don ' t want to be a man who ' s going to be my girlfriend .Context 0 Leonard She's gotten really hooked on Age of Conan, she's playing non-stop.", "figure_data": "SourceSpeaker UtteranceBig Bang Theory and Friends TV SeriesContext 0 Response 0 RajOh , I ' m sorry . I ' m sorry . I ' m sorry . I ' m sorry . I ' mUDCContext 0 askerall i need some quick amarok help. i cant hear my musicContext 1 helper is amarok muted?Context 2 askernoResponse 0 helper you can try to install the UNK packageContext 0 askeranyone had problems with the kernel update from today? giving me a kernel panicContext 1 helper you can select previous kernels at the bootloader (grub) menu on booth.Response 0 askeryou can try to install the drivers from the live cdContext 0 askerhow do I install Ubuntu?Response 0 helper yes"}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Ranked phredGAN a outputs according to adversarial word-level discrimination score Source Speaker D adv (G(.)) Utterance Well, that can't be right. No one's ever done that before. Except me, because I just did it. Sheldon and his brain, yeah cd , it should be in the repos , it's a good place to get the source of the kernel Response 1 helper 0.1984 use the UNK package , it should work . . .", "figure_data": "Big Bang Theory and Friends TV SeriesContext 0 Howard NAOkay, you have to understand something, we're in a hospital right now.Response 0 Penny0.1705Okay, I'm sorry. I'm not really even like that.Response 1 Penny0.1426Okay, I'm sorry, I'm sorry.Response 2 Penny0.0688Okay.Context 0 Sheldon NA Did I? Response 0 Leonard 0.3976 Sheldon , what are you doing ?Response 1 Leonard 0.3503Sheldon ?Context 0 Leonard NAShe's gotten really hooked on Age of Conan, she's playing non-stop.Response 0 Raj0.4890Okay , so we know , what about you and Penny doing here ?Response 1 Raj0.3586Okay , so we would have to say that about people ?Response 2 Raj0.1113Okay , let ' s go .UDCContext 0 askerNAall i need some quick amarok help. i cant hear my musicContext 1 helper NAis amarok muted?Context 2 askerNAnoResponse 0 helper 0.3079use the UNK drivers , and then run the \" UNK \" command to get the UNKResponse 1 helper 0.1283what is the error message ?Response 2 helper 0.0725what version of ubuntu ?Context 0 askerNAanyone had problems with the kernel update from today? giving me a kernel panicContext 1 helper NAyou can select previous kernels at the bootloader (grub) menu on booth.Response 0 asker0.3665it says that it is not installed . . .Response 1 asker0.3195i'm not sure what i can find . . .Response 2 asker0.0186it's a UNK , I'm not sure of the way .Context 0 askerNAhow do I install Ubuntu?Response 0 helper 0.5797 use the alternate Response 2 helper 0.0131 use the UNK"}], "formulas": [], "doi": ""}