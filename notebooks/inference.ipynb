{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oi5bJvhn8_iw",
    "outputId": "817fa3ce-80f9-4562-a438-79f45a48b99c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68M8X5v1_TNx",
    "outputId": "3cf138c4-0830-4795-bc60-2a15283fa9b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_p1_qyCU9D2K",
    "outputId": "eb312673-6049-418d-cccc-0ecf3491a247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "%set_env OPENAI_API_KEY="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3bpxmjOe9FgS"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZV4Be8Y4-JBS",
    "outputId": "d8f159a8-029e-470c-ed1e-3351398dc76e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "mcRvrG_E-MKM",
    "outputId": "bed11ed3-1774-4bef-baa9-a7301cd2b683"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>A good one</td>\n",
       "      <td>This paper proposes a better pre-trained prior...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>paper shows promising results using point clou...</td>\n",
       "      <td>The paper considers the problem of training ne...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>Limited novelty and weak improvements</td>\n",
       "      <td>The authors propose completing an occluded poi...</td>\n",
       "      <td>4: Ok but not good enough - rejection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>Since the idea itself is simple enough, the re...</td>\n",
       "      <td>The idea of this paper is simple but fascinati...</td>\n",
       "      <td>5: Marginally below acceptance threshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GamePad: A Learning Environment for Theorem Pr...</td>\n",
       "      <td>https://openreview.net/pdf?id=r1xwKoR9Y7</td>\n",
       "      <td>In this paper, we introduce a system called Ga...</td>\n",
       "      <td>Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...</td>\n",
       "      <td>An intriguing integration of ML and automated ...</td>\n",
       "      <td>Summary: This paper mixes automated theorem pr...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0            Pre-Training by Completing Point Clouds   \n",
       "1            Pre-Training by Completing Point Clouds   \n",
       "2            Pre-Training by Completing Point Clouds   \n",
       "3            Pre-Training by Completing Point Clouds   \n",
       "4  GamePad: A Learning Environment for Theorem Pr...   \n",
       "\n",
       "                                         url  \\\n",
       "0  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "1  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "2  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "3  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "4   https://openreview.net/pdf?id=r1xwKoR9Y7   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  There has recently been a flurry of exciting a...   \n",
       "1  There has recently been a flurry of exciting a...   \n",
       "2  There has recently been a flurry of exciting a...   \n",
       "3  There has recently been a flurry of exciting a...   \n",
       "4  In this paper, we introduce a system called Ga...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "1  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "2  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "3  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "4  Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...   \n",
       "\n",
       "                                        review_title  \\\n",
       "0                                         A good one   \n",
       "1  paper shows promising results using point clou...   \n",
       "2              Limited novelty and weak improvements   \n",
       "3  Since the idea itself is simple enough, the re...   \n",
       "4  An intriguing integration of ML and automated ...   \n",
       "\n",
       "                                              review  \\\n",
       "0  This paper proposes a better pre-trained prior...   \n",
       "1  The paper considers the problem of training ne...   \n",
       "2  The authors propose completing an occluded poi...   \n",
       "3  The idea of this paper is simple but fascinati...   \n",
       "4  Summary: This paper mixes automated theorem pr...   \n",
       "\n",
       "                                     rating  \n",
       "0                     7: Good paper, accept  \n",
       "1                     7: Good paper, accept  \n",
       "2     4: Ok but not good enough - rejection  \n",
       "3  5: Marginally below acceptance threshold  \n",
       "4                     7: Good paper, accept  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "toy_data = pd.read_csv(\"../toy_dataset.csv\")\n",
    "# toy_data = pd.read_csv(\"/content/drive/My Drive//CIS6200/toy_dataset.csv\")\n",
    "toy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GCFzb1N49H8r"
   },
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "def send_prompt(prompt):\n",
    "  response = client.chat.completions.create(\n",
    "      messages=[\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": prompt,\n",
    "          }\n",
    "      ],\n",
    "      # model=\"gpt-4-0125-preview\",\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      temperature=1,\n",
    "  )\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gZt9BEYY87wm"
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a professional machine learning conference reviewer who reviews a given paper and considers 4 criteria: **importance and novelty**, **potential reasons for acceptance**, **potential reasons for rejection**, and **suggestions for improvement**.\n",
    "\n",
    "You just need to use the following JSON format for output, but don't output opinions that don't exist in the original reviews. if you're not sure, return an empty dict:\n",
    "\n",
    "{\n",
    "'Significance and novelty': List multiple items by using Dict, The key is a brief description of the item, and the value is a detailed description of the item.\n",
    "\n",
    "'Potential reasons for acceptance': List multiple items by using Dict, The key is a brief description of the item, and the value is a detailed description of the item.\n",
    "\n",
    "\"Potential reasons for rejection\": List multiple items by using Dict, The key is a brief description of the item, and the value is a detailed description of the item.\n",
    "\n",
    "'Suggestions for improvement': List multiple items by using Dict, The key is a brief description of the item, and the value is a detailed description of the item.\n",
    "}\n",
    "\n",
    "The given paper is as follows:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# PROMPT = PromptTemplate(input_variables=[\"input\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "yXxE_pFx_q_7",
    "outputId": "730c1788-409d-4e04-a5f3-48372e2fd483"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'There has recently been a flurry of exciting advances in deep learning models on point clouds. However, these advances have been hampered by the difficulty of creating labelled point cloud datasets: sparse point clouds often have unclear label identities for certain points, while dense point clouds are time-consuming to annotate. Inspired by mask-based pre-training in the natural language processing community, we propose a pre-training mechanism based point clouds completion. It works by masking occluded points that result from observations at different camera views. It then optimizes a completion model that learns how to reconstruct the occluded points, given the partial point cloud. In this way, our method learns a pre-trained representation that can identify the visual constraints inherently embedded in real-world point clouds. We call our method Occlusion Completion (OcCo). We demonstrate that OcCo learns representations that improve the semantic understandings as well as generalization on downstream tasks over prior methods, transfer to different datasets, reduce training time and improve label efficiency.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample\n",
    "\n",
    "paper_abstract = toy_data[\"abstract\"][0]\n",
    "paper_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQR0qqqDAOjm",
    "outputId": "91cef950-d6c6-42b8-a48f-ae377a4fc062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a professional machine learning conference reviewer who reviews a given paper and considers 4 criteria: **importance and novelty**, **potential reasons for acceptance**, **potential reasons for rejection**, and **suggestions for improvement**.\n",
      "\n",
      "You just need to use the following JSON format for output, but don't output opinions that don't exist in the original reviews. if you're not sure, return an empty dict:\n",
      "\n",
      "{\n",
      "'Significance and novelty': List multiple items by using Dict, The key is a brief description of the item, and the value is a detailed description of the item.\n",
      "\n",
      "'Potential reasons for acceptance': List multiple items by using Dict, The key is a brief description of the item, and the value is a detailed description of the item.\n",
      "\n",
      "\"Potential reasons for rejection\": List multiple items by using Dict, The key is a brief description of the item, and the value is a detailed description of the item.\n",
      "\n",
      "'Suggestions for improvement': List multiple items by using Dict, The key is a brief description of the item, and the value is a detailed description of the item.\n",
      "}\n",
      "\n",
      "The given paper is as follows:\n",
      "\n",
      "There has recently been a flurry of exciting advances in deep learning models on point clouds. However, these advances have been hampered by the difficulty of creating labelled point cloud datasets: sparse point clouds often have unclear label identities for certain points, while dense point clouds are time-consuming to annotate. Inspired by mask-based pre-training in the natural language processing community, we propose a pre-training mechanism based point clouds completion. It works by masking occluded points that result from observations at different camera views. It then optimizes a completion model that learns how to reconstruct the occluded points, given the partial point cloud. In this way, our method learns a pre-trained representation that can identify the visual constraints inherently embedded in real-world point clouds. We call our method Occlusion Completion (OcCo). We demonstrate that OcCo learns representations that improve the semantic understandings as well as generalization on downstream tasks over prior methods, transfer to different datasets, reduce training time and improve label efficiency.\n"
     ]
    }
   ],
   "source": [
    "prompt = template + paper_abstract\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3GZUB1t9NJd",
    "outputId": "9487e060-e807-490d-b9ae-814759094054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"Significance and novelty\": {\n",
      "\"Mask-based pre-training\": \"The use of mask-based pre-training in the context of point clouds is a novel approach that draws inspiration from the natural language processing community.\",\n",
      "\"Occlusion Completion (OcCo)\": \"The proposal of OcCo as a method for pre-training on point clouds through completion of occluded points is a unique and innovative contribution to the field.\"\n",
      "},\n",
      "\"Potential reasons for acceptance\": {\n",
      "\"Increased semantic understanding\": \"The paper demonstrates that the proposed method improves semantic understanding of point clouds compared to previous techniques.\",\n",
      "\"Generalization on downstream tasks\": \"The method shows improved generalization on downstream tasks, which is a crucial aspect of any machine learning model.\"\n",
      "},\n",
      "\"Potential reasons for rejection\": {},\n",
      "\"Suggestions for improvement\": {\n",
      "\"Experimental validation\": \"Providing more thorough experimental validation on a wider range of datasets could strengthen the paper's claims and results.\",\n",
      "\"Comparison with existing methods\": \"Including a more detailed comparison with existing methods in the field would help in understanding the effectiveness and uniqueness of the proposed approach.\"\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = send_prompt(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8_wFHbCiA6ws"
   },
   "outputs": [],
   "source": [
    "def get_gpt_response(paper_abstract):\n",
    "  prompt = template + paper_abstract\n",
    "  response = send_prompt(prompt)\n",
    "  return response\n",
    "\n",
    "toy_data[\"gpt-3.5-turbo-reviews\"] = toy_data[\"abstract\"].apply(get_gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "Woy4J5hpCQqH",
    "outputId": "5b4aa6f0-00a0-4ec0-cf5d-c03109a1811c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"toy_data\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Pre-Training by Completing Point Clouds\",\n          \"GamePad: A Learning Environment for Theorem Proving\",\n          \"C-Learning: Learning to Achieve Goals via Recursive Classification\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"https://openreview.net/pdf?id=jPSYH47QSZL\",\n          \"https://openreview.net/pdf?id=r1xwKoR9Y7\",\n          \"https://openreview.net/pdf?id=tc5qisoB-C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"There has recently been a flurry of exciting advances in deep learning models on point clouds. However, these advances have been hampered by the difficulty of creating labelled point cloud datasets: sparse point clouds often have unclear label identities for certain points, while dense point clouds are time-consuming to annotate. Inspired by mask-based pre-training in the natural language processing community, we propose a pre-training mechanism based point clouds completion. It works by masking occluded points that result from observations at different camera views. It then optimizes a completion model that learns how to reconstruct the occluded points, given the partial point cloud. In this way, our method learns a pre-trained representation that can identify the visual constraints inherently embedded in real-world point clouds. We call our method Occlusion Completion (OcCo). We demonstrate that OcCo learns representations that improve the semantic understandings as well as generalization on downstream tasks over prior methods, transfer to different datasets, reduce training time and improve label efficiency.\",\n          \"In this paper, we introduce a system called GamePad that can be used to explore the application of machine learning methods to theorem proving in the Coq proof assistant. Interactive theorem provers such as Coq enable users to construct machine-checkable proofs in a step-by-step manner. Hence, they provide an opportunity to explore theorem proving with human supervision. We use GamePad to synthesize proofs for a simple algebraic rewrite problem and train baseline models for a formalization of the Feit-Thompson theorem. We address position evaluation (i.e., predict the number of proof steps left) and tactic prediction (i.e., predict the next proof step) tasks, which arise naturally in tactic-based theorem proving.\",\n          \"We study the problem of predicting and controlling the future state distribution of an autonomous agent. This problem, which can be viewed as a reframing of goal-conditioned reinforcement learning (RL), is centered around learning a conditional probability density function over future states. Instead of directly estimating this density function, we indirectly estimate this density function by training a classifier to predict whether an observation comes from the future. Via Bayes' rule, predictions from our classifier can be transformed into predictions over future states. Importantly, an off-policy variant of our algorithm allows us to predict the future state distribution of a new policy, without collecting new experience. This variant allows us to optimize functionals of a policy's future state distribution, such as the density of reaching a particular goal state. While conceptually similar to Q-learning, our work lays a principled foundation for goal-conditioned RL as density estimation, providing justification for goal-conditioned methods used in prior work. This foundation makes hypotheses about Q-learning, including the optimal goal-sampling ratio, which we confirm experimentally. Moreover, our proposed method is competitive with prior goal-conditioned RL methods.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,Matt Kusner\",\n          \"Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya Sutskever\",\n          \"Benjamin Eysenbach,Ruslan Salakhutdinov,Sergey Levine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"A good one\",\n          \"Official Blind Review #5\",\n          \"Interesting and relevant to UOM paper but relevance and connection is not discussed. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"This paper proposes a better pre-trained prior for a variety of downstream applications in point cloud analysis. The workflow of the pre-training mechanism is to first 1) generate occluded points that result from view occlusion and then 2) optimize the encoder to learn how to complete the occluded points from the partial point cloud. In downstream applications, the obtained encoder will be used as the initial weights in the network training. Empirical experiments have shown that such a pre-train mechanism can improve initialization over prior baselines and benefit a variety of tasks even with a large domain gap.\\r\\n\\r\\nPros:\\r\\n1. The experimental results have shown a steady improvement in performance by using the proposed pre-training approach in different encoder architectures and different downstream applications. That provides strong support for validating the effectiveness of the proposed approach.\\r\\n2. I also like the result that the initialization is only pre-trained on the occlusions generated from the ModelNet40 but still work in another dataset. And yet, the pre-training is done in a self-supervised manner. This is a great plus for this approach as it indicates that it could be a general-purpose booster for a wide range of applications without spending too much effort in collecting special-purpose dataset for pre-training. \\r\\n3. The paper is well written and presented.\\r\\n\\r\\nCons:\\r\\n1. The improvement, as shown in the statistics, is very incremental in most cases. I understand it is difficult to achieve better results on well-established benchmarks, but it somehow indicates the improvement is limited.\\r\\n2. Though the paper already stated some nice explanation of the idea behind this approach, I would appreciate it if a more in-depth analysis of why such a pre-training mechanism could work is provided. Specifically, I would like more analysis of why such a pre-training method can adapt to different datasets? What are the common features that OcCo captures across different datasets? \\r\\nSome visualization similar to Figure 3 would be helpful.\\r\\n\\r\\n---- Final Rating ----\\r\\n\\r\\nThe authors' response has resolved my concerns. I would keep my positive rating.\",\n          \"Summary:\\r\\n\\r\\nThis paper introduces PERIL, a meta RL method that combines demonstration trajectories and trajectories collected by the policy, in order to adapt to a new task. To this end, the authors combine ideas from metaRL (specifically from PEARL (Rakelly et al. 2019) and Humplik et al (2019)) where a set encoder is used to encode trajectories to a latent vector describing the task, with imitation learning techniques by (a) training this encoder also with demonstrations (b) initialising the latent vector at test time by feeding demonstrations through the encoder, and (c) having additional losses inspired by metaIL techniques. The motivation is that using demonstrations allows us to learn tasks that are difficult otherwise, for example because the rewards (at test time) are sparse. \\r\\n\\r\\nOverall impression:\\r\\n\\r\\nI like the idea of using demonstrations for metaRL when tasks are sparse. Many metaRL methods do not work well in sparse reward tasks, and using expert demonstrations is a nice way of guiding the agent towards behaviour that can solve the task. Empirically, the proposed method PERIL outperforms the baselines PEARL and MetaIL, so that is promising. The authors provide analysis of the latent space which nicely illustrates what the method has learned. However, PERIL is quite complex since it consists of many different parts and loss terms (six if I counted correctly), and it needs demonstrations + interactions + (sparse) reward signals at test time. I found it hard to keep track of everything and make sense of how these parts fit together. From both the text and the empirical results, it is not clear to me why all the parts are necessary / what they do, and I am left wondering if a simpler approach would work as well. The notation and mathematical formulation in the paper is not polished enough (there are inconsistencies, variable name clashes, some parts of the objective function not properly introduced and explained) which added to my confusion. Therefore, even though the idea seems promising, I think the paper is not quite ready for publication.\\r\\n\\r\\nQuestions:\\r\\n- In the introduction you say that MetaIL methods have the drawback that \\\"after adaptation, they cannot continue to improve the policy in the way that RL methods can\\\". You say that you method PERIL \\\"allows for continual policy improvement through further exploration of the task\\\". I have a few questions about this.\\r\\n - Since only the latent embedding is updated, doesn't PERIL also suffer from the fact that the policy cannot be improved in the way that RL methods can (but instead, all adaptation is that within the limits of task inference)? \\r\\n - Why is additional exploration at test time even necessary, if we have expert rollouts and the policy itself isn't actually updated (the only thing that's adapted at test time is the latent embedding)? If all the demos + trajectories are used for is task inference, then shouldn't the expert demos always be sufficient?\\r\\n - You motivate your approach by saying that at test time, it is useful if the expert does not have to provide a shaped reward. However, you do make use of a shaped reward during training - this is a limitation that should be discussed in the paper. In addition, you still need (sparse) rewards at test time. Are those really necessary, given that you have a demonstration of the task? Did you test PERIL without those sparse reward inputs to the encoder?\\r\\n- Table 1, how was the agent trained? Was it with number of adaptation trajectories k>0? If so, what if you would train the agent with k=0? On the other hand, can you get good zero-shot adaptation performance by just increasing the number of demonstrations? \\r\\n- You say $d_\\\\lambda$ is a VAE, but if I understand your setup correctly then $d_\\\\lambda$ is only the decoder of a VAE right? And Eq 8 is the reconstruction loss? Which also means it's not technically a VAE, because in encodes and decodes different things (encodes trajectories, decodes task descriptors - Humplik et al. 2019 describe this as an information bottleneck). Shouldn't there also be a KL term somewhere here?\\r\\n- Where is $L_{bc}$ used? It's not part of Eq (7), but I also can't find it anywhere else except in Algo 1 and Fig 2. And what about $L_{mi}$, it's only in Algo 1 but nowhere else? Fig 2 has $L_{KL}$, where is that from? It would really help my understanding of piecing everything together if there was one single equation somewhere, that includes all loss terms. For each loss term, I as the reader want to clearly understand where it comes from, and why it is necessary (see suggestions for additional baselines/ablations below).\\r\\n\\r\\nSuggestions / Feedback:\\r\\n- The problem formulation and the proposed solution don't match. In your problem setting you say you're in a general POMDP where the true state may be partially observed, but in your algorithm you rely on the fact that it's a POMDP only w.r.t. the task (i.e., reward and transition function) and *not* w.r.t. the environment state. That's an important difference! To explain that in more detail: in the introduction and problem setting you say $z$ models the true underlying state $s$ which can change at any moment: your transition function is $p(o',z'|o,a,z)$ where $o$ are observations. However, the entire formulation in your algorithm relies on the fact that $z$ does _not_ change over time, but instead describes a fixed task. That's also what PEARL does, which is what your formulation is based on. I think there's two ways to resolve this: (A) Either change the problem setting such that $z$ is fixed throughout time and define the transition function as $p(s'|s,a,z)$ where the environment state $s$ is now fully observable, or (B) change the algorithm to actually model a belief over a latent $z$ that can change over time. Option (A) is probably an easier fix, but then you might also have to change some of the environments (if I understand correctly, in Key2D the state of the handle is unobserved and can change the unobserved environment state).\\r\\n- Section 3.1, I would add explicitly what the objective of the policy is (both in writing and in a mathematical expression). You aim to maximise the return of a policy that conditions on $K_d$ demonstrations, and which has interacted with the environment for $K_r$ rollouts (changing the notation here to make the distinction clear). From there it is easy for the reader to see what happens if you set $K_d=0$ (you get something more similar to PEARL), and what happens when you set $K_r=0$ (which is the zero-shot case). It's good to contrast this for the reader, and explain / show empirically why and when $K_d>0$ and $K_r>0$ is necessary. (See my comment on baselines below.) \\r\\n- To understand PERIL better, I would suggest to add a few baselines. \\r\\n - PEARL with a pre-initialised buffer that contains the demonstrations. The encoder and policy will be trained as normal, but there's additional data coming from the buffer that contains expert trajectories. Since PEARL uses an off-policy algorithm it is possible to train the policy with this data. I think this is an important comparison, because it's a very simple way to incorporate demonstrations into PEARL and it would be good to understand if/when/why this works/doesn't work.\\r\\n - In addition to the above, use the demonstrations at test time to initialise the context in PEARL. This is very close to the setting in PERIL, except that some parts of the objective function are missing ($L_{info}$, $L_{aux}$, $L_{bc}$, $L_{mi}$ - I think).  This would give insight into whether those additional losses are truly necessary (currently you only have ablations on $L_{aux}$).\\r\\n - Zero-Shot PERIL. There is some analysis of this in Table 1, but I think it would still be helpful to add this baseline. Does it work well for within-task-distribution adaptation (Fig 4) and not so well for settings that require more generalisation (Fig 5)? What if we just throw in more demonstrations, is that sufficient to do zero-shot adaptation or do we really need the policy rollouts? I think this is a central question that should be very clearly answered in the paper. Table 1 is a good start but this analysis can be expanded.\\r\\n - Humplik et al. (2019), but with additional demonstration data to train the encoder/decoder. Again, this is the simplest way to incorporate the demonstration data into this method without explicitly making use of it at test time. This comparison would tell us something about why the demonstrations are necessary - are they necessary during training but not at test time, or the other way around, or are they necessary both during training and testing?\\r\\n - Not sure I got everything, there's still $L_{bc}$ and $L_{mi}$ which I'm not entirely sure where they come from and if they are necessary. But basically, I think it's really important to analyse which parts are necessary - and make the method as simple as possible if you find some parts are not necessary.\\r\\n\\r\\nSmaller comments (didn't influence my score):\\r\\n- There's a clash between using the variable k/K for the demonstrations (e.g., Sec 3.1 \\\"primal inference\\\", Sec 4.1 first sentence, Fig 7), and for the number of policy rollouts (e.g., algorithm 1 line 5, Table 1). This is confusing, so I strongly suggest using two distinct variable names (something like $k_d$ and $k_r$ also works).\\r\\n- Similarly it would help if you use two separate notations for the trajectories $\\\\tau$ that come from the demonstrations, and the ones that come from the policy. Throughout Section 3 I don't always understand which one of the two you are talking about.\\r\\n- Your references need fixing. Some of them are without a year, and some say technical report even though they were published at a conference (e.g. Finn et al., Rakelly et al.). Your \\\"Wang\\\" reference for RL2 also seems wrong (first sentence in related work)? It should be Jane Wang et al. \\\"Learning to reinforcement learn\\\". The way I always get my bibtex entries is via scholar.google.com: search for the paper there; click on the \\\"cite\\\" button under it and then \\\"BibTeX\\\" (Double check whether the paper was published somewhere though, google scholar often only puts the arXiv link then actually the paper was published somewhere. Sometimes the authors also put the correct bibtex comment on their homepage/github with the code).\\r\\n- Fig 1 left, there's a typo: \\\"learn to lean\\\" -> \\\"learn to learn\\\"\\r\\n- For your experiments, I would call PERIL-A only \\\"PERIL\\\" (since this is your full method, including all losses), and then call the *ablations* different, so for example PERIL-noAux when you remove the auxiliary loss.\\r\\n- All figures should have some form of indication of the error/std/confidence interval (using shaded regions around the mean for example).\\r\\n- Sec 4.2, explain what the multi-task family setting is and why it is challenging. \\r\\n\",\n          \"This paper attempts to explain the generalization in a deep network using separability of the features at various layers. The paper is motivated via a perceptron classifying a Gaussian distribution.\\r\\n\\r\\nOverall, I think the experimental evidence in the paper is not rigorous enough to draw the conclusions that the authors wish to draw. The paper will benefit from more careful experiments, I am listing down some suggestions below.\\r\\n\\r\\nWhat is the connection between the result in Section 2 with those in Section 3? What is the variance on the plots in Fig. 2?\\r\\nOn lines 103-110, max-pooling should reduce variability because it collapses spatial variability in the input. I think there is confounding occurring here due to the presence of batch-norm which (at least in theory) de-correlates the features. De-correlated features are easier to separate using a linear classifier. Further, the features of well-performing deep networks are not easily separable, e.g., https://arxiv.org/abs/1902.01889.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"4: Ok but not good enough - rejection\",\n          \"3: Clear rejection\",\n          \"7: Good paper, accept\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gpt-3.5-turbo-reviews\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"{\\n    \\\"Significance and novelty\\\": {\\n        \\\"Introduction of mask-based pre-training for point clouds\\\": \\\"The paper introduces a novel pre-training mechanism based on mask-based pre-training, inspired by natural language processing techniques, for point clouds which is a unique contribution in the field.\\\",\\n        \\\"OcCo method for point cloud completion\\\": \\\"The proposed Occlusion Completion (OcCo) method is innovative and aims to address the challenges of label inefficiency and time-consuming annotation by learning representations through point cloud completion.\\\"\\n    },\\n    \\\"Potential reasons for acceptance\\\": {\\n        \\\"Innovative approach\\\": \\\"The paper presents a novel approach for pre-training point cloud models using occlusion completion, which can potentially lead to significant advancements in the field.\\\",\\n        \\\"Improved semantic understanding and generalization\\\": \\\"The OcCo method demonstrates improved semantic understandings and generalization on downstream tasks compared to prior methods, showcasing its potential for acceptance.\\\"\\n    },\\n    \\\"Potential reasons for rejection\\\": {\\n        \\\"Lack of comparative analysis\\\": \\\"The paper should provide a more detailed comparative analysis with existing methods in the field to further validate the effectiveness of the OcCo method.\\\",\\n        \\\"Limited experimental results\\\": \\\"More extensive experimental results and evaluation on various datasets are needed to fully demonstrate the effectiveness of the proposed method.\\\"\\n    },\\n    \\\"Suggestions for improvement\\\": {\\n        \\\"Comparative analysis\\\": \\\"Include a more comprehensive comparative analysis with existing methods to highlight the advantages of the OcCo method.\\\",\\n        \\\"Additional experiments\\\": \\\"Conduct additional experiments on different datasets and scenarios to provide a deeper evaluation of the proposed method.\\\"\\n    }\\n}\",\n          \"{\\n\\\"Significance and novelty\\\": {\\n    \\\"Combining imitation learning with meta reinforcement learning (meta-RL)\\\": \\\"Introducing a method, PERIL, that combines imitation learning with meta-RL to improve adaptation rates in unseen tasks.\\\",\\n    \\\"Dual inference strategies for exploration policies\\\": \\\"Using dual inference strategies in PERIL to precondition exploration policies on demonstrations, enhancing adaptation rates.\\\",\\n    \\\"Robustness to task alterations and uncertainties\\\": \\\"Contrasting with pure imitation learning, PERIL is capable of exploring beyond demonstrations, making it robust to task alterations and uncertainties.\\\",\\n    \\\"Interpolating from previously learned dynamics\\\": \\\"Showing how PERIL can adapt to unseen tasks and task families by interpolating from within previously learnt dynamics under sparse rewards.\\\"\\n},\\n\\n\\\"Potential reasons for acceptance\\\": {\\n    \\\"Innovative approach\\\": \\\"Introducing a new method, PERIL, which combines imitation learning and meta-RL to improve adaptation to new tasks.\\\",\\n    \\\"Demonstrated improvement in adaptation rates\\\": \\\"Showing that PERIL improves adaptation rates in unseen tasks by preconditioning exploration policies on demonstrations.\\\",\\n    \\\"Robustness and flexibility\\\": \\\"Highlighting the robustness of PERIL to task alterations and uncertainties, as well as its flexibility in adapting to unseen tasks and task families.\\\"\\n},\\n\\n\\\"Potential reasons for rejection\\\": {\\n    \\\"Lack of empirical evaluation\\\": \\\"The paper may be rejected if it lacks thorough empirical evaluation of the proposed method PERIL.\\\",\\n    \\\"Limited comparison with existing methods\\\": \\\"There may be grounds for rejection if the paper does not provide adequate comparison with existing methods in the field.\\\",\\n    \\\"Unclear implementation details\\\": \\\"Insufficient details on the implementation of PERIL could lead to rejection.\\\"\\n},\\n\\n\\\"Suggestions for improvement\\\": {\\n    \\\"Include more empirical results\\\": \\\"Adding more empirical results and experiments to further validate the performance of PERIL.\\\",\\n    \\\"Perform a comprehensive comparison\\\": \\\"Conducting a thorough comparison with existing methods to demonstrate the advantages of PERIL.\\\",\\n    \\\"Provide more implementation details\\\": \\\"Offering more detailed information on the implementation of PERIL to aid reproducibility.\\\"\\n}\\n}\",\n          \"{\\n\\\"Significance and novelty\\\": {\\n    \\\"Consideration of data geometry for generalization\\\": \\\"The paper proposes considering the geometry of data to better explain generalization achieved in deep learning, which is a novel approach.\\\",\\n    \\\"Linear separability in high dimensions\\\": \\\"The paper shows that the separability of data can explain generalization in high dimensions, which is an important finding.\\\",\\n    \\\"Sequential increase in linear separability within CNNs\\\": \\\"The paper demonstrates how layers within CNNs sequentially increase the linear separability of data, which is a significant contribution.\\\"\\n},\\n\\n\\\"Potential reasons for acceptance\\\": {\\n    \\\"Innovative approach\\\": \\\"The paper takes an innovative approach by focusing on data geometry for explaining generalization in deep learning.\\\",\\n    \\\"Relevance to current deep learning research\\\": \\\"The findings on linear separability and CNN layers are relevant and contribute to the current understanding of deep learning models.\\\",\\n    \\\"Clear presentation of results\\\": \\\"The paper presents the results on data separability and CNN layers clearly, making it easy to follow and understand.\\\"\\n},\\n\\n\\\"Potential reasons for rejection\\\": {},\\n\\n\\\"Suggestions for improvement\\\": {\\n    \\\"Comparison with existing methods\\\": \\\"It would be beneficial to compare the proposed approach with existing methods for explaining generalization in deep learning.\\\",\\n    \\\"Additional experiments\\\": \\\"Including more experiments to further validate the findings on data separability and CNN layers would strengthen the paper's conclusions.\\\"\\n}\\n}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "toy_data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-2a7ab963-4a86-4314-9828-a73aab9d9d2e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>gpt-3.5-turbo-reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>A good one</td>\n",
       "      <td>This paper proposes a better pre-trained prior...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "      <td>{\\n    \"Significance and novelty\": {\\n        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>paper shows promising results using point clou...</td>\n",
       "      <td>The paper considers the problem of training ne...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "      <td>{\\n\"Significance and novelty\": {\\n    \"Use of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>Limited novelty and weak improvements</td>\n",
       "      <td>The authors propose completing an occluded poi...</td>\n",
       "      <td>4: Ok but not good enough - rejection</td>\n",
       "      <td>{\\n    \"Significance and novelty\": {\\n        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>Since the idea itself is simple enough, the re...</td>\n",
       "      <td>The idea of this paper is simple but fascinati...</td>\n",
       "      <td>5: Marginally below acceptance threshold</td>\n",
       "      <td>{\\n\"Significance and novelty\": {\\n    \"Mask-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GamePad: A Learning Environment for Theorem Pr...</td>\n",
       "      <td>https://openreview.net/pdf?id=r1xwKoR9Y7</td>\n",
       "      <td>In this paper, we introduce a system called Ga...</td>\n",
       "      <td>Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...</td>\n",
       "      <td>An intriguing integration of ML and automated ...</td>\n",
       "      <td>Summary: This paper mixes automated theorem pr...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Explo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a7ab963-4a86-4314-9828-a73aab9d9d2e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-2a7ab963-4a86-4314-9828-a73aab9d9d2e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-2a7ab963-4a86-4314-9828-a73aab9d9d2e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-6ad7279b-4cfb-4377-87f7-17e08cd8141c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ad7279b-4cfb-4377-87f7-17e08cd8141c')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-6ad7279b-4cfb-4377-87f7-17e08cd8141c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0            Pre-Training by Completing Point Clouds   \n",
       "1            Pre-Training by Completing Point Clouds   \n",
       "2            Pre-Training by Completing Point Clouds   \n",
       "3            Pre-Training by Completing Point Clouds   \n",
       "4  GamePad: A Learning Environment for Theorem Pr...   \n",
       "\n",
       "                                         url  \\\n",
       "0  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "1  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "2  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "3  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "4   https://openreview.net/pdf?id=r1xwKoR9Y7   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  There has recently been a flurry of exciting a...   \n",
       "1  There has recently been a flurry of exciting a...   \n",
       "2  There has recently been a flurry of exciting a...   \n",
       "3  There has recently been a flurry of exciting a...   \n",
       "4  In this paper, we introduce a system called Ga...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "1  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "2  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "3  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "4  Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...   \n",
       "\n",
       "                                        review_title  \\\n",
       "0                                         A good one   \n",
       "1  paper shows promising results using point clou...   \n",
       "2              Limited novelty and weak improvements   \n",
       "3  Since the idea itself is simple enough, the re...   \n",
       "4  An intriguing integration of ML and automated ...   \n",
       "\n",
       "                                              review  \\\n",
       "0  This paper proposes a better pre-trained prior...   \n",
       "1  The paper considers the problem of training ne...   \n",
       "2  The authors propose completing an occluded poi...   \n",
       "3  The idea of this paper is simple but fascinati...   \n",
       "4  Summary: This paper mixes automated theorem pr...   \n",
       "\n",
       "                                     rating  \\\n",
       "0                     7: Good paper, accept   \n",
       "1                     7: Good paper, accept   \n",
       "2     4: Ok but not good enough - rejection   \n",
       "3  5: Marginally below acceptance threshold   \n",
       "4                     7: Good paper, accept   \n",
       "\n",
       "                               gpt-3.5-turbo-reviews  \n",
       "0  {\\n    \"Significance and novelty\": {\\n        ...  \n",
       "1  {\\n\"Significance and novelty\": {\\n    \"Use of ...  \n",
       "2  {\\n    \"Significance and novelty\": {\\n        ...  \n",
       "3  {\\n\"Significance and novelty\": {\\n    \"Mask-ba...  \n",
       "4  {\\n  \"Significance and novelty\": {\\n    \"Explo...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "kuszM0GlC85o"
   },
   "outputs": [],
   "source": [
    "csv_file_path = '/content/toy_data_w_gpt_reviews.csv'  # Define your file path here\n",
    "toy_data.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ZhjPLsPJDEux",
    "outputId": "1acbd218-b23b-4e85-f4b5-088317045683"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_d922e6c8-2aa4-43d2-9998-9d61798e726b\", \"toy_data_w_gpt_reviews.csv\", 135719)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Article Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_data_w_gpt_reviews = pd.read_csv(\"../toy_data_w_gpt_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     https://openreview.net/pdf?id=jPSYH47QSZL\n",
       "1     https://openreview.net/pdf?id=jPSYH47QSZL\n",
       "2     https://openreview.net/pdf?id=jPSYH47QSZL\n",
       "3     https://openreview.net/pdf?id=jPSYH47QSZL\n",
       "4      https://openreview.net/pdf?id=r1xwKoR9Y7\n",
       "5      https://openreview.net/pdf?id=r1xwKoR9Y7\n",
       "6      https://openreview.net/pdf?id=r1xwKoR9Y7\n",
       "7     https://openreview.net/pdf?id=4NtqESjOIAz\n",
       "8     https://openreview.net/pdf?id=4NtqESjOIAz\n",
       "9     https://openreview.net/pdf?id=XDo0go2IJgT\n",
       "10     https://openreview.net/pdf?id=BIIwfP55pp\n",
       "11     https://openreview.net/pdf?id=BIIwfP55pp\n",
       "12     https://openreview.net/pdf?id=BIIwfP55pp\n",
       "13     https://openreview.net/pdf?id=BIIwfP55pp\n",
       "14     https://openreview.net/pdf?id=tc5qisoB-C\n",
       "15     https://openreview.net/pdf?id=tc5qisoB-C\n",
       "16     https://openreview.net/pdf?id=tc5qisoB-C\n",
       "17     https://openreview.net/pdf?id=tc5qisoB-C\n",
       "18     https://openreview.net/pdf?id=tc5qisoB-C\n",
       "19     https://openreview.net/pdf?id=Byl3K2VtwB\n",
       "20     https://openreview.net/pdf?id=Byl3K2VtwB\n",
       "21     https://openreview.net/pdf?id=Byl3K2VtwB\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data_w_gpt_reviews[\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a professional machine learning conference reviewer who reviews a given paper and considers 4 criteria: **importance and novelty**, **potential reasons for acceptance**, **potential reasons for rejection**, and **suggestions for improvement**.\n",
    "\n",
    "You just need to use the following JSON format for output, but don't output opinions that don't exist in the original reviews. if you're not sure, return an empty dict:\n",
    "\n",
    "{\n",
    "'Significance and novelty': List multiple items by using Dict, The key is a brief description of the item, and the value is a detailed description of the item.\n",
    "\n",
    "'Potential reasons for acceptance': List multiple items by using Dict, The key is a brief description of the item, and the value is a detailed description of the item.\n",
    "\n",
    "\"Potential reasons for rejection\": List multiple items by using Dict, The key is a brief description of the item, and the value is a detailed description of the item.\n",
    "\n",
    "'Suggestions for improvement': List multiple items by using Dict, The key is a brief description of the item, and the value is a detailed description of the item.\n",
    "}\n",
    "\n",
    "The given paper is as follows:\n",
    "{input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy0_3_gpt_responses = [\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Introduction of Occlusion Completion (OcCo) for point cloud pre-training\": \"The paper introduces a novel pre-training method named Occlusion Completion (OcCo), which enhances point cloud models by learning to reconstruct occluded parts of point clouds. This approach is inspired by mask-based pre-training in natural language processing and adapts it innovatively for 3D point cloud data. The novelty lies in using occlusion as a mechanism for pre-training, aiming to improve semantic understandings and generalization on downstream tasks.\",\n",
    "    \"Leveraging occluded point clouds for learning structural information\": \"The method uniquely leverages the natural occurrence of occlusions in point clouds obtained from different camera viewpoints to generate occluded point clouds. This approach forces the model to learn structural and contextual information about the objects, which is a novel strategy for pre-training point cloud models.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Demonstrated improvements over existing methods\": \"OcCo shows significant improvements over prior methods in various downstream tasks such as object classification, part segmentation, and semantic segmentation. These improvements are quantitatively demonstrated through comprehensive experiments.\",\n",
    "    \"Extensive experimental validation\": \"The paper provides extensive experimental results validating the effectiveness of OcCo pre-training across multiple benchmarks and settings. This includes few-shot learning scenarios and different levels of label availability, showcasing the method's versatility and robustness.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Lack of theoretical analysis\": \"The paper primarily focuses on empirical results and may lack a detailed theoretical analysis explaining why OcCo pre-training leads to better generalization and performance on downstream tasks.\",\n",
    "    \"Comparison with very recent or concurrent works\": \"Depending on the timing and scope of the review, the paper might not compare its approach against the very latest or concurrent works in point cloud processing, which could be seen as a limitation.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Provide more theoretical insights\": \"Enhancing the paper with theoretical insights or analysis on why OcCo pre-training is effective could strengthen the paper. This could include discussions on the nature of occlusions in point clouds and their role in learning robust features.\",\n",
    "    \"Expand comparisons to include more recent methods\": \"Updating the experimental comparisons to include more recent or concurrent works in point cloud pre-training and completion could provide a clearer picture of OcCo's standing in the field.\",\n",
    "    \"Explore limitations and future work\": \"A more detailed discussion on the limitations of the proposed method and potential directions for future work could provide readers with insights into the method's applicability and areas for improvement.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Introduction of Occlusion Completion (OcCo) mechanism\": \"The paper proposes a novel pre-training mechanism, Occlusion Completion (OcCo), which innovatively uses the natural occurrence of occlusions in point clouds to generate training data. This mechanism helps in learning robust representations that improve semantic understanding and generalization on downstream tasks.\",\n",
    "    \"Advances in handling sparse and dense point clouds\": \"By addressing the challenges in annotating point clouds due to their sparsity or density, the paper introduces an approach that potentially reduces the need for extensive labeled datasets. This approach is significant for advancing point cloud processing techniques.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Comprehensive experimental validation\": \"The paper presents extensive experiments demonstrating the effectiveness of OcCo across multiple benchmarks and tasks, including object classification, part segmentation, and semantic segmentation, showing improvements over existing methods.\",\n",
    "    \"Insightful analysis on learned representations\": \"Through various analyses, including feature visualization and concept detection, the paper provides deep insights into what the pre-trained model learns, highlighting the method's capability to capture useful geometric and semantic information from point clouds.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Limited theoretical underpinning\": \"The paper's strong empirical results might be seen as lacking a robust theoretical framework explaining why OcCo works effectively, which could be a point of critique.\",\n",
    "    \"Comparison with state-of-the-art methods\": \"Although the paper compares OcCo with existing methods, the rapidly evolving nature of the field might require further comparison with more recent or concurrent works to fully establish its position.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Enhanced theoretical explanation\": \"Providing a more detailed theoretical analysis or justification for the effectiveness of OcCo could strengthen the paper, offering insights into how and why occlusion-based pre-training aids in learning robust point cloud representations.\",\n",
    "    \"Extended comparisons and benchmarks\": \"Expanding the experimental comparisons to include the latest methods in point cloud processing could further validate OcCo's effectiveness. Additionally, exploring its applicability to more varied and challenging datasets could showcase its adaptability and robustness.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Novel pre-training mechanism\": \"The paper introduces Occlusion Completion (OcCo), a novel pre-training mechanism for point cloud models, addressing the challenge of sparse and dense point clouds by learning to reconstruct occluded parts.\",\n",
    "    \"Enhanced semantic understanding and generalization\": \"OcCo is shown to enhance semantic understandings and generalization on downstream tasks, offering significant contributions over prior methods by using occlusions naturally occurring in point clouds.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Comprehensive experiments and benchmarks\": \"Extensive experimental validation demonstrates the effectiveness of OcCo across multiple benchmarks, including object classification, part segmentation, and semantic segmentation, showing improvements over existing methods.\",\n",
    "    \"Innovative approach to learning from occlusions\": \"The approach to generate occluded point clouds and learning a completion model to reconstruct them provides a fresh perspective on pre-training, potentially inspiring future research in point cloud processing.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Lack of theoretical foundation\": \"The paper could face criticism for not providing a solid theoretical foundation explaining the effectiveness of OcCo, potentially leaving some questions unanswered regarding the underlying principles.\",\n",
    "    \"Limited comparison with recent methods\": \"Given the rapid advancements in point cloud processing, the paper might be critiqued for not including comparisons with the most recent or concurrent methods in the field.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Strengthen theoretical explanations\": \"Incorporating more detailed theoretical analysis or insights could help in understanding why OcCo outperforms other pre-training methods, providing a stronger foundation for the proposed approach.\",\n",
    "    \"Expand experimental comparisons\": \"Broadening the scope of experimental comparisons to include more recent and varied methods could help in establishing OcCo's position more firmly within the current research landscape.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Innovative pre-training approach\": \"The paper introduces Occlusion Completion (OcCo), a novel pre-training method for point cloud models, which enhances model performance by learning to reconstruct occluded parts of point clouds. This approach is inspired by mask-based pre-training in NLP and uniquely adapted for 3D point cloud data, addressing the challenge of sparse and dense point clouds.\",\n",
    "    \"Enhancement in semantic understanding and generalization\": \"OcCo demonstrates significant advancements in improving semantic understandings and generalization across various downstream tasks including object classification, part segmentation, and semantic segmentation, showcasing its ability to transfer to different datasets efficiently.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Comprehensive experimental validation\": \"Extensive experiments across multiple benchmarks and settings validate OcCo's effectiveness, showing improvements over existing methods and highlighting its robustness and versatility in handling point cloud data.\",\n",
    "    \"Insightful analysis and interpretation\": \"The paper provides a thorough analysis of what is learned from OcCo pre-training, using visualizations and probe tests, to offer insights into how the pre-trained model captures useful geometric and semantic information from point clouds.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Lack of theoretical explanation\": \"While the empirical results are strong, the paper might be criticized for not providing a detailed theoretical foundation explaining the effectiveness of OcCo, which could strengthen the paper's claims.\",\n",
    "    \"Limited comparison with state-of-the-art methods\": \"The rapidly evolving field of point cloud processing may have seen new developments since the submission, and the paper could be seen as lacking if it does not include comparisons with the very latest methods.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Strengthen theoretical underpinnings\": \"Enhancing the paper with more detailed theoretical insights or explanations for why OcCo pre-training leads to improved performance on downstream tasks could provide a stronger justification for the approach.\",\n",
    "    \"Broaden comparisons and update benchmarks\": \"Expanding comparisons to include the latest methods in point cloud processing and exploring its applicability to more diverse and challenging datasets could further demonstrate OcCo's effectiveness and adaptability.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "toy4_6_gpt_responses = [\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Introduction of GamePad\": \"GamePad is introduced as a system to explore the application of machine learning methods to theorem proving in the Coq proof assistant. It provides a structured Python representation of Coq proofs, enabling dynamic proof construction and serving as an environment for reinforcement learning.\",\n",
    "    \"Focus on interactive theorem provers (ITPs)\": \"The work focuses on leveraging ITPs, specifically the Coq proof assistant, for theorem proving with human supervision. This approach is novel in its attempt to bridge the gap between machine learning and human-level proof construction and understanding.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Structured representation of proofs\": \"GamePad offers a detailed and structured representation of Coq proofs, including proof states, steps, and expression ASTs, which are crucial for applying machine learning algorithms effectively to theorem proving.\",\n",
    "    \"Exploration of machine learning tasks in theorem proving\": \"The paper addresses essential machine learning tasks within theorem proving, such as position evaluation and tactic prediction, laying the groundwork for future research in applying learning techniques to formal proofs.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Limited scope of evaluation\": \"The evaluation primarily focuses on simple algebraic rewrite problems and the Feit-Thompson formalization. There might be concerns about the system's applicability and performance on a broader range of theorem proving tasks.\",\n",
    "    \"Complexity and accessibility of the environment\": \"While GamePad is a powerful tool, its complexity and the requirement for familiarity with Coq might limit its accessibility to researchers and practitioners not already versed in theorem proving.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Extend evaluations to more diverse problems\": \"Expanding the evaluation to include a wider variety of theorem proving problems could demonstrate the system's versatility and effectiveness across different domains.\",\n",
    "    \"Improve documentation and user-friendliness\": \"Enhancing the documentation and providing more resources for users unfamiliar with Coq could make GamePad more accessible to a broader audience, encouraging adoption and experimentation.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Introduces GamePad\": \"A novel system designed to integrate machine learning with theorem proving within the Coq proof assistant. It aims to bridge the gap between automated and interactive theorem proving by leveraging machine learning for proof synthesis and tactic prediction.\",\n",
    "    \"Focus on ITPs for machine learning application\": \"Pioneering in its focus on utilizing Interactive Theorem Provers (ITPs) for machine learning applications, specifically targeting the Coq proof assistant. This approach opens new avenues for applying deep learning techniques in formal theorem proving.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Structured representation of proofs\": \"GamePad provides a structured Python representation of Coq proofs, including all proof states and steps, which is a significant advancement for integrating machine learning with theorem proving.\",\n",
    "    \"Comprehensive evaluation\": \"The paper conducts a comprehensive evaluation, demonstrating the effectiveness of GamePad in synthesizing proofs for algebraic rewrite problems and applying baseline models for position evaluation and tactic prediction on real-world datasets.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Scope of evaluation\": \"The evaluation primarily focuses on algebraic rewrite problems and the Feit-Thompson formalization. The scope might be perceived as limited in demonstrating the system's capabilities across a broader range of theorem proving tasks.\",\n",
    "    \"Complexity and accessibility\": \"The complexity of setting up and interacting with GamePad, given its reliance on the Coq proof assistant, might pose a barrier to entry for researchers and practitioners not already familiar with theorem proving.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Expand the range of evaluations\": \"Broadening the range of theorem proving problems used in the evaluation could better showcase GamePad's capabilities and its potential impact on the field.\",\n",
    "    \"Improve documentation and user guidance\": \"Enhancing the documentation and providing more comprehensive guides and tutorials could lower the barrier to entry, making GamePad more accessible to a wider audience.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Introduction of GamePad\": \"The paper presents GamePad, a novel system designed to facilitate the application of machine learning techniques to theorem proving within the Coq proof assistant. This integration is significant as it leverages interactive theorem provers (ITPs) to enable machine-checkable proof construction with human supervision, bridging a gap in the automation of theorem proving.\",\n",
    "    \"Focus on Coq proof assistant\": \"GamePad's specific focus on the Coq proof assistant is novel, as Coq is a mature system used for formalizing non-trivial theorems. The system's support for extracting verified software makes it a strategic choice for proving program correctness.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Comprehensive toolset\": \"GamePad provides a structured Python representation of Coq proofs, including proof states, steps, and expression ASTs. This comprehensive toolset facilitates dynamic proof construction and is usable as an environment for reinforcement learning, making it a versatile resource for researchers.\",\n",
    "    \"Empirical validation\": \"The paper demonstrates GamePad's utility through empirical validation, including synthesis of Coq proof scripts for algebraic rewrite problems and application of baseline models for position evaluation and tactic prediction on real-world datasets, showcasing its practical applicability.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Limited scope of evaluation\": \"While GamePad is evaluated on algebraic rewrite problems and the Feit-Thompson formalization, the scope of these evaluations may be seen as limited. Expanding the range of problems and datasets could further validate GamePad's effectiveness and versatility.\",\n",
    "    \"Complexity of setup and use\": \"The initial setup and use of GamePad, particularly its integration with the Coq proof assistant, may present a barrier to entry for some researchers, potentially limiting its broader adoption.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Extend the range of evaluation problems\": \"Broadening the scope of evaluation problems and datasets could help demonstrate GamePad's applicability to a wider range of theorem proving tasks, enhancing its appeal to the research community.\",\n",
    "    \"Improve documentation and user guides\": \"Enhancing the documentation and providing detailed user guides and tutorials could lower the barrier to entry, making GamePad more accessible and encouraging its adoption among researchers not already familiar with Coq.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "toy7_8_gpt_responses = [\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Exploration of data geometry in generalisation\": \"The paper shifts focus from the traditional examination of machine capacity and hypothesis class size to the geometry of data in explaining generalisation performance in machine learning. It posits that data's geometrical properties, particularly in high dimensions, are crucial for understanding generalisation in deep learning models.\",\n",
    "    \"Insight into class separability in high dimensions\": \"The theoretical insights into how class separability affects generalisation, even in high-dimensional spaces, offer a novel perspective. The demonstration that layers within CNNs increase linear separability sequentially is a significant contribution to understanding why deep learning models, especially CNNs, exhibit strong generalisation capabilities.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Theoretical and empirical analysis\": \"The combination of theoretical results on class separation with empirical investigations into CNNs presents a comprehensive study that bridges theory with practical observations. This holistic approach strengthens the paper's contributions and its potential impact on the field.\",\n",
    "    \"Practical implications for CNN architecture design\": \"The findings regarding the role of convolutional and max pooling layers in enhancing data separability could have direct implications on CNN architecture design. These insights could guide the development of more efficient and generalisable deep learning models.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Generalisability of results beyond CNNs\": \"While the paper offers in-depth analysis and findings related to CNNs, its focus is somewhat narrow. The generalisability of the results to other types of deep learning models or to different machine learning paradigms may be questioned.\",\n",
    "    \"Quantitative evaluation and benchmarks\": \"The empirical work, though insightful, might be critiqued for its scope and the choice of datasets. Further quantitative evaluation against established benchmarks or across a broader range of datasets might be needed to fully validate the claims.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Expand empirical analysis\": \"Extending the empirical analysis to include other types of neural networks and machine learning models could help validate the universality of the paper's claims about data geometry and class separability. Such expansion would also enhance the paper's appeal to a broader audience.\",\n",
    "    \"In-depth investigation into other data types\": \"Further investigation into the geometry of class separability across varied data types, beyond image data, could provide additional insights into the model's generalisation capabilities. This could also include exploring different dimensional reduction techniques to visualise and understand data geometry.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Geometry of data in generalization\": \"The paper introduces a novel perspective by emphasizing the importance of the geometry of data, rather than just the capacity of learning models, in explaining the generalization performance in machine learning. This approach could significantly shift the current understanding and methodologies in the field.\",\n",
    "    \"Sequential increase of linear separability in CNNs\": \"It highlights a crucial insight that layers within CNNs sequentially increase the linear separability of data, offering a detailed explanation on the mechanics behind CNNs' ability to generalize well, which is a novel contribution to the understanding of deep learning architectures.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Bridging theoretical insights with empirical validation\": \"The work adeptly combines theoretical analysis on class separation with empirical studies on CNNs, offering a comprehensive look at the problem. This duality ensures the paper's appeal to both theoretical and practical machine learning audiences.\",\n",
    "    \"Practical implications for CNN design and application\": \"The findings regarding the role of convolutional and max pooling layers in enhancing data separability have direct implications on CNN architecture design and application, making the paper highly relevant for current deep learning research and practice.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Limited broader applicability beyond image classification\": \"While the paper offers significant insights into CNNs and image classification, its focus may be perceived as narrow. Extending these findings to other data types or learning models could enhance its impact and address potential concerns about its broader applicability.\",\n",
    "    \"Quantitative benchmarks and comparison\": \"The empirical section could be strengthened by including more rigorous quantitative benchmarks and comparisons with state-of-the-art models. This would help in solidifying the paper’s claims and situating its contributions within the larger body of work.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Expand analysis to other model types and data\": \"Exploring how the proposed insights on data geometry and class separability apply to other types of neural networks and learning models could enhance the paper's contributions and demonstrate the universality of its findings.\",\n",
    "    \"Include more rigorous benchmarks\": \"Incorporating more rigorous benchmarks and comparisons with existing methods could help validate the proposed theories more robustly. This could involve detailed performance analysis on various datasets and against current state-of-the-art models.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "toy9_9_gpt_responses = [\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Introduction of Anomaly Feature Vectors (AFVs)\": \"The paper introduces a novel approach for detecting and classifying adversarial inputs using Anomaly Feature Vectors (AFVs) derived from statistical profiles of latent features. This method not only distinguishes between clean and adversarial inputs but also identifies the types of adversarial attacks, such as PGD or Carlini-Wagner, with high accuracy on CIFAR-10 dataset.\",\n",
    "    \"Advancement in adversarial attack detection and classification\": \"By focusing on the classification of adversarial attack types, the research advances the state of the art in adversarial example research. It moves beyond binary detection to fine-grained classification, opening pathways for attack-specific mitigation strategies.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"High classification accuracy for adversarial attack types\": \"The system achieves close to 93% accuracy in distinguishing among several types of adversarial attacks on the CIFAR-10 dataset, which represents a significant improvement over existing methods that primarily focus on detection without classification.\",\n",
    "    \"Efficient second-stage classifier with small AFV size\": \"The efficiency of the second-stage classifier, which utilizes a small number of anomaly detection features compared to the input size or latent variables, could be a compelling reason for acceptance. The reduced feature set simplifies the model without sacrificing detection or classification performance.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Limited evaluation on datasets beyond CIFAR-10\": \"While the system shows promise on the CIFAR-10 dataset, its generalizability to other datasets or real-world scenarios is not thoroughly evaluated. Extending the approach to more varied datasets could strengthen the paper.\",\n",
    "    \"Adversarial robustness of the DeClaw pipeline\": \"The current pipeline is not adversarially trained, which might raise concerns regarding its robustness against sophisticated adversarial attacks, especially in scenarios where the adversary has knowledge of the DeClaw pipeline.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Extend evaluations to additional datasets\": \"Conducting comprehensive evaluations on a wider range of datasets, including CIFAR-100 and ImageNet, would help validate the approach's effectiveness and generalizability across different domains.\",\n",
    "    \"Explore adversarial training for the DeClaw pipeline\": \"Investigating the incorporation of adversarial training into the DeClaw pipeline could enhance its robustness against more sophisticated or unseen adversarial attacks, potentially improving its applicability in security-sensitive applications.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "toy10_13_gpt_responses = [\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Hybrid Meta-RL and IL Approach\": \"PERIL introduces a novel method that blends meta-reinforcement learning (Meta-RL) with imitation learning (IL) using probabilistic embeddings. This approach enables efficient adaptation to new tasks by utilizing both demonstrations and reinforcement learning, addressing limitations in existing Meta-RL and Meta-IL frameworks.\",\n",
    "    \"Dual Inference Strategy\": \"The paper presents a dual inference strategy that allows for preconditioning exploration policies on demonstrations. This significantly improves adaptation rates for unseen tasks and enables the system to explore beyond the scope of the initial demonstration, enhancing its robustness to task alterations and uncertainties.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Exceptional Adaptation Rates\": \"PERIL demonstrates exceptional adaptation rates and outperforms existing Meta-RL and Meta-IL baselines in structured exploration tasks, achieving close to 93% accuracy in distinguishing among several types of adversarial attacks on the CIFAR-10 dataset.\",\n",
    "    \"Efficient Use of Demonstrations\": \"The method efficiently utilizes demonstrations to precondition the exploration policy, enabling rapid adaptation to new tasks. This efficient use of demonstrations, coupled with the capability for continuous improvement through exploration, presents a significant advancement over pure imitation learning approaches.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Generalization Beyond CIFAR-10\": \"While PERIL shows promise on the CIFAR-10 dataset, the generalization of this approach to other datasets or real-world scenarios is not thoroughly evaluated. Expanding the approach to more varied datasets could enhance the paper's impact.\",\n",
    "    \"Robustness of the DeClaw Pipeline\": \"The robustness of the DeClaw pipeline against sophisticated adversarial attacks, especially in scenarios where the adversary has knowledge of the DeClaw pipeline, is not fully addressed. This might raise concerns regarding its practical application in security-sensitive domains.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Expand Evaluations to Additional Datasets\": \"Conducting comprehensive evaluations on a wider range of datasets, including more challenging real-world scenarios, would validate the approach's effectiveness and generalizability.\",\n",
    "    \"Explore Adversarial Training for DeClaw\": \"Investigating the incorporation of adversarial training into the DeClaw pipeline could potentially enhance its robustness against sophisticated adversarial attacks, making it more suitable for practical applications.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Hybrid Meta-RL and IL Framework\": \"Introduces a novel framework, PERIL, that combines meta-reinforcement learning (Meta-RL) with imitation learning (IL) using probabilistic embeddings. This approach leverages demonstrations for efficient exploration and adaptation to new tasks, showcasing a significant step towards solving the challenge of data efficiency and generalization in learning systems.\",\n",
    "    \"Probabilistic Embedding for Task Adaptation\": \"PERIL utilizes dual inference strategies for task adaptation, allowing for preconditioned exploration policies based on demonstrations. This method effectively bridges the gap between Meta-RL and IL, enabling the system to explore beyond the scope of demonstrations and adapt to task alterations and uncertainties.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Superior Adaptation Rates\": \"Demonstrates exceptional adaptation rates across various tasks, outperforming existing Meta-RL and Meta-IL baselines. This achievement underlines the efficacy of PERIL in utilizing demonstrations for structured exploration and its potential in facilitating zero-shot learning.\",\n",
    "    \"Robust to Task Alterations\": \"The framework's ability to adapt to unseen tasks as well as unseen task families within a set of Meta-RL benchmarks under sparse rewards indicates its robustness and versatility. Such capability is critical for the application of RL systems in real-world scenarios, where tasks often involve uncertainties and alterations.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Limited Demonstration of Broader Applicability\": \"While the paper presents promising results on CIFAR-10 and other structured exploration tasks, the generalizability of PERIL across a wider range of real-world applications remains to be thoroughly evaluated. Additional experiments across diverse domains could strengthen the paper's claims.\",\n",
    "    \"Dependency on Quality and Quantity of Demonstrations\": \"The system's performance is inherently linked to the quality and quantity of demonstrations available for each task. There is a potential concern regarding the framework's effectiveness in scenarios where high-quality demonstrations are scarce or inapplicable.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Extensive Evaluation Across Diverse Domains\": \"To validate the generalizability and robustness of PERIL, conducting further experiments across a broader spectrum of tasks and domains, including real-world applications, would be beneficial. Such evaluations could help establish PERIL's applicability and performance in varied scenarios.\",\n",
    "    \"Investigate Alternative Demonstration Strategies\": \"Exploring alternative strategies for generating or utilizing demonstrations, including synthetic or semi-supervised approaches, could enhance the framework's effectiveness. This exploration might also reduce the dependency on high-quality demonstrations and expand the range of tasks where PERIL can be applied.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Hybrid Meta-RL and IL Framework\": \"The paper introduces PERIL, a novel framework that integrates meta-reinforcement learning (Meta-RL) and imitation learning (IL) using probabilistic embeddings. This approach enables rapid adaptation to new tasks by conditioning on demonstrations and further exploration, addressing limitations in both Meta-RL and Meta-IL.\",\n",
    "    \"Dual Inference Strategies\": \"PERIL employs dual inference strategies for task adaptation, leveraging demonstrations for initial task inference and exploration for continuous task refinement. This method improves adaptation rates in unseen tasks and demonstrates exploration beyond demonstrations, enhancing robustness to task alterations and uncertainties.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Exceptional Adaptation Rates\": \"The framework achieves outstanding adaptation rates, significantly outperforming existing Meta-RL and Meta-IL baselines in structured exploration tasks. This demonstrates the effectiveness of blending demonstrations and exploration within a meta-learning context.\",\n",
    "    \"Efficient Use of Demonstrations\": \"PERIL efficiently uses demonstrations to precondition exploration policies, enabling rapid adaptation to new tasks. This efficient use of demonstrations represents a significant step forward in leveraging human knowledge for machine learning.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Generalization Concerns\": \"The paper primarily demonstrates PERIL's effectiveness on simulated tasks with structured environments. There might be concerns regarding its generalization to more complex or diverse real-world scenarios.\",\n",
    "    \"Exploration of Sophisticated Adversarial Attacks\": \"The document does not explicitly address the robustness of PERIL against sophisticated adversarial attacks. Given the increasing importance of security in ML applications, this could be seen as a limitation.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Broaden Evaluation Scope\": \"Extending the evaluation to include more diverse and complex real-world tasks could help validate the approach's effectiveness and generalizability. This would strengthen the case for PERIL's applicability beyond simulated environments.\",\n",
    "    \"Investigate Robustness to Adversarial Attacks\": \"Exploring the robustness of PERIL against various adversarial attacks could provide insights into its security and reliability. Developing strategies to enhance its defensive capabilities would be a valuable direction for future research.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Hybrid Meta-RL and IL Framework\": \"PERIL introduces a novel framework that combines the merits of both Reinforcement Learning (RL) and Imitation Learning (IL), overcoming limitations of meta-RL and meta-IL by allowing for tasks to be defined using demonstrations only, while enabling continual policy improvement through further exploration.\",\n",
    "    \"Probabilistic Embeddings for Task Representation\": \"Utilizes a novel approach of probabilistic embeddings to represent tasks, which allows the agent to adapt to new tasks by preconditioning exploration policies on demonstrations, enhancing adaptation rates in unseen tasks.\",\n",
    "    \"Exploration Beyond Demonstrations\": \"Unlike pure imitation learning, PERIL is capable of exploring beyond the demonstration, making it robust to task alterations and uncertainties.\",\n",
    "    \"Meta-RL Benchmarks Under Sparse Rewards\": \"Demonstrates the ability of PERIL to interpolate within previously learnt dynamics to adapt to unseen tasks and task families within a set of meta-RL benchmarks under sparse rewards.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Addressing Key Limitations\": \"Effectively addresses key limitations of existing meta-RL and meta-IL approaches by providing a natural way for non-experts to describe tasks through demonstrations and enabling adaptation without hand-crafted rewards or state-space engineering.\",\n",
    "    \"High Adaptation Rates\": \"Achieves exceptional adaptation rates and is capable of efficient exploration in unseen tasks, outperforming other Meta-RL and Meta-IL baselines in structured exploration.\",\n",
    "    \"Robustness to Task Variations\": \"Showcases robustness to task alterations and uncertainties, with the ability to perform zero-shot learning and multi-family meta-learning.\",\n",
    "    \"Comprehensive Evaluation\": \"Extensive experiments across a range of tasks demonstrate superior data efficiency and adaptation capabilities compared to a range of baselines.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {},\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Real-World Applications\": \"Future work could explore applying PERIL to real-world contact-rich robot manipulation tasks to further validate its effectiveness and robustness in more complex scenarios.\",\n",
    "    \"Learning from Imperfect Demonstrations\": \"Investigating extensions of the framework to learn from imperfect demonstrations could enhance its applicability and effectiveness in environments where expert trajectories are not readily available or are suboptimal.\",\n",
    "    \"Exploration of Auxiliary Systems\": \"Further exploration of the role and impact of auxiliary systems in multi-task family settings could provide insights into optimizing task inference and improving generalization across diverse task families.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "toy14_18_gpt_responses = [\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Novel Framework for Goal-conditioned RL\": \"Introduces 'C-Learning', a novel framework for goal-conditioned reinforcement learning (RL) that reframes the problem as estimating the probability density over future states. This approach is a significant departure from traditional methods, offering a new perspective on achieving tasks in RL without direct reliance on reward functions.\",\n",
    "    \"Advancement in Off-policy Learning\": \"Develops an off-policy variant of C-Learning that allows for predicting the future state distribution of new policies without collecting new experience. This capability is crucial for optimizing policies based on future state distributions and represents a significant advancement in the flexibility and efficiency of goal-conditioned RL algorithms.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Empirical Validation\": \"The paper provides comprehensive empirical validation demonstrating that C-Learning accurately estimates the density over future states and outperforms existing goal-conditioned RL methods on simulated robotic tasks. This strong empirical evidence supports the effectiveness and applicability of the proposed method.\",\n",
    "    \"Theoretical Insights\": \"Offers theoretical insights into goal-conditioned Q-learning, including hypotheses about the optimal goal-sampling ratio. These insights contribute to a deeper understanding of the underlying mechanisms in goal-conditioned learning and can guide future research in the field.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Generalization to Diverse Tasks\": \"While the paper demonstrates the effectiveness of C-Learning on specific tasks, the generalizability of the approach to a wider range of environments and tasks remains to be fully explored. Expanding the evaluation to include diverse settings could strengthen the case for C-Learning's applicability.\",\n",
    "    \"Comparison with State-of-the-art Methods\": \"The paper compares C-Learning with prior goal-conditioned RL methods but may benefit from a broader comparison, including the latest advancements in the field. A more extensive comparison could help position C-Learning within the current research landscape more clearly.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Broaden Experimental Evaluation\": \"To further validate the generalizability and robustness of C-Learning, expanding the experimental evaluation to include a wider variety of tasks, especially those with complex dynamics and high-dimensional state spaces, is recommended.\",\n",
    "    \"Investigate Learning from Imperfect Demonstrations\": \"Exploring extensions of C-Learning to learn from imperfect demonstrations could enhance its practical applicability. Investigating how the method performs with noisy or suboptimal demonstrations could provide valuable insights into its robustness and flexibility.\",\n",
    "    \"Further Theoretical Analysis\": \"While the paper provides valuable theoretical insights, further analysis could help solidify the theoretical foundations of C-Learning. Specifically, exploring the convergence properties and theoretical guarantees in more detail would be beneficial.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Novel approach for goal-conditioned RL\": \"Introduces a new framework, C-Learning, for goal-conditioned reinforcement learning, reframing it as estimating the probability density over future states without direct reliance on reward functions.\",\n",
    "    \"Density estimation via classification\": \"Presents an innovative method by indirectly estimating the future state density function through classification, enabling predictions of future state distributions for new policies without collecting new experience.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Comprehensive empirical validation\": \"Demonstrates superior performance in estimating future state distributions and outperforms existing goal-conditioned RL methods on simulated robotic tasks, supported by extensive experimental validation.\",\n",
    "    \"Theoretical insights and implications\": \"Provides valuable theoretical insights into goal-conditioned Q-learning, including hypotheses about the optimal goal-sampling ratio, contributing to a deeper understanding of goal-conditioned learning mechanisms.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Generalization concerns\": \"While showing promise on specific simulated tasks, the paper's exploration of C-Learning's generalizability across a wider range of environments or tasks is limited.\",\n",
    "    \"Comparison breadth\": \"The comparison with state-of-the-art methods could be expanded to include a broader range of recent advancements in the field to clearly establish C-Learning's position within the current research landscape.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Expand experimental evaluation\": \"Conduct further evaluations on a broader array of tasks and environments, especially those with complex dynamics, to validate the approach's effectiveness and generalizability.\",\n",
    "    \"Enhance theoretical analysis\": \"Deepen the theoretical analysis to provide more insights into C-Learning's mechanisms and potential limitations, possibly exploring convergence properties and theoretical guarantees in more detail.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Novel Framework for Goal-conditioned RL\": \"Introduces 'C-Learning', a novel framework for goal-conditioned reinforcement learning (RL) that reframes the problem as estimating the probability density over future states. This approach represents a significant departure from traditional RL methods, emphasizing density estimation over direct reward function optimization.\",\n",
    "    \"Advancement in Off-policy Learning\": \"Presents an off-policy variant of C-Learning that enables predicting the future state distribution of new policies without additional data collection. This development is crucial for enhancing the efficiency of policy optimization, particularly in environments where data collection is costly or difficult.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Empirical Validation on Simulated Robotic Tasks\": \"Demonstrates the efficacy of C-Learning through comprehensive empirical validation on simulated robotic tasks, showcasing its ability to outperform existing goal-conditioned RL methods in terms of accurately estimating future state densities.\",\n",
    "    \"Theoretical Insights into Goal-conditioned Q-learning\": \"Provides valuable theoretical insights into the nature of goal-conditioned Q-learning, including hypotheses about optimal goal-sampling ratios. These contributions deepen the understanding of the underlying mechanisms in goal-conditioned learning.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Generalization Beyond Specific Tasks\": \"The paper's evaluation focuses on simulated robotic tasks, raising questions about the generalizability of C-Learning to other domains or more complex environments. Expanding the scope of evaluation could strengthen the case for C-Learning's applicability.\",\n",
    "    \"Comparison with State-of-the-art Methods\": \"While the paper compares C-Learning with prior goal-conditioned RL methods, a broader comparison with the latest advancements in the field could provide a clearer context for C-Learning's contributions.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Broaden Evaluation to Diverse Domains\": \"To validate the generalizability and robustness of C-Learning, it is recommended to extend the evaluation to a wider variety of tasks, especially those with complex dynamics and high-dimensional state spaces.\",\n",
    "    \"Enhanced Theoretical Analysis\": \"Further theoretical analysis, particularly regarding the convergence properties and theoretical guarantees of C-Learning, would be beneficial. This could include exploring the conditions under which C-Learning achieves optimal future state density estimation.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Novel framework for goal-conditioned RL\": \"The paper introduces C-Learning, a new framework for goal-conditioned reinforcement learning (RL) that focuses on learning a conditional probability density function over future states. This approach is distinct from traditional methods by estimating this density function indirectly through a classifier, offering a principled foundation for goal-conditioned RL as density estimation.\",\n",
    "    \"Off-policy variant for future state prediction\": \"An off-policy variant of C-Learning is proposed, enabling the prediction of future state distribution for new policies without requiring new experience. This significant advancement allows for the optimization of policy future state distributions, enhancing the ability to reach specific goal states.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Addresses limitations of Q-learning in continuous environments\": \"The paper effectively addresses the limitations of Q-learning in continuous environments with sparse rewards, offering a solution that avoids the reliance on reward functions. This contribution is significant for advancing goal-conditioned RL methodologies.\",\n",
    "    \"Competitive with existing goal-conditioned RL methods\": \"C-Learning is shown to be competitive with existing goal-conditioned RL methods across a suite of simulated robotic tasks. This demonstrates the practical applicability and potential of the proposed method in complex RL scenarios.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Dependence on specific assumptions and settings\": \"The effectiveness of C-Learning might be limited to the assumptions and settings under which it was tested. The generalizability of the approach across a broader range of RL problems and environments could be a concern.\",\n",
    "    \"Comparison with a narrow set of existing methods\": \"The paper might face criticism for comparing C-Learning primarily with Q-learning based methods, potentially overlooking other relevant approaches in goal-conditioned RL.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Extend evaluation to a wider range of environments\": \"To demonstrate the robustness and generalizability of C-Learning, it is suggested to extend the evaluation to a broader range of environments, including those with different types of goals and reward structures.\",\n",
    "    \"Explore integration with other RL techniques\": \"Exploring how C-Learning could be integrated with other RL techniques, such as model-based approaches or policy gradient methods, could further enhance its applicability and effectiveness.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"New framing of goal-conditioned RL\": \"Presents a novel framing of goal-conditioned reinforcement learning (RL) as estimating the probability density over future states. This approach provides a principled foundation for goal-conditioned RL as density estimation, offering a new perspective and justification for goal-conditioned methods used in prior work.\",\n",
    "    \"Introduction of C-Learning\": \"Introduces C-Learning, a method for estimating the future state distribution indirectly by training a classifier to predict whether an observation comes from the future. This method allows for optimizing functionals of a policy's future state distribution, such as the density of reaching a particular goal state, without collecting new experience.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Theoretical and empirical insights\": \"Provides theoretical insights into goal-conditioned Q-learning and demonstrates experimentally that C-Learning more accurately estimates the density over future states compared to existing goal-conditioned RL methods across a suite of simulated robotic tasks.\",\n",
    "    \"Advancement in goal-conditioned RL methods\": \"By reframing goal-conditioned RL as density estimation and introducing an off-policy variant of the algorithm, this work lays the groundwork for more efficient and effective goal-conditioned learning strategies.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Generalization and applicability concerns\": \"While showing promising results on simulated robotic tasks, the generalizability of C-Learning to other domains, datasets, and real-world scenarios remains to be fully explored.\",\n",
    "    \"Comparison with a broader range of existing methods\": \"The paper could benefit from a broader comparison with recent advancements in goal-conditioned RL, including those employing different approaches such as model-based methods or other forms of policy optimization.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Expand empirical evaluation\": \"To validate the approach's effectiveness and generalizability, it is recommended to extend the empirical evaluation to include a wider variety of tasks, environments, and potentially real-world scenarios.\",\n",
    "    \"Explore integration with other RL techniques\": \"Investigating how C-Learning could be integrated with other reinforcement learning techniques, such as model-based approaches or different policy optimization methods, could further enhance its applicability and performance.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "toy19_21_gpt_responses = [\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Introduction of Deep MinCut (DMC)\": \"The paper presents Deep MinCut (DMC), an unsupervised approach to learn node embeddings by leveraging the community structure within graph data. This method innovatively combines the detection of communities with the learning of node embeddings, offering insights into graph structure without a separate clustering step. DMC minimizes the mincut loss, which focuses on the connections between communities, a novel approach in the context of unsupervised learning for graph-structured data.\",\n",
    "    \"Efficient minibatch training process\": \"In addition to introducing a new method for learning embeddings, the paper proposes an efficient minibatch training process for DMC. This approach is designed to handle large-scale graphs by approximating the mincut loss with sampled subgraphs, significantly improving the scalability of the method.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Empirical validation of meaningful communities\": \"The paper provides empirical evidence demonstrating that DMC can learn meaningful communities and that the node embeddings generated are competitive in node classification benchmarks. These results could be compelling for acceptance, showcasing the practical utility of the proposed method in various applications.\",\n",
    "    \"Theoretical underpinning and flexibility\": \"DMC is not only practically validated but also has a strong theoretical foundation. The flexibility of DMC, demonstrated through its application in node classification and community detection, and its ability to learn a hierarchy of communities, suggests a broad applicability and potential impact on the field.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Generalization beyond tested datasets\": \"While DMC shows promise on the datasets tested, the generalizability of the approach to other datasets or real-world scenarios is not thoroughly evaluated. A broader evaluation, including diverse settings, could strengthen the paper.\",\n",
    "    \"Comparison with state-of-the-art methods\": \"The paper might benefit from a broader comparison with recent advancements in unsupervised learning for graph-structured data, including other methods focusing on community detection and node embeddings.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Extend evaluation to more varied datasets\": \"To demonstrate the robustness and generalizability of DMC, extending the empirical evaluation to include a wider variety of tasks and datasets, including more complex real-world scenarios, is recommended.\",\n",
    "    \"Explore integration with other RL techniques\": \"Investigating how DMC could be integrated with other machine learning or reinforcement learning techniques could further enhance its applicability and performance, offering new avenues for research.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Innovative approach to learning node embeddings\": \"Deep MinCut (DMC) introduces an unsupervised method for learning node embeddings through community detection, without requiring a separate clustering step. This method is novel in leveraging the structure within graph data to derive node representations based on their community membership, offering new insights into graph structure.\",\n",
    "    \"Scalability through minibatch training\": \"DMC proposes an efficient minibatch training process to accommodate large-scale graphs, which is significant for practical applications. This process allows for the approximation of mincut loss with sampled subgraphs, enhancing the method's scalability and usability in real-world scenarios.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Empirical validation on node classification tasks\": \"The paper provides strong empirical evidence showcasing that the communities learned by DMC are meaningful and that the node embeddings are competitive in node classification benchmarks. Such practical validation of DMC's effectiveness in both embedding quality and community detection is a compelling reason for acceptance.\",\n",
    "    \"Theoretical underpinnings of the approach\": \"The theoretical motivation behind minimizing the mincut loss for simultaneous learning of node embeddings and communities, along with the development of an off-policy variant of the algorithm, lays a strong foundation for the proposed method. These contributions could significantly impact the field of graph learning.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Generalization and broader comparison needed\": \"While the paper shows promising results, its evaluation is limited to specific datasets. A broader examination across diverse datasets and a more extensive comparison with state-of-the-art methods in unsupervised learning for graph-structured data would strengthen the paper.\",\n",
    "    \"Exploration of method's limitations\": \"The paper could further detail the limitations of DMC, especially in scenarios with highly overlapping or hierarchical community structures, to provide a clearer understanding of its applicability and potential areas for improvement.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Extend evaluation to diverse datasets\": \"Broadening the empirical evaluation to include a wider range of tasks and datasets, especially those with complex community structures or higher-dimensional embeddings, could validate the generalizability of DMC.\",\n",
    "    \"Deepen comparative analysis\": \"A more thorough comparison with recent unsupervised learning methods, particularly those that also address community detection, would help situate DMC within the current research landscape and highlight its unique contributions more clearly.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\",\n",
    "    \"\"\"{\n",
    "  \"Significance and novelty\": {\n",
    "    \"Introduction of Deep MinCut (DMC)\": \"Presents Deep MinCut (DMC), a novel unsupervised approach for learning node embeddings by leveraging the community structure within graphs. This method innovatively combines the learning of node embeddings with the detection of communities, providing meaningful insights into graph structure without a separate clustering step.\",\n",
    "    \"Efficient minibatch training process\": \"Introduces an efficient minibatch training process for DMC, designed to handle large-scale graphs. This process approximates the mincut loss with sampled subgraphs, significantly enhancing the scalability and practical applicability of the method.\"\n",
    "  },\n",
    "  \"Potential reasons for acceptance\": {\n",
    "    \"Empirical validation of meaningful communities\": \"Provides empirical evidence that DMC learns meaningful communities and generates node embeddings competitive in node classification benchmarks. This empirical validation underscores the method's effectiveness and its potential for broad applicability in graph analysis tasks.\",\n",
    "    \"Theoretical underpinnings and flexibility\": \"Offers theoretical insights into goal-conditioned Q-learning, enhancing the understanding of goal-conditioned learning mechanisms. DMC's ability to learn a hierarchy of communities adds a layer of flexibility, enabling its application to complex hierarchical structures within data.\"\n",
    "  },\n",
    "  \"Potential reasons for rejection\": {\n",
    "    \"Generalization beyond tested datasets\": \"While DMC shows promise on the tested datasets, the generalization of the approach to other datasets or real-world scenarios is not extensively evaluated. Expanding the evaluation to more varied datasets could help solidify the method's effectiveness and versatility.\",\n",
    "    \"Comparison with state-of-the-art methods\": \"The document might benefit from a broader comparison with the latest advancements in unsupervised learning for graph-structured data. A more comprehensive comparison could better position DMC within the current research landscape.\"\n",
    "  },\n",
    "  \"Suggestions for improvement\": {\n",
    "    \"Extend empirical evaluation to diverse datasets\": \"To further validate DMC's effectiveness and generalizability, extending empirical evaluation to include a wider range of tasks and datasets, particularly those with complex community structures, is recommended.\",\n",
    "    \"Explore integration with other graph learning techniques\": \"Investigating how DMC could be integrated with other graph learning techniques, such as graph convolutional networks or different forms of policy optimization, could enhance its utility and performance.\"\n",
    "  }\n",
    "}\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_responses = toy0_3_gpt_responses + toy4_6_gpt_responses + toy7_8_gpt_responses + toy9_9_gpt_responses + toy10_13_gpt_responses + toy14_18_gpt_responses + toy19_21_gpt_responses\n",
    "len(gpt_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_data_w_gpt_reviews[\"gpt-4-full-reviews\"] = gpt_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>gpt-3.5-turbo-reviews</th>\n",
       "      <th>gpt-4-full-reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>A good one</td>\n",
       "      <td>This paper proposes a better pre-trained prior...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "      <td>{\\n    \"Significance and novelty\": {\\n        ...</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Intro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>paper shows promising results using point clou...</td>\n",
       "      <td>The paper considers the problem of training ne...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "      <td>{\\n\"Significance and novelty\": {\\n    \"Use of ...</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Intro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>Limited novelty and weak improvements</td>\n",
       "      <td>The authors propose completing an occluded poi...</td>\n",
       "      <td>4: Ok but not good enough - rejection</td>\n",
       "      <td>{\\n    \"Significance and novelty\": {\\n        ...</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Novel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>Since the idea itself is simple enough, the re...</td>\n",
       "      <td>The idea of this paper is simple but fascinati...</td>\n",
       "      <td>5: Marginally below acceptance threshold</td>\n",
       "      <td>{\\n\"Significance and novelty\": {\\n    \"Mask-ba...</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Innov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GamePad: A Learning Environment for Theorem Pr...</td>\n",
       "      <td>https://openreview.net/pdf?id=r1xwKoR9Y7</td>\n",
       "      <td>In this paper, we introduce a system called Ga...</td>\n",
       "      <td>Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...</td>\n",
       "      <td>An intriguing integration of ML and automated ...</td>\n",
       "      <td>Summary: This paper mixes automated theorem pr...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Explo...</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Intro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0            Pre-Training by Completing Point Clouds   \n",
       "1            Pre-Training by Completing Point Clouds   \n",
       "2            Pre-Training by Completing Point Clouds   \n",
       "3            Pre-Training by Completing Point Clouds   \n",
       "4  GamePad: A Learning Environment for Theorem Pr...   \n",
       "\n",
       "                                         url  \\\n",
       "0  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "1  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "2  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "3  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "4   https://openreview.net/pdf?id=r1xwKoR9Y7   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  There has recently been a flurry of exciting a...   \n",
       "1  There has recently been a flurry of exciting a...   \n",
       "2  There has recently been a flurry of exciting a...   \n",
       "3  There has recently been a flurry of exciting a...   \n",
       "4  In this paper, we introduce a system called Ga...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "1  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "2  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "3  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "4  Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...   \n",
       "\n",
       "                                        review_title  \\\n",
       "0                                         A good one   \n",
       "1  paper shows promising results using point clou...   \n",
       "2              Limited novelty and weak improvements   \n",
       "3  Since the idea itself is simple enough, the re...   \n",
       "4  An intriguing integration of ML and automated ...   \n",
       "\n",
       "                                              review  \\\n",
       "0  This paper proposes a better pre-trained prior...   \n",
       "1  The paper considers the problem of training ne...   \n",
       "2  The authors propose completing an occluded poi...   \n",
       "3  The idea of this paper is simple but fascinati...   \n",
       "4  Summary: This paper mixes automated theorem pr...   \n",
       "\n",
       "                                     rating  \\\n",
       "0                     7: Good paper, accept   \n",
       "1                     7: Good paper, accept   \n",
       "2     4: Ok but not good enough - rejection   \n",
       "3  5: Marginally below acceptance threshold   \n",
       "4                     7: Good paper, accept   \n",
       "\n",
       "                               gpt-3.5-turbo-reviews  \\\n",
       "0  {\\n    \"Significance and novelty\": {\\n        ...   \n",
       "1  {\\n\"Significance and novelty\": {\\n    \"Use of ...   \n",
       "2  {\\n    \"Significance and novelty\": {\\n        ...   \n",
       "3  {\\n\"Significance and novelty\": {\\n    \"Mask-ba...   \n",
       "4  {\\n  \"Significance and novelty\": {\\n    \"Explo...   \n",
       "\n",
       "                                  gpt-4-full-reviews  \n",
       "0  {\\n  \"Significance and novelty\": {\\n    \"Intro...  \n",
       "1  {\\n  \"Significance and novelty\": {\\n    \"Intro...  \n",
       "2  {\\n  \"Significance and novelty\": {\\n    \"Novel...  \n",
       "3  {\\n  \"Significance and novelty\": {\\n    \"Innov...  \n",
       "4  {\\n  \"Significance and novelty\": {\\n    \"Intro...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data_w_gpt_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = '../toy_data_w_gpt_reviews.csv'  # Define your file path here\n",
    "toy_data_w_gpt_reviews.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
