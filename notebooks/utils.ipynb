{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../reviews/notes.jsonl') as f:\n",
    "    reviews = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random select 10 reviews\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "random_reviews = random.sample(reviews, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any\n",
    "\n",
    "def extract_review_messages(review_data: Dict[str, List[Dict[str, Dict[str, Any]]]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extracts and returns the review messages including titles, reviews, and ratings from a given review data structure.\n",
    "\n",
    "    Args:\n",
    "        review_data (Dict[str, List[Dict[str, Dict[str, Any]]]]): A dictionary containing the review information,\n",
    "        expected to have a 'reviews_msg' key with a list of dictionaries. Each dictionary should have a 'content'\n",
    "        key that contains a dictionary with 'title', 'review', and 'rating' keys.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of dictionaries, each containing 'title', 'review', and 'rating' keys with their\n",
    "        respective values extracted from the review data.\n",
    "    \"\"\"\n",
    "    review_messages = []\n",
    "    for message in review_data.get('reviews_msg', []):\n",
    "        content = message.get('content', {})\n",
    "        if all(key in content for key in ['title', 'review', 'rating']):\n",
    "            review_messages.append({\n",
    "                'title': content['title'],\n",
    "                'review': content['review'],\n",
    "                'rating': content['rating']\n",
    "            })\n",
    "\n",
    "    return review_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basic_dict': {'forum': 'jPSYH47QSZL',\n",
       "  'title': 'Pre-Training by Completing Point Clouds',\n",
       "  'url': 'https://openreview.net/forum?id=jPSYH47QSZL',\n",
       "  'pub_date': '--',\n",
       "  'abstract': 'There has recently been a flurry of exciting advances in deep learning models on point clouds. However, these advances have been hampered by the difficulty of creating labelled point cloud datasets: sparse point clouds often have unclear label identities for certain points, while dense point clouds are time-consuming to annotate. Inspired by mask-based pre-training in the natural language processing community, we propose a pre-training mechanism based point clouds completion. It works by masking occluded points that result from observations at different camera views. It then optimizes a completion model that learns how to reconstruct the occluded points, given the partial point cloud. In this way, our method learns a pre-trained representation that can identify the visual constraints inherently embedded in real-world point clouds. We call our method Occlusion Completion (OcCo). We demonstrate that OcCo learns representations that improve the semantic understandings as well as generalization on downstream tasks over prior methods, transfer to different datasets, reduce training time and improve label efficiency.',\n",
       "  'TL;DR': '--',\n",
       "  'authors': 'Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,Matt Kusner',\n",
       "  'keywords': 'self-supervised learning,pre-training,point clouds',\n",
       "  'venue': '--',\n",
       "  'venue_id': '--',\n",
       "  'number': 992,\n",
       "  'pdf_url': 'https://openreview.net/pdf?id=jPSYH47QSZL',\n",
       "  'signatures': ['ICLR.cc/2021/Conference'],\n",
       "  'bibtex': '@misc{\\nwang2021pretraining,\\ntitle={Pre-Training by Completing Point Clouds},\\nauthor={Hanchen Wang and Qi Liu and Xiangyu Yue and Joan Lasenby and Matt Kusner},\\nyear={2021},\\nurl={https://openreview.net/forum?id=jPSYH47QSZL}\\n}',\n",
       "  'from_venue_id': 'ICLR.cc/2021/Conference'},\n",
       " 'reviews_msg': [{'id': '-gdQfih288t',\n",
       "   'original': None,\n",
       "   'number': 1,\n",
       "   'cdate': 1603694578361,\n",
       "   'ddate': None,\n",
       "   'tcdate': 1603694578361,\n",
       "   'tmdate': 1606794528549,\n",
       "   'tddate': None,\n",
       "   'forum': 'jPSYH47QSZL',\n",
       "   'replyto': 'jPSYH47QSZL',\n",
       "   'invitation': 'ICLR.cc/2021/Conference/Paper992/-/Official_Review',\n",
       "   'content': {'title': 'A good one',\n",
       "    'review': \"This paper proposes a better pre-trained prior for a variety of downstream applications in point cloud analysis. The workflow of the pre-training mechanism is to first 1) generate occluded points that result from view occlusion and then 2) optimize the encoder to learn how to complete the occluded points from the partial point cloud. In downstream applications, the obtained encoder will be used as the initial weights in the network training. Empirical experiments have shown that such a pre-train mechanism can improve initialization over prior baselines and benefit a variety of tasks even with a large domain gap.\\n\\nPros:\\n1. The experimental results have shown a steady improvement in performance by using the proposed pre-training approach in different encoder architectures and different downstream applications. That provides strong support for validating the effectiveness of the proposed approach.\\n2. I also like the result that the initialization is only pre-trained on the occlusions generated from the ModelNet40 but still work in another dataset. And yet, the pre-training is done in a self-supervised manner. This is a great plus for this approach as it indicates that it could be a general-purpose booster for a wide range of applications without spending too much effort in collecting special-purpose dataset for pre-training. \\n3. The paper is well written and presented.\\n\\nCons:\\n1. The improvement, as shown in the statistics, is very incremental in most cases. I understand it is difficult to achieve better results on well-established benchmarks, but it somehow indicates the improvement is limited.\\n2. Though the paper already stated some nice explanation of the idea behind this approach, I would appreciate it if a more in-depth analysis of why such a pre-training mechanism could work is provided. Specifically, I would like more analysis of why such a pre-training method can adapt to different datasets? What are the common features that OcCo captures across different datasets? \\nSome visualization similar to Figure 3 would be helpful.\\n\\n---- Final Rating ----\\n\\nThe authors' response has resolved my concerns. I would keep my positive rating.\",\n",
       "    'rating': '7: Good paper, accept',\n",
       "    'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'},\n",
       "   'signatures': ['ICLR.cc/2021/Conference/Paper992/AnonReviewer1'],\n",
       "   'readers': ['everyone'],\n",
       "   'nonreaders': [],\n",
       "   'writers': ['ICLR.cc/2021/Conference',\n",
       "    'ICLR.cc/2021/Conference/Paper992/AnonReviewer1']},\n",
       "  {'id': 'X2KCXHb2f_v',\n",
       "   'original': None,\n",
       "   'number': 2,\n",
       "   'cdate': 1603746066436,\n",
       "   'ddate': None,\n",
       "   'tcdate': 1603746066436,\n",
       "   'tmdate': 1606669985066,\n",
       "   'tddate': None,\n",
       "   'forum': 'jPSYH47QSZL',\n",
       "   'replyto': 'jPSYH47QSZL',\n",
       "   'invitation': 'ICLR.cc/2021/Conference/Paper992/-/Official_Review',\n",
       "   'content': {'title': 'paper shows promising results using point cloud completion tasks for pre-training representations, method is clearly described; however, highly related work not discussed that limits novelty of the proposed OcCo task, experimental setup not fully clear, making it hard to understand the results',\n",
       "    'review': 'The paper considers the problem of training networks for point cloud processing through a point cloud completion task. Given a point cloud, it is rendered from a set of viewpoints and for each viewpoint the set of visible points is determine. A network is then trained to generate the full point cloud from the partially observed point cloud for a given view. Here, an encoder-decoder architecture is used, where the encoder corresponds to the network that should be pre-trained. Experimental results show that the proposed method outperforms two baselines for three tasks (object classification, object part segmentation, and semantic segmentation), when using less training data, and that the pre-training on the occlusion task leads to faster convergence.\\n\\nOn the positive side, the occlusion completion (OcCo) task is clearly described and it should be fairly straightforward for a researcher to setup this task. The task requires no human annotation and is thus suitable for pre-training from large datasets captured in uncontrolled settings. The experiments cover a wide range of tasks and settings and show that the OcCo pre-training strategy outperforms random initialization and the approach from Saunders & Sievers. Here, the simplicity of the OcCo task coupled with its performance is clearly a major strength of the paper. In particular, Fig. 4 shows that the networks pre-trained on the OcCo task tend to converge much faster compared to the baselines.\\n\\nOn the negative side, I feel that the paper oversells the novelty of the OcCo task. The OcCo task is a variation of the (semantic) scene completion task that asks to complete a partial observation of a scene / object and is receiving attention in the computer vision community. Recent examples include [Dai et al.,  SG-NN: Sparse Generative Neural Networks for Self-Supervised Scene Completion of RGB-D Scans, CVPR 2020] and [Hou et al., RevealNet: Seeing Behind Objects in RGB-D Scans, CVPR 2020], with older works including [Firman et al., Structured prediction of unobserved voxels from a single depth image, CVPR 2016]. [Schönberger et al., Semantic Visual Localization, CVPR 2018] use (semantic) scene completion as a proxy task to train a 3D descriptors for 3D-3D matching between models. Given a voxelized partial observation of a scene, they train an encoder-decoder architecture to predict the complete volume (potentially also predicting semantic labels for each voxel). The embedding in the latent space are then used as 3D descriptors (i.e., the decoder part of the network is not needed at test time). In other words, they use the OcCo task for training their networks. They show that the learned representation generalizes between datasets and sensor modalities (training on 3D data obtained from stereo images, tested on LiDAR data). Given this result, I see limited novelty in using the OcCo task for pre-training point cloud networks and it does not seem very surprising that pre-training on the OcCo task should result in meaningful representations.\\n\\nMy second main point of criticism is the level of detail of the experimental evaluation. While the experiments cover a wide range of tasks and settings, I feel that crucial information needed to understand the results are missing:\\n1) Is the same dataset (ModelNet40) used to pre-train on the OcCo task also used to pre-train the JigSaw approach from Sauder & Sievers? Unfortunately, no details on the latter are provided in the main paper (or I was not able to find them), making it hard to understand how meaningful the comparison is.\\n2) There are no details on how the networks are trained for the different tasks, e.g., for how many epochs are the network trained for the task at hand?, do the networks converge for all pre-training strategies?\\n3) How significant are the improvements over the two baselines. For most considered settings, the improvements seem rather small, e.g., often less than 1 point compared to the Rand baseline in Tab. 2 and 3. Is this a meaningful improvment? Or would simply using a different random seed for training explain such a difference? Given that the paper claims that \"These results demonstrate that the OcCo-initialized models have strong transfer capabilities on out-of-domain datasets\" and that \"OcCo-initialized models achieve superior results compared to the randomly-initialized models\", this is an important question to answer.\\nI think there is enough space in the paper to include this information. Specifically, I do not think that Alg. 1 is necessary in the main paper (but would be good to have as an appendix) as the text and Fig. 1 already describe the approach in sufficient detail. Similarly, the z-Buffer algorithm is a classic computer graphics technique that is covered in basic lectures and does not need to be discussed in detail (e.g., see [Pittaluga et al., Revealing Scenes by Inverting Structure from Motion Reconstructions, CVPR 2019] briefly mentioning z-Buffering and the use of Delaunay triangulation for determining visibility). I think this space could be spend on providing more details.\\n\\nIn the current form, I do not think the paper is ready for publication as the paper, in my opinion, overclaims its contributions, misses relevant work (see also below), and misses crucial details necessary to understand the experimental results. As such, I am currently recommending to reject the paper. I believe that these issues can be addressed, but I would base my final recommendation based on the authors\\' feedback.\\n\\nHere are additional detailed comments:\\n* In Sec. 2.1, I do not understand the comment \"Our goal is to learn a randomized occlusion mapping o : P → P (where P is the space of all point clouds) from a full point cloud P to an occluded point cloud P\". As far as I can tell, the mapping is not learned but follows a fixed pipeline.\\n* I don\\'t understand how Eq. 2 \"most closely approximates the inverse of eq. (1)\". Eq. 2 is the inverse of Eq. 1. The only approximation that I could see if the 2D projection coordinates are rounded to the nearest integer.\\n* The introduction teases with the statement \"Current 3D sensing modalities (i.e., 3D scanners, stereo cameras, lidars) have enabled the creation of large repositories of point cloud data (Rusu & Cousins, 2011; Hackel et al., 2017).\" However, only synthetic data is used for pre-training, which is a bit disappointing. I am not convinced that the synthetic datasets \"are qualitatively similar to point clouds in datasets where points are collected via 3D imaging devices such as handheld scanners (Dai et al., 2017a; Armeni et al., 2016) and lidar (Geiger et al., 2012).\" Based on my experience, handheld scanners (RGB-D cameras or (multi-view) stereo cameras) produce much more noisy measurements with outliers while lidar sensors, especially for autonomous vehicles, typically produce sparser point clouds.\\n* Sec. 3.2 states that \"We observe that, in early stage the encoder is able to learn low-level geometric primitives, i.e., planes, cylinders and cones, while later the network recognises more complex shapes like wings, leafs and upper bodies (non-rigid).\" I am not sure how I see this in Fig. 3 since I don\\'t know what the color-coding signifies.\\n* Looking at Fig. 3, I am not sure whether the statement that \"clearly separable clusters are formed for different object classes\" is true. There seems to be quite some overlap between classes, but this is also a bit hard to tell given the small size of the figure.\\n* [Yang et al., PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows, ICCV 2019] and [Gadelha et al., Label-Efficient Learning on Point Clouds using Approximate Convex Decompositions, ECCV 2020]  both propose generative models for point clouds. Both of them show that they can be used for unsupervised representation learning and they show competitive results for the task of only training an SVM classifier on top of the learned representation for ModelNet. Both should be discussed in the related work.\\n\\n### After rebuttal phase ###\\nThe comments by the authors and the revised version of the paper successfully address my concerns. I thus recommend to accept the paper.',\n",
       "    'rating': '7: Good paper, accept',\n",
       "    'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'},\n",
       "   'signatures': ['ICLR.cc/2021/Conference/Paper992/AnonReviewer3'],\n",
       "   'readers': ['everyone'],\n",
       "   'nonreaders': [],\n",
       "   'writers': ['ICLR.cc/2021/Conference',\n",
       "    'ICLR.cc/2021/Conference/Paper992/AnonReviewer3']},\n",
       "  {'id': '1mCH5gO3d3O',\n",
       "   'original': None,\n",
       "   'number': 3,\n",
       "   'cdate': 1603809225462,\n",
       "   'ddate': None,\n",
       "   'tcdate': 1603809225462,\n",
       "   'tmdate': 1605024556831,\n",
       "   'tddate': None,\n",
       "   'forum': 'jPSYH47QSZL',\n",
       "   'replyto': 'jPSYH47QSZL',\n",
       "   'invitation': 'ICLR.cc/2021/Conference/Paper992/-/Official_Review',\n",
       "   'content': {'title': 'Limited novelty and weak improvements',\n",
       "    'review': 'The authors propose completing an occluded point cloud as a pretraining step for point cloud processing methods. Multiple occlusions are generated for the network to complete by simulating a camera perspective. \\n\\nPros: \\n- First work analyzing this specific pretraining for point clouds\\n\\nCons:\\n- Weak novelty\\n- Limited experimental reliability\\n\\nOverall, the novelty of the paper seems rather weak. The only novel contribution is the idea of point cloud completion as a pretraining task. This idea is rather simple and similar techniques are well known and used in other fields such as NLP. Hence, it does not represent a significant methodological advancement.\\nNevertheless, the paper would still be interesting if it showed extraordinary results in this particular field of application. Unfortunately, the experimental results seem weak as well. They show modest gains with respect to existing techniques and they lack any information on run-to-run variance. This makes it impossible to understand if the gains that are shown are statistically significant or just lucky runs with careful parameter tuning. ',\n",
       "    'rating': '4: Ok but not good enough - rejection',\n",
       "    'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'},\n",
       "   'signatures': ['ICLR.cc/2021/Conference/Paper992/AnonReviewer4'],\n",
       "   'readers': ['everyone'],\n",
       "   'nonreaders': [],\n",
       "   'writers': ['ICLR.cc/2021/Conference',\n",
       "    'ICLR.cc/2021/Conference/Paper992/AnonReviewer4']},\n",
       "  {'id': 'qFSx63oIHKN',\n",
       "   'original': None,\n",
       "   'number': 4,\n",
       "   'cdate': 1603853434431,\n",
       "   'ddate': None,\n",
       "   'tcdate': 1603853434431,\n",
       "   'tmdate': 1605024556759,\n",
       "   'tddate': None,\n",
       "   'forum': 'jPSYH47QSZL',\n",
       "   'replyto': 'jPSYH47QSZL',\n",
       "   'invitation': 'ICLR.cc/2021/Conference/Paper992/-/Official_Review',\n",
       "   'content': {'title': 'Since the idea itself is simple enough, the reviewer would not argue too much about the technical contribution of this paper, but concerns more about the analytic contributions. The reviewer’s concerns lie as follows.',\n",
       "    'review': 'The idea of this paper is simple but fascinating. Actually there are many studies concerning the task of point cloud completion, but using it as the initialization approach to improve the other tasks is quiet novel. The experimental results seem solid and quantitatively prove the effectiveness of the OcCo-initialization.\\n\\nSince the idea itself is simple enough, the reviewer would not argue too much about the technical contribution of this paper, but concerns more about the analytic contributions. The reviewer’s concerns are as follows.\\n1. In addition to verify the effectiveness of OcCo-initialization, more analysis on why this simple idea can take effect should also be given. For example, the author should go deeper to explain why OcCo-initialized PointNet can outperform the random initialized PointNet (e.g. by visualizing the learned features of the two kinds of PointNet, like Figure 3).\\n2. The idea of OcCo-initialization can be concluded as some kind of task oriented initialization approach. Considering the simplicity of this idea, similar initialization strategy can be formulated, such as pre-training network on segmentation task and apply them on classification task. So why the author only chooses the completion task as the initialization strategy, or if task oriented initialization can be considered as a universal strategy in point cloud processing?\\n3. Although the experimental results look solid, the reviewer still concerns if the proposed OcCo-initialization can achieve the SOTA results or close enough to the current SOTA. For example, PointCNN can achieve much better segmentation results compared to the methods in Table 3. So if the OcCo-initialization can still succeed in the PointCNN which has better ability of learning point cloud features?\\n4. The author is advised to clarify the necessity of Sec 2.1, which is the main part of the model description. In reviewer’s opinion, a method to generate partial point cloud from single view is essentially not a technical contribution for this paper.\\n',\n",
       "    'rating': '5: Marginally below acceptance threshold',\n",
       "    'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'},\n",
       "   'signatures': ['ICLR.cc/2021/Conference/Paper992/AnonReviewer2'],\n",
       "   'readers': ['everyone'],\n",
       "   'nonreaders': [],\n",
       "   'writers': ['ICLR.cc/2021/Conference',\n",
       "    'ICLR.cc/2021/Conference/Paper992/AnonReviewer2']},\n",
       "  {'id': 'ATOMBhg7w_L',\n",
       "   'original': None,\n",
       "   'number': 2,\n",
       "   'cdate': 1606029609903,\n",
       "   'ddate': None,\n",
       "   'tcdate': 1606029609903,\n",
       "   'tmdate': 1606029609903,\n",
       "   'tddate': None,\n",
       "   'forum': 'jPSYH47QSZL',\n",
       "   'replyto': 'jPSYH47QSZL',\n",
       "   'invitation': 'ICLR.cc/2021/Conference/Paper992/-/Official_Comment',\n",
       "   'content': {'title': 'Overall Response',\n",
       "    'comment': 'We thank all the reviewers for the time and comments! \\n\\nWe have brought a major update for our submission on:\\ni) Analysis on learned features in OcCo pre-training (in Sections 3.2, 3.3), using Feature Visualization (Olah et al., 2017), Network Dissection (Bau et al., 2017) and Clustering metrics (NMI, AMI) on the learned embeddings under SO(3) transformation. Our method shows superior performance over baselines under the transformation.\\nii) Few-shot learning (in Section 3.4), where we compare OcCo with a new baseline (Sharma & Kaul, 2020), as well as prior baselines. OcCo beats or matches the best method on 7 of the 8 settings.\\niii) Ran the hardest fine tuning classification and segmentation tasks (due to computational constraints) for three separate runs (Tables 3, 4, 5). OcCo shows meaningful improvements overall baselines.\\n\\nWe respond to each reviewers comments in detail below.\\n'},\n",
       "   'signatures': ['ICLR.cc/2021/Conference/Paper992/Authors'],\n",
       "   'readers': ['everyone'],\n",
       "   'nonreaders': [],\n",
       "   'writers': ['ICLR.cc/2021/Conference',\n",
       "    'ICLR.cc/2021/Conference/Paper992/Authors']},\n",
       "  {'id': 'dDH2ohBuWnx',\n",
       "   'original': None,\n",
       "   'number': 1,\n",
       "   'cdate': 1610040402548,\n",
       "   'ddate': None,\n",
       "   'tcdate': 1610040402548,\n",
       "   'tmdate': 1610473998669,\n",
       "   'tddate': None,\n",
       "   'forum': 'jPSYH47QSZL',\n",
       "   'replyto': 'jPSYH47QSZL',\n",
       "   'invitation': 'ICLR.cc/2021/Conference/Paper992/-/Decision',\n",
       "   'content': {'title': 'Final Decision',\n",
       "    'decision': 'Reject',\n",
       "    'comment': 'The paper proposes an unsupervised pretraining approach for 3D recognition, which is based on point cloud completion. The initial review receives a mixed rating, with two reviewers rate the paper below the bar and two above the bar. After the rebuttal, R3 changes the opinion from above the bar to a rejection recommendation. While several reviewers recognize the simplicity of the proposed method, R2 and R4 consider the proposed method a straightforward extension of known approaches for NLP and vision tasks. A lack of novelty was also pointed out as a weakness by R3 and R4. After consolidating the reviews and the rebuttal, the AC finds the weakness claims convincing and determines the paper is not ready for publication in the current form. '},\n",
       "   'signatures': ['ICLR.cc/2021/Conference/Program_Chairs'],\n",
       "   'readers': ['everyone'],\n",
       "   'nonreaders': [],\n",
       "   'writers': ['ICLR.cc/2021/Conference/Program_Chairs']}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'A good one',\n",
       "  'review': \"This paper proposes a better pre-trained prior for a variety of downstream applications in point cloud analysis. The workflow of the pre-training mechanism is to first 1) generate occluded points that result from view occlusion and then 2) optimize the encoder to learn how to complete the occluded points from the partial point cloud. In downstream applications, the obtained encoder will be used as the initial weights in the network training. Empirical experiments have shown that such a pre-train mechanism can improve initialization over prior baselines and benefit a variety of tasks even with a large domain gap.\\n\\nPros:\\n1. The experimental results have shown a steady improvement in performance by using the proposed pre-training approach in different encoder architectures and different downstream applications. That provides strong support for validating the effectiveness of the proposed approach.\\n2. I also like the result that the initialization is only pre-trained on the occlusions generated from the ModelNet40 but still work in another dataset. And yet, the pre-training is done in a self-supervised manner. This is a great plus for this approach as it indicates that it could be a general-purpose booster for a wide range of applications without spending too much effort in collecting special-purpose dataset for pre-training. \\n3. The paper is well written and presented.\\n\\nCons:\\n1. The improvement, as shown in the statistics, is very incremental in most cases. I understand it is difficult to achieve better results on well-established benchmarks, but it somehow indicates the improvement is limited.\\n2. Though the paper already stated some nice explanation of the idea behind this approach, I would appreciate it if a more in-depth analysis of why such a pre-training mechanism could work is provided. Specifically, I would like more analysis of why such a pre-training method can adapt to different datasets? What are the common features that OcCo captures across different datasets? \\nSome visualization similar to Figure 3 would be helpful.\\n\\n---- Final Rating ----\\n\\nThe authors' response has resolved my concerns. I would keep my positive rating.\",\n",
       "  'rating': '7: Good paper, accept'},\n",
       " {'title': 'paper shows promising results using point cloud completion tasks for pre-training representations, method is clearly described; however, highly related work not discussed that limits novelty of the proposed OcCo task, experimental setup not fully clear, making it hard to understand the results',\n",
       "  'review': 'The paper considers the problem of training networks for point cloud processing through a point cloud completion task. Given a point cloud, it is rendered from a set of viewpoints and for each viewpoint the set of visible points is determine. A network is then trained to generate the full point cloud from the partially observed point cloud for a given view. Here, an encoder-decoder architecture is used, where the encoder corresponds to the network that should be pre-trained. Experimental results show that the proposed method outperforms two baselines for three tasks (object classification, object part segmentation, and semantic segmentation), when using less training data, and that the pre-training on the occlusion task leads to faster convergence.\\n\\nOn the positive side, the occlusion completion (OcCo) task is clearly described and it should be fairly straightforward for a researcher to setup this task. The task requires no human annotation and is thus suitable for pre-training from large datasets captured in uncontrolled settings. The experiments cover a wide range of tasks and settings and show that the OcCo pre-training strategy outperforms random initialization and the approach from Saunders & Sievers. Here, the simplicity of the OcCo task coupled with its performance is clearly a major strength of the paper. In particular, Fig. 4 shows that the networks pre-trained on the OcCo task tend to converge much faster compared to the baselines.\\n\\nOn the negative side, I feel that the paper oversells the novelty of the OcCo task. The OcCo task is a variation of the (semantic) scene completion task that asks to complete a partial observation of a scene / object and is receiving attention in the computer vision community. Recent examples include [Dai et al.,  SG-NN: Sparse Generative Neural Networks for Self-Supervised Scene Completion of RGB-D Scans, CVPR 2020] and [Hou et al., RevealNet: Seeing Behind Objects in RGB-D Scans, CVPR 2020], with older works including [Firman et al., Structured prediction of unobserved voxels from a single depth image, CVPR 2016]. [Schönberger et al., Semantic Visual Localization, CVPR 2018] use (semantic) scene completion as a proxy task to train a 3D descriptors for 3D-3D matching between models. Given a voxelized partial observation of a scene, they train an encoder-decoder architecture to predict the complete volume (potentially also predicting semantic labels for each voxel). The embedding in the latent space are then used as 3D descriptors (i.e., the decoder part of the network is not needed at test time). In other words, they use the OcCo task for training their networks. They show that the learned representation generalizes between datasets and sensor modalities (training on 3D data obtained from stereo images, tested on LiDAR data). Given this result, I see limited novelty in using the OcCo task for pre-training point cloud networks and it does not seem very surprising that pre-training on the OcCo task should result in meaningful representations.\\n\\nMy second main point of criticism is the level of detail of the experimental evaluation. While the experiments cover a wide range of tasks and settings, I feel that crucial information needed to understand the results are missing:\\n1) Is the same dataset (ModelNet40) used to pre-train on the OcCo task also used to pre-train the JigSaw approach from Sauder & Sievers? Unfortunately, no details on the latter are provided in the main paper (or I was not able to find them), making it hard to understand how meaningful the comparison is.\\n2) There are no details on how the networks are trained for the different tasks, e.g., for how many epochs are the network trained for the task at hand?, do the networks converge for all pre-training strategies?\\n3) How significant are the improvements over the two baselines. For most considered settings, the improvements seem rather small, e.g., often less than 1 point compared to the Rand baseline in Tab. 2 and 3. Is this a meaningful improvment? Or would simply using a different random seed for training explain such a difference? Given that the paper claims that \"These results demonstrate that the OcCo-initialized models have strong transfer capabilities on out-of-domain datasets\" and that \"OcCo-initialized models achieve superior results compared to the randomly-initialized models\", this is an important question to answer.\\nI think there is enough space in the paper to include this information. Specifically, I do not think that Alg. 1 is necessary in the main paper (but would be good to have as an appendix) as the text and Fig. 1 already describe the approach in sufficient detail. Similarly, the z-Buffer algorithm is a classic computer graphics technique that is covered in basic lectures and does not need to be discussed in detail (e.g., see [Pittaluga et al., Revealing Scenes by Inverting Structure from Motion Reconstructions, CVPR 2019] briefly mentioning z-Buffering and the use of Delaunay triangulation for determining visibility). I think this space could be spend on providing more details.\\n\\nIn the current form, I do not think the paper is ready for publication as the paper, in my opinion, overclaims its contributions, misses relevant work (see also below), and misses crucial details necessary to understand the experimental results. As such, I am currently recommending to reject the paper. I believe that these issues can be addressed, but I would base my final recommendation based on the authors\\' feedback.\\n\\nHere are additional detailed comments:\\n* In Sec. 2.1, I do not understand the comment \"Our goal is to learn a randomized occlusion mapping o : P → P (where P is the space of all point clouds) from a full point cloud P to an occluded point cloud P\". As far as I can tell, the mapping is not learned but follows a fixed pipeline.\\n* I don\\'t understand how Eq. 2 \"most closely approximates the inverse of eq. (1)\". Eq. 2 is the inverse of Eq. 1. The only approximation that I could see if the 2D projection coordinates are rounded to the nearest integer.\\n* The introduction teases with the statement \"Current 3D sensing modalities (i.e., 3D scanners, stereo cameras, lidars) have enabled the creation of large repositories of point cloud data (Rusu & Cousins, 2011; Hackel et al., 2017).\" However, only synthetic data is used for pre-training, which is a bit disappointing. I am not convinced that the synthetic datasets \"are qualitatively similar to point clouds in datasets where points are collected via 3D imaging devices such as handheld scanners (Dai et al., 2017a; Armeni et al., 2016) and lidar (Geiger et al., 2012).\" Based on my experience, handheld scanners (RGB-D cameras or (multi-view) stereo cameras) produce much more noisy measurements with outliers while lidar sensors, especially for autonomous vehicles, typically produce sparser point clouds.\\n* Sec. 3.2 states that \"We observe that, in early stage the encoder is able to learn low-level geometric primitives, i.e., planes, cylinders and cones, while later the network recognises more complex shapes like wings, leafs and upper bodies (non-rigid).\" I am not sure how I see this in Fig. 3 since I don\\'t know what the color-coding signifies.\\n* Looking at Fig. 3, I am not sure whether the statement that \"clearly separable clusters are formed for different object classes\" is true. There seems to be quite some overlap between classes, but this is also a bit hard to tell given the small size of the figure.\\n* [Yang et al., PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows, ICCV 2019] and [Gadelha et al., Label-Efficient Learning on Point Clouds using Approximate Convex Decompositions, ECCV 2020]  both propose generative models for point clouds. Both of them show that they can be used for unsupervised representation learning and they show competitive results for the task of only training an SVM classifier on top of the learned representation for ModelNet. Both should be discussed in the related work.\\n\\n### After rebuttal phase ###\\nThe comments by the authors and the revised version of the paper successfully address my concerns. I thus recommend to accept the paper.',\n",
       "  'rating': '7: Good paper, accept'},\n",
       " {'title': 'Limited novelty and weak improvements',\n",
       "  'review': 'The authors propose completing an occluded point cloud as a pretraining step for point cloud processing methods. Multiple occlusions are generated for the network to complete by simulating a camera perspective. \\n\\nPros: \\n- First work analyzing this specific pretraining for point clouds\\n\\nCons:\\n- Weak novelty\\n- Limited experimental reliability\\n\\nOverall, the novelty of the paper seems rather weak. The only novel contribution is the idea of point cloud completion as a pretraining task. This idea is rather simple and similar techniques are well known and used in other fields such as NLP. Hence, it does not represent a significant methodological advancement.\\nNevertheless, the paper would still be interesting if it showed extraordinary results in this particular field of application. Unfortunately, the experimental results seem weak as well. They show modest gains with respect to existing techniques and they lack any information on run-to-run variance. This makes it impossible to understand if the gains that are shown are statistically significant or just lucky runs with careful parameter tuning. ',\n",
       "  'rating': '4: Ok but not good enough - rejection'},\n",
       " {'title': 'Since the idea itself is simple enough, the reviewer would not argue too much about the technical contribution of this paper, but concerns more about the analytic contributions. The reviewer’s concerns lie as follows.',\n",
       "  'review': 'The idea of this paper is simple but fascinating. Actually there are many studies concerning the task of point cloud completion, but using it as the initialization approach to improve the other tasks is quiet novel. The experimental results seem solid and quantitatively prove the effectiveness of the OcCo-initialization.\\n\\nSince the idea itself is simple enough, the reviewer would not argue too much about the technical contribution of this paper, but concerns more about the analytic contributions. The reviewer’s concerns are as follows.\\n1. In addition to verify the effectiveness of OcCo-initialization, more analysis on why this simple idea can take effect should also be given. For example, the author should go deeper to explain why OcCo-initialized PointNet can outperform the random initialized PointNet (e.g. by visualizing the learned features of the two kinds of PointNet, like Figure 3).\\n2. The idea of OcCo-initialization can be concluded as some kind of task oriented initialization approach. Considering the simplicity of this idea, similar initialization strategy can be formulated, such as pre-training network on segmentation task and apply them on classification task. So why the author only chooses the completion task as the initialization strategy, or if task oriented initialization can be considered as a universal strategy in point cloud processing?\\n3. Although the experimental results look solid, the reviewer still concerns if the proposed OcCo-initialization can achieve the SOTA results or close enough to the current SOTA. For example, PointCNN can achieve much better segmentation results compared to the methods in Table 3. So if the OcCo-initialization can still succeed in the PointCNN which has better ability of learning point cloud features?\\n4. The author is advised to clarify the necessity of Sec 2.1, which is the main part of the model description. In reviewer’s opinion, a method to generate partial point cloud from single view is essentially not a technical contribution for this paper.\\n',\n",
       "  'rating': '5: Marginally below acceptance threshold'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_review_messages(random_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "for paper in random_reviews:\n",
    "    title = paper['basic_dict']['title']\n",
    "    pdf_url = paper['basic_dict']['pdf_url']\n",
    "    abstract = paper['basic_dict']['abstract']\n",
    "    authors = paper['basic_dict']['authors'] \n",
    "    reviews = extract_review_messages(paper)\n",
    "    \n",
    "    for review in reviews:\n",
    "        examples.append({\n",
    "            'title': title,\n",
    "            'url': pdf_url,\n",
    "            'abstract': abstract,\n",
    "            'authors': authors,\n",
    "            'review_title': review['title'],\n",
    "            'review': review['review'],\n",
    "            'rating': review['rating']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>A good one</td>\n",
       "      <td>This paper proposes a better pre-trained prior...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>paper shows promising results using point clou...</td>\n",
       "      <td>The paper considers the problem of training ne...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>Limited novelty and weak improvements</td>\n",
       "      <td>The authors propose completing an occluded poi...</td>\n",
       "      <td>4: Ok but not good enough - rejection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>Since the idea itself is simple enough, the re...</td>\n",
       "      <td>The idea of this paper is simple but fascinati...</td>\n",
       "      <td>5: Marginally below acceptance threshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GamePad: A Learning Environment for Theorem Pr...</td>\n",
       "      <td>https://openreview.net/pdf?id=r1xwKoR9Y7</td>\n",
       "      <td>In this paper, we introduce a system called Ga...</td>\n",
       "      <td>Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...</td>\n",
       "      <td>An intriguing integration of ML and automated ...</td>\n",
       "      <td>Summary: This paper mixes automated theorem pr...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GamePad: A Learning Environment for Theorem Pr...</td>\n",
       "      <td>https://openreview.net/pdf?id=r1xwKoR9Y7</td>\n",
       "      <td>In this paper, we introduce a system called Ga...</td>\n",
       "      <td>Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...</td>\n",
       "      <td>Nice exposition on the opportunities and the i...</td>\n",
       "      <td>In the paper, the authors describe how machine...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GamePad: A Learning Environment for Theorem Pr...</td>\n",
       "      <td>https://openreview.net/pdf?id=r1xwKoR9Y7</td>\n",
       "      <td>In this paper, we introduce a system called Ga...</td>\n",
       "      <td>Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...</td>\n",
       "      <td>Interesting direction, but too preliminary</td>\n",
       "      <td>The submission describes a system for applying...</td>\n",
       "      <td>4: Ok but not good enough - rejection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Generalisation and the Geometry of Class Separ...</td>\n",
       "      <td>https://openreview.net/pdf?id=4NtqESjOIAz</td>\n",
       "      <td>Recent results in deep learning show that cons...</td>\n",
       "      <td>Dominic Belcher,Adam Prugel-Bennett,Srinandan ...</td>\n",
       "      <td>Linear separability in layers.</td>\n",
       "      <td>This work investigates how linearly separable ...</td>\n",
       "      <td>6: Marginally above acceptance threshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Generalisation and the Geometry of Class Separ...</td>\n",
       "      <td>https://openreview.net/pdf?id=4NtqESjOIAz</td>\n",
       "      <td>Recent results in deep learning show that cons...</td>\n",
       "      <td>Dominic Belcher,Adam Prugel-Bennett,Srinandan ...</td>\n",
       "      <td>Review</td>\n",
       "      <td>This paper attempts to explain the generalizat...</td>\n",
       "      <td>6: Marginally above acceptance threshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Using Anomaly Feature Vectors for Detecting, C...</td>\n",
       "      <td>https://openreview.net/pdf?id=XDo0go2IJgT</td>\n",
       "      <td>We present DeClaW, a system for detecting, cla...</td>\n",
       "      <td>Nelson Manohar-Alers,Ryan Feng,Sahib Singh,Jig...</td>\n",
       "      <td>A method to classify clean image and adversari...</td>\n",
       "      <td>This paper proposed a DNN-based attack-type cl...</td>\n",
       "      <td>Accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PERIL: Probabilistic Embeddings for hybrid Met...</td>\n",
       "      <td>https://openreview.net/pdf?id=BIIwfP55pp</td>\n",
       "      <td>Imitation learning is a natural way for a huma...</td>\n",
       "      <td>Alvaro Prat,Edward Johns</td>\n",
       "      <td>Review</td>\n",
       "      <td>Summary: This work seeks to efficiently learn ...</td>\n",
       "      <td>4: Ok but not good enough - rejection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PERIL: Probabilistic Embeddings for hybrid Met...</td>\n",
       "      <td>https://openreview.net/pdf?id=BIIwfP55pp</td>\n",
       "      <td>Imitation learning is a natural way for a huma...</td>\n",
       "      <td>Alvaro Prat,Edward Johns</td>\n",
       "      <td>A very ambitious work which falls short on the...</td>\n",
       "      <td>## Summary of the Work\\nThe work propose a met...</td>\n",
       "      <td>3: Clear rejection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PERIL: Probabilistic Embeddings for hybrid Met...</td>\n",
       "      <td>https://openreview.net/pdf?id=BIIwfP55pp</td>\n",
       "      <td>Imitation learning is a natural way for a huma...</td>\n",
       "      <td>Alvaro Prat,Edward Johns</td>\n",
       "      <td>Writing is not clear and needs some work, Conn...</td>\n",
       "      <td>## Summary of work\\nThis work proposes PERIL, ...</td>\n",
       "      <td>4: Ok but not good enough - rejection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PERIL: Probabilistic Embeddings for hybrid Met...</td>\n",
       "      <td>https://openreview.net/pdf?id=BIIwfP55pp</td>\n",
       "      <td>Imitation learning is a natural way for a huma...</td>\n",
       "      <td>Alvaro Prat,Edward Johns</td>\n",
       "      <td>review</td>\n",
       "      <td>Summary:\\n\\nThis paper introduces PERIL, a met...</td>\n",
       "      <td>4: Ok but not good enough - rejection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C-Learning: Learning to Achieve Goals via Recu...</td>\n",
       "      <td>https://openreview.net/pdf?id=tc5qisoB-C</td>\n",
       "      <td>We study the problem of predicting and control...</td>\n",
       "      <td>Benjamin Eysenbach,Ruslan Salakhutdinov,Sergey...</td>\n",
       "      <td>Good idea, but confusing manuscripts.</td>\n",
       "      <td>The authors propose a new algorithm, called C-...</td>\n",
       "      <td>6: Marginally above acceptance threshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C-Learning: Learning to Achieve Goals via Recu...</td>\n",
       "      <td>https://openreview.net/pdf?id=tc5qisoB-C</td>\n",
       "      <td>We study the problem of predicting and control...</td>\n",
       "      <td>Benjamin Eysenbach,Ruslan Salakhutdinov,Sergey...</td>\n",
       "      <td>well written and clear</td>\n",
       "      <td>Summary:\\nThis work presents a goal-conditione...</td>\n",
       "      <td>8: Top 50% of accepted papers, clear accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C-Learning: Learning to Achieve Goals via Recu...</td>\n",
       "      <td>https://openreview.net/pdf?id=tc5qisoB-C</td>\n",
       "      <td>We study the problem of predicting and control...</td>\n",
       "      <td>Benjamin Eysenbach,Ruslan Salakhutdinov,Sergey...</td>\n",
       "      <td>Interesting and relevant to UOM paper but rele...</td>\n",
       "      <td>This paper studies a problem of predicting fut...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C-Learning: Learning to Achieve Goals via Recu...</td>\n",
       "      <td>https://openreview.net/pdf?id=tc5qisoB-C</td>\n",
       "      <td>We study the problem of predicting and control...</td>\n",
       "      <td>Benjamin Eysenbach,Ruslan Salakhutdinov,Sergey...</td>\n",
       "      <td>Building probability density of reaching a fut...</td>\n",
       "      <td>This paper explores learning a classifier to p...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C-Learning: Learning to Achieve Goals via Recu...</td>\n",
       "      <td>https://openreview.net/pdf?id=tc5qisoB-C</td>\n",
       "      <td>We study the problem of predicting and control...</td>\n",
       "      <td>Benjamin Eysenbach,Ruslan Salakhutdinov,Sergey...</td>\n",
       "      <td>Official Blind Review #5</td>\n",
       "      <td>[summary]\\nThis paper studies to predict futur...</td>\n",
       "      <td>4: Ok but not good enough - rejection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Unsupervised Learning of Node Embeddings by De...</td>\n",
       "      <td>https://openreview.net/pdf?id=Byl3K2VtwB</td>\n",
       "      <td>We present Deep MinCut (DMC), an unsupervised ...</td>\n",
       "      <td>Chi Thang Duong,Dung Hoang,Truong Giang Le Ba,...</td>\n",
       "      <td>Official Blind Review #3</td>\n",
       "      <td>This paper is reporting an unsupervised approa...</td>\n",
       "      <td>3: Weak Reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Unsupervised Learning of Node Embeddings by De...</td>\n",
       "      <td>https://openreview.net/pdf?id=Byl3K2VtwB</td>\n",
       "      <td>We present Deep MinCut (DMC), an unsupervised ...</td>\n",
       "      <td>Chi Thang Duong,Dung Hoang,Truong Giang Le Ba,...</td>\n",
       "      <td>Official Blind Review #3</td>\n",
       "      <td>Although this paper seems to only combine exis...</td>\n",
       "      <td>3: Weak Reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Unsupervised Learning of Node Embeddings by De...</td>\n",
       "      <td>https://openreview.net/pdf?id=Byl3K2VtwB</td>\n",
       "      <td>We present Deep MinCut (DMC), an unsupervised ...</td>\n",
       "      <td>Chi Thang Duong,Dung Hoang,Truong Giang Le Ba,...</td>\n",
       "      <td>Official Blind Review #1</td>\n",
       "      <td>This work proposes a neural netowrk approach t...</td>\n",
       "      <td>3: Weak Reject</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0             Pre-Training by Completing Point Clouds   \n",
       "1             Pre-Training by Completing Point Clouds   \n",
       "2             Pre-Training by Completing Point Clouds   \n",
       "3             Pre-Training by Completing Point Clouds   \n",
       "4   GamePad: A Learning Environment for Theorem Pr...   \n",
       "5   GamePad: A Learning Environment for Theorem Pr...   \n",
       "6   GamePad: A Learning Environment for Theorem Pr...   \n",
       "7   Generalisation and the Geometry of Class Separ...   \n",
       "8   Generalisation and the Geometry of Class Separ...   \n",
       "9   Using Anomaly Feature Vectors for Detecting, C...   \n",
       "10  PERIL: Probabilistic Embeddings for hybrid Met...   \n",
       "11  PERIL: Probabilistic Embeddings for hybrid Met...   \n",
       "12  PERIL: Probabilistic Embeddings for hybrid Met...   \n",
       "13  PERIL: Probabilistic Embeddings for hybrid Met...   \n",
       "14  C-Learning: Learning to Achieve Goals via Recu...   \n",
       "15  C-Learning: Learning to Achieve Goals via Recu...   \n",
       "16  C-Learning: Learning to Achieve Goals via Recu...   \n",
       "17  C-Learning: Learning to Achieve Goals via Recu...   \n",
       "18  C-Learning: Learning to Achieve Goals via Recu...   \n",
       "19  Unsupervised Learning of Node Embeddings by De...   \n",
       "20  Unsupervised Learning of Node Embeddings by De...   \n",
       "21  Unsupervised Learning of Node Embeddings by De...   \n",
       "\n",
       "                                          url  \\\n",
       "0   https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "1   https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "2   https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "3   https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "4    https://openreview.net/pdf?id=r1xwKoR9Y7   \n",
       "5    https://openreview.net/pdf?id=r1xwKoR9Y7   \n",
       "6    https://openreview.net/pdf?id=r1xwKoR9Y7   \n",
       "7   https://openreview.net/pdf?id=4NtqESjOIAz   \n",
       "8   https://openreview.net/pdf?id=4NtqESjOIAz   \n",
       "9   https://openreview.net/pdf?id=XDo0go2IJgT   \n",
       "10   https://openreview.net/pdf?id=BIIwfP55pp   \n",
       "11   https://openreview.net/pdf?id=BIIwfP55pp   \n",
       "12   https://openreview.net/pdf?id=BIIwfP55pp   \n",
       "13   https://openreview.net/pdf?id=BIIwfP55pp   \n",
       "14   https://openreview.net/pdf?id=tc5qisoB-C   \n",
       "15   https://openreview.net/pdf?id=tc5qisoB-C   \n",
       "16   https://openreview.net/pdf?id=tc5qisoB-C   \n",
       "17   https://openreview.net/pdf?id=tc5qisoB-C   \n",
       "18   https://openreview.net/pdf?id=tc5qisoB-C   \n",
       "19   https://openreview.net/pdf?id=Byl3K2VtwB   \n",
       "20   https://openreview.net/pdf?id=Byl3K2VtwB   \n",
       "21   https://openreview.net/pdf?id=Byl3K2VtwB   \n",
       "\n",
       "                                             abstract  \\\n",
       "0   There has recently been a flurry of exciting a...   \n",
       "1   There has recently been a flurry of exciting a...   \n",
       "2   There has recently been a flurry of exciting a...   \n",
       "3   There has recently been a flurry of exciting a...   \n",
       "4   In this paper, we introduce a system called Ga...   \n",
       "5   In this paper, we introduce a system called Ga...   \n",
       "6   In this paper, we introduce a system called Ga...   \n",
       "7   Recent results in deep learning show that cons...   \n",
       "8   Recent results in deep learning show that cons...   \n",
       "9   We present DeClaW, a system for detecting, cla...   \n",
       "10  Imitation learning is a natural way for a huma...   \n",
       "11  Imitation learning is a natural way for a huma...   \n",
       "12  Imitation learning is a natural way for a huma...   \n",
       "13  Imitation learning is a natural way for a huma...   \n",
       "14  We study the problem of predicting and control...   \n",
       "15  We study the problem of predicting and control...   \n",
       "16  We study the problem of predicting and control...   \n",
       "17  We study the problem of predicting and control...   \n",
       "18  We study the problem of predicting and control...   \n",
       "19  We present Deep MinCut (DMC), an unsupervised ...   \n",
       "20  We present Deep MinCut (DMC), an unsupervised ...   \n",
       "21  We present Deep MinCut (DMC), an unsupervised ...   \n",
       "\n",
       "                                              authors  \\\n",
       "0   Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "1   Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "2   Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "3   Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "4   Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...   \n",
       "5   Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...   \n",
       "6   Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...   \n",
       "7   Dominic Belcher,Adam Prugel-Bennett,Srinandan ...   \n",
       "8   Dominic Belcher,Adam Prugel-Bennett,Srinandan ...   \n",
       "9   Nelson Manohar-Alers,Ryan Feng,Sahib Singh,Jig...   \n",
       "10                           Alvaro Prat,Edward Johns   \n",
       "11                           Alvaro Prat,Edward Johns   \n",
       "12                           Alvaro Prat,Edward Johns   \n",
       "13                           Alvaro Prat,Edward Johns   \n",
       "14  Benjamin Eysenbach,Ruslan Salakhutdinov,Sergey...   \n",
       "15  Benjamin Eysenbach,Ruslan Salakhutdinov,Sergey...   \n",
       "16  Benjamin Eysenbach,Ruslan Salakhutdinov,Sergey...   \n",
       "17  Benjamin Eysenbach,Ruslan Salakhutdinov,Sergey...   \n",
       "18  Benjamin Eysenbach,Ruslan Salakhutdinov,Sergey...   \n",
       "19  Chi Thang Duong,Dung Hoang,Truong Giang Le Ba,...   \n",
       "20  Chi Thang Duong,Dung Hoang,Truong Giang Le Ba,...   \n",
       "21  Chi Thang Duong,Dung Hoang,Truong Giang Le Ba,...   \n",
       "\n",
       "                                         review_title  \\\n",
       "0                                          A good one   \n",
       "1   paper shows promising results using point clou...   \n",
       "2               Limited novelty and weak improvements   \n",
       "3   Since the idea itself is simple enough, the re...   \n",
       "4   An intriguing integration of ML and automated ...   \n",
       "5   Nice exposition on the opportunities and the i...   \n",
       "6          Interesting direction, but too preliminary   \n",
       "7                      Linear separability in layers.   \n",
       "8                                              Review   \n",
       "9   A method to classify clean image and adversari...   \n",
       "10                                             Review   \n",
       "11  A very ambitious work which falls short on the...   \n",
       "12  Writing is not clear and needs some work, Conn...   \n",
       "13                                             review   \n",
       "14              Good idea, but confusing manuscripts.   \n",
       "15                             well written and clear   \n",
       "16  Interesting and relevant to UOM paper but rele...   \n",
       "17  Building probability density of reaching a fut...   \n",
       "18                           Official Blind Review #5   \n",
       "19                           Official Blind Review #3   \n",
       "20                           Official Blind Review #3   \n",
       "21                           Official Blind Review #1   \n",
       "\n",
       "                                               review  \\\n",
       "0   This paper proposes a better pre-trained prior...   \n",
       "1   The paper considers the problem of training ne...   \n",
       "2   The authors propose completing an occluded poi...   \n",
       "3   The idea of this paper is simple but fascinati...   \n",
       "4   Summary: This paper mixes automated theorem pr...   \n",
       "5   In the paper, the authors describe how machine...   \n",
       "6   The submission describes a system for applying...   \n",
       "7   This work investigates how linearly separable ...   \n",
       "8   This paper attempts to explain the generalizat...   \n",
       "9   This paper proposed a DNN-based attack-type cl...   \n",
       "10  Summary: This work seeks to efficiently learn ...   \n",
       "11  ## Summary of the Work\\nThe work propose a met...   \n",
       "12  ## Summary of work\\nThis work proposes PERIL, ...   \n",
       "13  Summary:\\n\\nThis paper introduces PERIL, a met...   \n",
       "14  The authors propose a new algorithm, called C-...   \n",
       "15  Summary:\\nThis work presents a goal-conditione...   \n",
       "16  This paper studies a problem of predicting fut...   \n",
       "17  This paper explores learning a classifier to p...   \n",
       "18  [summary]\\nThis paper studies to predict futur...   \n",
       "19  This paper is reporting an unsupervised approa...   \n",
       "20  Although this paper seems to only combine exis...   \n",
       "21  This work proposes a neural netowrk approach t...   \n",
       "\n",
       "                                         rating  \n",
       "0                         7: Good paper, accept  \n",
       "1                         7: Good paper, accept  \n",
       "2         4: Ok but not good enough - rejection  \n",
       "3      5: Marginally below acceptance threshold  \n",
       "4                         7: Good paper, accept  \n",
       "5                         7: Good paper, accept  \n",
       "6         4: Ok but not good enough - rejection  \n",
       "7      6: Marginally above acceptance threshold  \n",
       "8      6: Marginally above acceptance threshold  \n",
       "9                                        Accept  \n",
       "10        4: Ok but not good enough - rejection  \n",
       "11                           3: Clear rejection  \n",
       "12        4: Ok but not good enough - rejection  \n",
       "13        4: Ok but not good enough - rejection  \n",
       "14     6: Marginally above acceptance threshold  \n",
       "15  8: Top 50% of accepted papers, clear accept  \n",
       "16                        7: Good paper, accept  \n",
       "17                        7: Good paper, accept  \n",
       "18        4: Ok but not good enough - rejection  \n",
       "19                               3: Weak Reject  \n",
       "20                               3: Weak Reject  \n",
       "21                               3: Weak Reject  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df = pd.DataFrame(examples)\n",
    "toy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the toy dataset\n",
    "toy_df.to_csv('toy_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "review_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
