{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Overview\n",
    "\n",
    "This notebook demonstrates the evaluation process of reviews generated by Large Language Models (LLMs) by comparing them with original human-generated reviews. The evaluation workflow consists of the following steps:\n",
    "\n",
    "1. **Summarization:** Both the human-generated reviews and the LLM-generated reviews are summarized.\n",
    "2. **Matching Summarized Points:** The summarized points from both sets of reviews are compared to identify matches.\n",
    "3. **Evaluation Metrics:** We calculate several metrics to assess the quality and similarity of the generated reviews relative to the human reviews. These metrics include:\n",
    "   - Hit Rate\n",
    "   - Jaccard Index\n",
    "   - Szymkiewicz–Simpson Overlap Coefficient\n",
    "   - Sørensen–Dice Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from typing import List, Tuple\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import clean_json_output\n",
    "from prompts import SUMMARY_PROMPT, REVIEW_COMPARISON_RPOMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "client = openai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Review Generation and Evaluation\n",
    "\n",
    "In this example, we use the paper titled \"Cyclic Orthogonal Convolutions for Long-Range Integration of Features\" to demonstrate the review generation and evaluation process. You can access the paper [here](https://openreview.net/pdf?id=868DWd46dv2). The human-generated reviews were obtained from the OpenReview platform, while the reviews generated by the LLM are produced using the GPT-4 Turbo model. This setup allows us to compare the effectiveness of automated review generation against human expert reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Cyclic Orthogonal Convolutions for Long-Range Integration of Features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_human_reviews = [\n",
    "    \"\"\"\n",
    "    The paper proposes cyclic orthogonal convolutions as a means to grow receptive fields fast in CNNs. The authors show a small improvement of their cyclic convolution model over a simple CNN baseline on CIFAR-10, ImageNet and Stylized ImageNet. Overall it's an interesting idea, but not executed very convincingly.\n",
    "\n",
    "    The biological motivation is weak at best. Long-range horizontal connections in cortex, which the authors use as motivation, are feature specific, i.e. between corresponding orientation domains. In contrast, in the authors' setup, they interact across all features. Moreover, the long-range connections are only along the x and y direction, but not in oblique directions. In my opinion, the author's proposal is not closer to biology than vision transformers, which also provide an all-to-all spatial interaction, albeit with a different mechanism and arguably stronger performance on large-scale datasets.\n",
    "\n",
    "    The experiments with simple CNNs are nice and show a trend in the right direction, but in order to show that the cyclic convolutions are also of practical use, more extensive and competitive results would be necessary. The authors argue that also in ResNets receptive fields grow sublinearly with depth. If that's the case, why don't they show that incorporating cyclic orthogonal convolutions improves a standard ResNet-50 model on ImageNet?\n",
    "\n",
    "    I don't find the pathfinder results very convincing. It has been shown before (this workshop, last year) that CNNs can also learn Pathfinder once the training setup is slightly adjusted \"\"\", \n",
    "    \"\"\"\n",
    "    This paper attempts to enable CNNs to learn long range spatial dependencies, typically only possible at great depth, in the early layers. To acheive this the authors propose CycleNet, a network of 'cycles' of orthogonal convolutions. These convolutions are performed across the three coordinate planes and have a subtaintially larger receptive field than a typical convolution without a dramatic increase in the number of parameters. The motivation for this work is comprehensive and the architecture is well described and intuitive. Experimental results show that CycleNet significantly improves performance over a baseline on the pathfinder challenge and also provides a modest improvement / increase in parameter efficiency on CIFAR-10.\n",
    "\n",
    "    The authors touch on a biological basis for the ideas explored here but I feel that the full potential of this line of reasoning is not realised. For example, the authors show improved generalisation to stylised ImageNet only in an Appendix when it is arguably among the most exciting results of the paper. These could be further augmented with the addition of other biological similarity measures such as the brain-score (https://www.brain-score.org/). Finally, it would be valuable for the authors to delve deeper into the related biology, perhaps identifying specific cell types or psychophysical results that they feel are better represented by the CycleNet model.\n",
    "\n",
    "    Overall, this is a well presented and clearly motivated work with promising results, a strong accept.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    This article proposes a convolutional network architecture to address the lack of connectivity between features of spatially distant locations within a layer. The authors propose CycleNet, which consists of the concatenation of convolutional operations on the three pairs dimensions - (x, y), (x, z) and (y, z) - instead of only on (x, y). The paper studies several properties of CycleNet compared to some baselines models: the performance on CIFAR-10, the receptive field size of the learnt features and the performance on the Pathfinder challenge.\n",
    "\n",
    "    This is a well written paper, which presents a simple and reasonable idea to address a weakness of standard convolutional models - the lack of connectivity between distant pixels or features. While the analysis of the proposed architecture does not outperform standard models on image classification tasks, the performance is close enough and, importantly, the experiments show the advantageous properties of CycleNet on other dimensions beyond classification accuracy, such as the receptive field size of the features and the performance on other tasks such as Pathfinder. I think the choice of experiments is sound and extensive enough for a workshop submission. Therefore, I have a generally positive impression of this paper and I recommend its acceptance to the SVRHM 2021.\n",
    "\n",
    "    Nonetheless, I have a few comments about potential weakness or aspects that could be improved, as well as some questions. First, I believe that the paper should more transparently present the less positive results of CycleNet from the experimental setup. For example, the authors show the performance on CIFAR-10 compared to a basic CNN baseline in Figure 3 of the main body of the paper, but leave for the supplementary material the results on ImageNet, where CycleNet achieve comparably worse classification accuracy. I argue that this introduces an analytical bias that can be misleading. Second, I think the paper could be improved by more in-depth discussion of the limitations of the proposal and directions for future work. Finally, I would also have appreciated a longer discussion on what the gap is that this new architecture aims to fill if the issue it addresses can be mitigated or solved by architectures such as transformers. I encourage the authors to consider these changes for their camera-ready version, if the paper is accepted.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gpt4_reviews = [\n",
    "    \"\"\"\n",
    "    [Significance and novelty]\n",
    "    1. The paper proposes a novel architecture, CycleNet, based on cyclic orthogonal convolutions that allows efficient information flow between features and locations across an entire image with a small number of layers. [2. The architecture differs from standard Convolutional Neural Networks (CNNs) as it allows for long-range integration of features in (x, y), (x, z), and (y, z) coordinates through the use of a cycle of three orthogonal convolutions. 3. CycleNet obtains competitive results on image classification tasks on CIFAR-10 and ImageNet datasets, while transferring better to stylised images and outperforming CNNs on the Pathfinder challenge, where integration of distant features is crucial. 4. The study hypothesizes that long-range integration favours recognition of objects by shape rather than texture, adding to the significance and novelty of the research.\n",
    "\n",
    "    [Potential reasons for acceptance]\n",
    "    1. The paper presents a novel architecture, CycleNet, which uses cyclic orthogonal convolutions, a new approach for long-range integration of features in CNNs. [2. The paper's experimental results show that CycleNet obtains competitive performance on image classification tasks on CIFAR-10 and ImageNet datasets. 3. CycleNet transfers better than CNNs to stylised images and outperforms them on the Pathfinder challenge, where integration of distant features is crucial. 4. The study provides insights into the importance of long-range integration of features for efficient recognition, contributing to the advancement of knowledge in the field.\n",
    "\n",
    "    [Potential reasons for rejection]\n",
    "    1. The paper lacks a comprehensive comparison with state-of-the-art methods for long-range integration of features in CNNs. [2. Some parts of the paper, particularly the theoretical explanations, can be unclear or lack sufficient detail. 3. The study could benefit from a more detailed experimental setup, such as more diverse datasets or a larger number of experiments, to further validate the proposed architecture's efficacy. 4. The authors fail to provide a clear explanation of why cyclic orthogonal convolutions lead to efficient long-range integration, and some explanations might require further justification or validation.\n",
    "\n",
    "    [Suggestions for improvement]\n",
    "    1. Conduct a comprehensive comparison with existing methods for long-range integration of features in CNNs and provide a detailed analysis of the results and performance differences. [2. Clarify the theoretical explanations and provide detailed, comprehensive justifications for the choices made in the design of the proposed architecture. 3. Provide a more detailed experimental setup, including more diverse datasets, a larger number of experiments, and control groups for a quantitative comparison of the proposed architecture's efficacy. 4. Validate the hypothesis by investigating the role of long-range integration of features in other recognition tasks or applications, and extend the research by implementing variations of the proposed architecture.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_reviews(reviews: List[str], title: str, client: openai.Client) -> Tuple[str, int]:\n",
    "    \"\"\"\n",
    "    Summarizes a list of reviews using the OpenAI GPT-4 model, formatting the result as a JSON string.\n",
    "\n",
    "    Args:\n",
    "        reviews (List[str]): List of review strings to be summarized.\n",
    "        title (str): Title of the subject to which the reviews pertain.\n",
    "        client (openai.Client): OpenAI client instance used to send requests to the GPT-4 model.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, int]: A tuple containing the JSON-formatted summary of reviews and the length of the output.\n",
    "    \"\"\"\n",
    "    # Construct the review messages with proper formatting\n",
    "    review_messages = \"\\n\\n\".join(reviews) + \"\\n\\n\"\n",
    "    prompt = SUMMARY_PROMPT.format(Title=title, Review_Text=review_messages)\n",
    "\n",
    "    # Use the GPT-4 model to generate a summary\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\", \n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    # Extract and clean the JSON output\n",
    "    output = clean_json_output(completion.choices[0].message.content)\n",
    "    length = len(json.loads(output))\n",
    "    \n",
    "    return output, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"1\": {\n",
      "        \"summary\": \"Weak biological motivation and lack of improved results on standard CNN applications like ResNet.\",\n",
      "        \"verbatim\": \"The biological motivation is weak at best. Long-range horizontal connections in cortex, which the authors use as motivation, are feature specific, i.e. between corresponding orientation domains. In contrast, in the authors' setup, they interact across all features. Moreover, the long-range connections are only along the x and y direction, but not in oblique directions. In my opinion, the author's proposal is not closer to biology than vision transformers, which also provide an all-to-all spatial interaction, albeit with a different mechanism and arguably stronger performance on large-scale datasets. If that's the case, why don't they show that incorporating cyclic orthogonal convolutions improves a standard ResNet-50 model on ImageNet?\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"summary\": \"Insufficient convincing performance data and transparency in reporting results across different datasets.\",\n",
      "        \"verbatim\": \"I don't find the pathfinder results very convincing. It has been shown before (this workshop, last year) that CNNs can also learn Pathfinder once the training setup is slightly adjusted. The authors show the performance on CIFAR-10 compared to a basic CNN baseline in Figure 3 of the main body of the paper, but leave for the supplementary material the results on ImageNet, where CycleNet achieve comparably worse classification accuracy.\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"summary\": \"Incomplete exploration of biological basis, and insufficient discussion on limitations and potential negative results.\",\n",
      "        \"verbatim\": \"The authors touch on a biological basis for the ideas explored here but I feel that the full potential of this line of reasoning is not realised. The paper should more transparently present the less positive results of CycleNet from the experimental setup. I think the paper could be improved by more in-depth discussion of the limitations of the proposal and directions for future work.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "human_reviews_summary, human_review_summary_length = summary_reviews(example_human_reviews, title=title, client=client)\n",
    "print(human_reviews_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"1\": {\n",
      "        \"summary\": \"Lacks a comprehensive comparison with state-of-the-art methods.\",\n",
      "        \"verbatim\": \"The paper lacks a comprehensive comparison with state-of-the-art methods for long-range integration of features in CNNs.\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"summary\": \"Theoretical explanations are unclear or insufficiently detailed.\",\n",
      "        \"verbatim\": \"Some parts of the paper, particularly the theoretical explanations, can be unclear or lack sufficient detail.\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"summary\": \"Experimental setup needs more diversity and expansiveness.\",\n",
      "        \"verbatim\": \"The study could benefit from a more detailed experimental setup, such as more diverse datasets or a larger number of experiments, to further validate the proposed architecture's efficacy.\"\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"summary\": \"Lacks clear explanation and justification for the efficiency of cyclic orthogonal convolutions.\",\n",
      "        \"verbatim\": \"The authors fail to provide a clear explanation of why cyclic orthogonal convolutions lead to efficient long-range integration, and some explanations might require further justification or validation.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "gpt_reviews_summary, gpt_reviews_summary_length = summary_reviews(example_gpt4_reviews, title=title, client=client)\n",
    "print(gpt_reviews_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Summarized Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_reviews(human_reviews: str, gpt_reviews: str, client: openai.Client) -> Tuple[str, int]:\n",
    "    \"\"\"\n",
    "    Compares two sets of reviews to identify matching reviews between human-written and GPT-generated sets.\n",
    "\n",
    "    Args:\n",
    "        human_reviews (str): JSON-formatted summary of human-written reviews.\n",
    "        gpt_reviews (str): JSON-formatted summary of GPT-generated reviews.\n",
    "        client (openai.Client): OpenAI client instance for sending requests.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, int]: A tuple containing the JSON-formatted comparison of reviews and the length of the output.\n",
    "    \"\"\"\n",
    "    prompt = REVIEW_COMPARISON_RPOMPT.format(Review_A=human_reviews, Review_B=gpt_reviews)\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\", messages=[{\"role\": \"system\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    output = clean_json_output(completion.choices[0].message.content)\n",
    "    length = len(json.loads(output))\n",
    "    \n",
    "    return output, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"A1-B4\": {\n",
      "        \"rationale\": \"Both Review A1 and Review B4 critique the biological basis and theoretical justification behind using cyclic orthogonal convolutions. A1 is critical of how the biological motivation doesn't align with true biological features and B4 points out that the rationale for the efficiency of such convolutions lacks clarity and needs further justification.\",\n",
      "        \"similarity\": \"7\"\n",
      "    },\n",
      "    \"A2-B3\": {\n",
      "        \"rationale\": \"Review A2 and Review B3 both express concerns about the adequacy of the experimental setups. A2 focuses on the insufficient transparency and performance data across different datasets, including the absence of detailed results on commonly recognized benchmarks like ImageNet. B3 suggests the need for more diverse datasets and a broader range of experiments to validate the architecture's efficacy, aligning with the concerns in A2 about not properly showcasing performance across datasets.\",\n",
      "        \"similarity\": \"7\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "reviews_match, reviews_match_length = match_reviews(human_reviews_summary, gpt_reviews_summary, client=client)\n",
    "print(reviews_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hits(matched_reviews: str, threshold: int = 7) -> int:\n",
    "    \"\"\"\n",
    "    Counts the number of high-similarity hits from a JSON-formatted comparison of reviews, \n",
    "    filtering hits by a specified similarity threshold.\n",
    "\n",
    "    Args:\n",
    "        matched_reviews (str): JSON-formatted string containing comparison data.\n",
    "        threshold (int): Minimum similarity score for a review to be considered a hit. Default is 7.\n",
    "\n",
    "    Returns:\n",
    "        int: Count of unique high-similarity hits.\n",
    "    \"\"\"\n",
    "    comparison = json.loads(matched_reviews)\n",
    "    hit_count = sum(1 for _, value in comparison.items() if int(value[\"similarity\"]) >= threshold)\n",
    "    return hit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of high-similarity hits between human and GPT-4 reviews is: 2\n"
     ]
    }
   ],
   "source": [
    "hit_count = count_hits(reviews_match)\n",
    "print(\"The number of high-similarity hits between human and GPT-4 reviews is: {}\".format(hit_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric import calculate_hit_rate, calculate_jaccard_index, calculate_sorensen_dice_coefficient, calculate_szymkiewicz_simpson_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate: 0.6666666666666666\n",
      "Jaccard Index: 0.4\n",
      "Sørensen-Dice Coefficient: 0.5714285714285714\n",
      "Szymkiewicz-Simpson Coefficient: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Hit Rate:\", calculate_hit_rate(hit_count, human_review_summary_length))\n",
    "print(\"Jaccard Index:\", calculate_jaccard_index(hit_count, human_review_summary_length, gpt_reviews_summary_length))\n",
    "print(\"Sørensen-Dice Coefficient:\", calculate_sorensen_dice_coefficient(hit_count, human_review_summary_length, gpt_reviews_summary_length))\n",
    "print(\"Szymkiewicz-Simpson Coefficient:\", calculate_szymkiewicz_simpson_coefficient(hit_count, human_review_summary_length, gpt_reviews_summary_length))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
