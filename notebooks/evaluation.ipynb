{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../data/paper_review_data_longqlora_10pct.jsonl') as f:\n",
    "    reviews = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any\n",
    "\n",
    "def extract_review_messages(review_data: Dict[str, List[Dict[str, Dict[str, Any]]]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extracts and returns the review messages including titles, reviews, and ratings from a given review data structure.\n",
    "\n",
    "    Args:\n",
    "        review_data (Dict[str, List[Dict[str, Dict[str, Any]]]]): A dictionary containing the review information,\n",
    "        expected to have a 'reviews_msg' key with a list of dictionaries. Each dictionary should have a 'content'\n",
    "        key that contains a dictionary with 'title', 'review', and 'rating' keys.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of dictionaries, each containing 'title', 'review', and 'rating' keys with their\n",
    "        respective values extracted from the review data.\n",
    "    \"\"\"\n",
    "    review_messages = []\n",
    "    for message in review_data.get('reviews_msg', []):\n",
    "        content = message.get('content', {})\n",
    "        if all(key in content for key in ['title', 'review', 'rating']):\n",
    "            review_messages.append({\n",
    "                'title': content['title'],\n",
    "                'review': content['review'],\n",
    "                'rating': content['rating']\n",
    "            })\n",
    "\n",
    "    return review_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_messages = extract_review_messages(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of review messages: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of review messages:\", len(review_messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>gpt-3.5-turbo-reviews</th>\n",
       "      <th>gpt-4-full-reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>A good one</td>\n",
       "      <td>This paper proposes a better pre-trained prior...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "      <td>{\\n    \"Significance and novelty\": {\\n        ...</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Intro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>paper shows promising results using point clou...</td>\n",
       "      <td>The paper considers the problem of training ne...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "      <td>{\\n\"Significance and novelty\": {\\n    \"Use of ...</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Intro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>Limited novelty and weak improvements</td>\n",
       "      <td>The authors propose completing an occluded poi...</td>\n",
       "      <td>4: Ok but not good enough - rejection</td>\n",
       "      <td>{\\n    \"Significance and novelty\": {\\n        ...</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Novel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>https://openreview.net/pdf?id=jPSYH47QSZL</td>\n",
       "      <td>There has recently been a flurry of exciting a...</td>\n",
       "      <td>Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...</td>\n",
       "      <td>Since the idea itself is simple enough, the re...</td>\n",
       "      <td>The idea of this paper is simple but fascinati...</td>\n",
       "      <td>5: Marginally below acceptance threshold</td>\n",
       "      <td>{\\n\"Significance and novelty\": {\\n    \"Mask-ba...</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Innov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GamePad: A Learning Environment for Theorem Pr...</td>\n",
       "      <td>https://openreview.net/pdf?id=r1xwKoR9Y7</td>\n",
       "      <td>In this paper, we introduce a system called Ga...</td>\n",
       "      <td>Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...</td>\n",
       "      <td>An intriguing integration of ML and automated ...</td>\n",
       "      <td>Summary: This paper mixes automated theorem pr...</td>\n",
       "      <td>7: Good paper, accept</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Explo...</td>\n",
       "      <td>{\\n  \"Significance and novelty\": {\\n    \"Intro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0            Pre-Training by Completing Point Clouds   \n",
       "1            Pre-Training by Completing Point Clouds   \n",
       "2            Pre-Training by Completing Point Clouds   \n",
       "3            Pre-Training by Completing Point Clouds   \n",
       "4  GamePad: A Learning Environment for Theorem Pr...   \n",
       "\n",
       "                                         url  \\\n",
       "0  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "1  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "2  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "3  https://openreview.net/pdf?id=jPSYH47QSZL   \n",
       "4   https://openreview.net/pdf?id=r1xwKoR9Y7   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  There has recently been a flurry of exciting a...   \n",
       "1  There has recently been a flurry of exciting a...   \n",
       "2  There has recently been a flurry of exciting a...   \n",
       "3  There has recently been a flurry of exciting a...   \n",
       "4  In this paper, we introduce a system called Ga...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "1  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "2  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "3  Hanchen Wang,Qi Liu,Xiangyu Yue,Joan Lasenby,M...   \n",
       "4  Daniel Huang,Prafulla Dhariwal,Dawn Song,Ilya ...   \n",
       "\n",
       "                                        review_title  \\\n",
       "0                                         A good one   \n",
       "1  paper shows promising results using point clou...   \n",
       "2              Limited novelty and weak improvements   \n",
       "3  Since the idea itself is simple enough, the re...   \n",
       "4  An intriguing integration of ML and automated ...   \n",
       "\n",
       "                                              review  \\\n",
       "0  This paper proposes a better pre-trained prior...   \n",
       "1  The paper considers the problem of training ne...   \n",
       "2  The authors propose completing an occluded poi...   \n",
       "3  The idea of this paper is simple but fascinati...   \n",
       "4  Summary: This paper mixes automated theorem pr...   \n",
       "\n",
       "                                     rating  \\\n",
       "0                     7: Good paper, accept   \n",
       "1                     7: Good paper, accept   \n",
       "2     4: Ok but not good enough - rejection   \n",
       "3  5: Marginally below acceptance threshold   \n",
       "4                     7: Good paper, accept   \n",
       "\n",
       "                               gpt-3.5-turbo-reviews  \\\n",
       "0  {\\n    \"Significance and novelty\": {\\n        ...   \n",
       "1  {\\n\"Significance and novelty\": {\\n    \"Use of ...   \n",
       "2  {\\n    \"Significance and novelty\": {\\n        ...   \n",
       "3  {\\n\"Significance and novelty\": {\\n    \"Mask-ba...   \n",
       "4  {\\n  \"Significance and novelty\": {\\n    \"Explo...   \n",
       "\n",
       "                                  gpt-4-full-reviews  \n",
       "0  {\\n  \"Significance and novelty\": {\\n    \"Intro...  \n",
       "1  {\\n  \"Significance and novelty\": {\\n    \"Intro...  \n",
       "2  {\\n  \"Significance and novelty\": {\\n    \"Novel...  \n",
       "3  {\\n  \"Significance and novelty\": {\\n    \"Innov...  \n",
       "4  {\\n  \"Significance and novelty\": {\\n    \"Intro...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../toy_data_w_gpt_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Initialize a nested dictionary to store reviews for each title\n",
    "reviews = defaultdict(lambda: {\n",
    "    'human_reviews': [],\n",
    "    'gpt-3.5-abstract-reviews': [],\n",
    "    'gpt-4-full-reviews': []\n",
    "})\n",
    "\n",
    "# Iterate over the DataFrame to populate the reviews dictionary\n",
    "for _, row in df.iterrows():\n",
    "    title = row['title']\n",
    "\n",
    "    # Append reviews to the corresponding lists within the dictionary\n",
    "    reviews[title]['human_reviews'].append(row['review'])\n",
    "    reviews[title]['gpt-3.5-abstract-reviews'].append(row['gpt-3.5-turbo-reviews'])\n",
    "    reviews[title]['gpt-4-full-reviews'].append(row['gpt-4-full-reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of titles: 7\n"
     ]
    }
   ],
   "source": [
    "titles = list(reviews.keys())\n",
    "print(\"Number of titles:\", len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_reviews': [\"This paper proposes a better pre-trained prior for a variety of downstream applications in point cloud analysis. The workflow of the pre-training mechanism is to first 1) generate occluded points that result from view occlusion and then 2) optimize the encoder to learn how to complete the occluded points from the partial point cloud. In downstream applications, the obtained encoder will be used as the initial weights in the network training. Empirical experiments have shown that such a pre-train mechanism can improve initialization over prior baselines and benefit a variety of tasks even with a large domain gap.\\n\\nPros:\\n1. The experimental results have shown a steady improvement in performance by using the proposed pre-training approach in different encoder architectures and different downstream applications. That provides strong support for validating the effectiveness of the proposed approach.\\n2. I also like the result that the initialization is only pre-trained on the occlusions generated from the ModelNet40 but still work in another dataset. And yet, the pre-training is done in a self-supervised manner. This is a great plus for this approach as it indicates that it could be a general-purpose booster for a wide range of applications without spending too much effort in collecting special-purpose dataset for pre-training. \\n3. The paper is well written and presented.\\n\\nCons:\\n1. The improvement, as shown in the statistics, is very incremental in most cases. I understand it is difficult to achieve better results on well-established benchmarks, but it somehow indicates the improvement is limited.\\n2. Though the paper already stated some nice explanation of the idea behind this approach, I would appreciate it if a more in-depth analysis of why such a pre-training mechanism could work is provided. Specifically, I would like more analysis of why such a pre-training method can adapt to different datasets? What are the common features that OcCo captures across different datasets? \\nSome visualization similar to Figure 3 would be helpful.\\n\\n---- Final Rating ----\\n\\nThe authors' response has resolved my concerns. I would keep my positive rating.\",\n",
       "  'The paper considers the problem of training networks for point cloud processing through a point cloud completion task. Given a point cloud, it is rendered from a set of viewpoints and for each viewpoint the set of visible points is determine. A network is then trained to generate the full point cloud from the partially observed point cloud for a given view. Here, an encoder-decoder architecture is used, where the encoder corresponds to the network that should be pre-trained. Experimental results show that the proposed method outperforms two baselines for three tasks (object classification, object part segmentation, and semantic segmentation), when using less training data, and that the pre-training on the occlusion task leads to faster convergence.\\n\\nOn the positive side, the occlusion completion (OcCo) task is clearly described and it should be fairly straightforward for a researcher to setup this task. The task requires no human annotation and is thus suitable for pre-training from large datasets captured in uncontrolled settings. The experiments cover a wide range of tasks and settings and show that the OcCo pre-training strategy outperforms random initialization and the approach from Saunders & Sievers. Here, the simplicity of the OcCo task coupled with its performance is clearly a major strength of the paper. In particular, Fig. 4 shows that the networks pre-trained on the OcCo task tend to converge much faster compared to the baselines.\\n\\nOn the negative side, I feel that the paper oversells the novelty of the OcCo task. The OcCo task is a variation of the (semantic) scene completion task that asks to complete a partial observation of a scene / object and is receiving attention in the computer vision community. Recent examples include [Dai et al.,  SG-NN: Sparse Generative Neural Networks for Self-Supervised Scene Completion of RGB-D Scans, CVPR 2020] and [Hou et al., RevealNet: Seeing Behind Objects in RGB-D Scans, CVPR 2020], with older works including [Firman et al., Structured prediction of unobserved voxels from a single depth image, CVPR 2016]. [Schönberger et al., Semantic Visual Localization, CVPR 2018] use (semantic) scene completion as a proxy task to train a 3D descriptors for 3D-3D matching between models. Given a voxelized partial observation of a scene, they train an encoder-decoder architecture to predict the complete volume (potentially also predicting semantic labels for each voxel). The embedding in the latent space are then used as 3D descriptors (i.e., the decoder part of the network is not needed at test time). In other words, they use the OcCo task for training their networks. They show that the learned representation generalizes between datasets and sensor modalities (training on 3D data obtained from stereo images, tested on LiDAR data). Given this result, I see limited novelty in using the OcCo task for pre-training point cloud networks and it does not seem very surprising that pre-training on the OcCo task should result in meaningful representations.\\n\\nMy second main point of criticism is the level of detail of the experimental evaluation. While the experiments cover a wide range of tasks and settings, I feel that crucial information needed to understand the results are missing:\\n1) Is the same dataset (ModelNet40) used to pre-train on the OcCo task also used to pre-train the JigSaw approach from Sauder & Sievers? Unfortunately, no details on the latter are provided in the main paper (or I was not able to find them), making it hard to understand how meaningful the comparison is.\\n2) There are no details on how the networks are trained for the different tasks, e.g., for how many epochs are the network trained for the task at hand?, do the networks converge for all pre-training strategies?\\n3) How significant are the improvements over the two baselines. For most considered settings, the improvements seem rather small, e.g., often less than 1 point compared to the Rand baseline in Tab. 2 and 3. Is this a meaningful improvment? Or would simply using a different random seed for training explain such a difference? Given that the paper claims that \"These results demonstrate that the OcCo-initialized models have strong transfer capabilities on out-of-domain datasets\" and that \"OcCo-initialized models achieve superior results compared to the randomly-initialized models\", this is an important question to answer.\\nI think there is enough space in the paper to include this information. Specifically, I do not think that Alg. 1 is necessary in the main paper (but would be good to have as an appendix) as the text and Fig. 1 already describe the approach in sufficient detail. Similarly, the z-Buffer algorithm is a classic computer graphics technique that is covered in basic lectures and does not need to be discussed in detail (e.g., see [Pittaluga et al., Revealing Scenes by Inverting Structure from Motion Reconstructions, CVPR 2019] briefly mentioning z-Buffering and the use of Delaunay triangulation for determining visibility). I think this space could be spend on providing more details.\\n\\nIn the current form, I do not think the paper is ready for publication as the paper, in my opinion, overclaims its contributions, misses relevant work (see also below), and misses crucial details necessary to understand the experimental results. As such, I am currently recommending to reject the paper. I believe that these issues can be addressed, but I would base my final recommendation based on the authors\\' feedback.\\n\\nHere are additional detailed comments:\\n* In Sec. 2.1, I do not understand the comment \"Our goal is to learn a randomized occlusion mapping o : P → P (where P is the space of all point clouds) from a full point cloud P to an occluded point cloud P\". As far as I can tell, the mapping is not learned but follows a fixed pipeline.\\n* I don\\'t understand how Eq. 2 \"most closely approximates the inverse of eq. (1)\". Eq. 2 is the inverse of Eq. 1. The only approximation that I could see if the 2D projection coordinates are rounded to the nearest integer.\\n* The introduction teases with the statement \"Current 3D sensing modalities (i.e., 3D scanners, stereo cameras, lidars) have enabled the creation of large repositories of point cloud data (Rusu & Cousins, 2011; Hackel et al., 2017).\" However, only synthetic data is used for pre-training, which is a bit disappointing. I am not convinced that the synthetic datasets \"are qualitatively similar to point clouds in datasets where points are collected via 3D imaging devices such as handheld scanners (Dai et al., 2017a; Armeni et al., 2016) and lidar (Geiger et al., 2012).\" Based on my experience, handheld scanners (RGB-D cameras or (multi-view) stereo cameras) produce much more noisy measurements with outliers while lidar sensors, especially for autonomous vehicles, typically produce sparser point clouds.\\n* Sec. 3.2 states that \"We observe that, in early stage the encoder is able to learn low-level geometric primitives, i.e., planes, cylinders and cones, while later the network recognises more complex shapes like wings, leafs and upper bodies (non-rigid).\" I am not sure how I see this in Fig. 3 since I don\\'t know what the color-coding signifies.\\n* Looking at Fig. 3, I am not sure whether the statement that \"clearly separable clusters are formed for different object classes\" is true. There seems to be quite some overlap between classes, but this is also a bit hard to tell given the small size of the figure.\\n* [Yang et al., PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows, ICCV 2019] and [Gadelha et al., Label-Efficient Learning on Point Clouds using Approximate Convex Decompositions, ECCV 2020]  both propose generative models for point clouds. Both of them show that they can be used for unsupervised representation learning and they show competitive results for the task of only training an SVM classifier on top of the learned representation for ModelNet. Both should be discussed in the related work.\\n\\n### After rebuttal phase ###\\nThe comments by the authors and the revised version of the paper successfully address my concerns. I thus recommend to accept the paper.',\n",
       "  'The authors propose completing an occluded point cloud as a pretraining step for point cloud processing methods. Multiple occlusions are generated for the network to complete by simulating a camera perspective. \\n\\nPros: \\n- First work analyzing this specific pretraining for point clouds\\n\\nCons:\\n- Weak novelty\\n- Limited experimental reliability\\n\\nOverall, the novelty of the paper seems rather weak. The only novel contribution is the idea of point cloud completion as a pretraining task. This idea is rather simple and similar techniques are well known and used in other fields such as NLP. Hence, it does not represent a significant methodological advancement.\\nNevertheless, the paper would still be interesting if it showed extraordinary results in this particular field of application. Unfortunately, the experimental results seem weak as well. They show modest gains with respect to existing techniques and they lack any information on run-to-run variance. This makes it impossible to understand if the gains that are shown are statistically significant or just lucky runs with careful parameter tuning. ',\n",
       "  'The idea of this paper is simple but fascinating. Actually there are many studies concerning the task of point cloud completion, but using it as the initialization approach to improve the other tasks is quiet novel. The experimental results seem solid and quantitatively prove the effectiveness of the OcCo-initialization.\\n\\nSince the idea itself is simple enough, the reviewer would not argue too much about the technical contribution of this paper, but concerns more about the analytic contributions. The reviewer’s concerns are as follows.\\n1. In addition to verify the effectiveness of OcCo-initialization, more analysis on why this simple idea can take effect should also be given. For example, the author should go deeper to explain why OcCo-initialized PointNet can outperform the random initialized PointNet (e.g. by visualizing the learned features of the two kinds of PointNet, like Figure 3).\\n2. The idea of OcCo-initialization can be concluded as some kind of task oriented initialization approach. Considering the simplicity of this idea, similar initialization strategy can be formulated, such as pre-training network on segmentation task and apply them on classification task. So why the author only chooses the completion task as the initialization strategy, or if task oriented initialization can be considered as a universal strategy in point cloud processing?\\n3. Although the experimental results look solid, the reviewer still concerns if the proposed OcCo-initialization can achieve the SOTA results or close enough to the current SOTA. For example, PointCNN can achieve much better segmentation results compared to the methods in Table 3. So if the OcCo-initialization can still succeed in the PointCNN which has better ability of learning point cloud features?\\n4. The author is advised to clarify the necessity of Sec 2.1, which is the main part of the model description. In reviewer’s opinion, a method to generate partial point cloud from single view is essentially not a technical contribution for this paper.\\n'],\n",
       " 'gpt-3.5-abstract-reviews': ['{\\n    \"Significance and novelty\": {\\n        \"Introduction of mask-based pre-training for point clouds\": \"The paper introduces a novel pre-training mechanism based on mask-based pre-training, inspired by natural language processing techniques, for point clouds which is a unique contribution in the field.\",\\n        \"OcCo method for point cloud completion\": \"The proposed Occlusion Completion (OcCo) method is innovative and aims to address the challenges of label inefficiency and time-consuming annotation by learning representations through point cloud completion.\"\\n    },\\n    \"Potential reasons for acceptance\": {\\n        \"Innovative approach\": \"The paper presents a novel approach for pre-training point cloud models using occlusion completion, which can potentially lead to significant advancements in the field.\",\\n        \"Improved semantic understanding and generalization\": \"The OcCo method demonstrates improved semantic understandings and generalization on downstream tasks compared to prior methods, showcasing its potential for acceptance.\"\\n    },\\n    \"Potential reasons for rejection\": {\\n        \"Lack of comparative analysis\": \"The paper should provide a more detailed comparative analysis with existing methods in the field to further validate the effectiveness of the OcCo method.\",\\n        \"Limited experimental results\": \"More extensive experimental results and evaluation on various datasets are needed to fully demonstrate the effectiveness of the proposed method.\"\\n    },\\n    \"Suggestions for improvement\": {\\n        \"Comparative analysis\": \"Include a more comprehensive comparative analysis with existing methods to highlight the advantages of the OcCo method.\",\\n        \"Additional experiments\": \"Conduct additional experiments on different datasets and scenarios to provide a deeper evaluation of the proposed method.\"\\n    }\\n}',\n",
       "  '{\\n\"Significance and novelty\": {\\n    \"Use of mask-based pre-training in point cloud data\": \"The paper introduces a novel approach inspired by mask-based pre-training in the natural language processing community to address the challenges in creating labelled point cloud datasets.\"\\n},\\n\\n\\'Potential reasons for acceptance\\': {\\n    \"Innovative approach\": \"The use of mask-based pre-training for point cloud data is innovative and shows potential for improving semantic understanding and generalization.\",\\n    \"Improved representation learning\": \"The method demonstrates that it can improve representation learning in real-world point clouds, which is a significant contribution to the field.\"\\n},\\n\\n\"Potential reasons for rejection\": {},\\n\\n\\'Suggestions for improvement\\': {\\n    \"Evaluation on larger datasets\": \"It would be beneficial to evaluate the performance of OcCo on larger datasets to further validate its effectiveness.\",\\n    \"Comparison with state-of-the-art methods\": \"A comparative analysis with existing state-of-the-art methods would help in demonstrating the superiority of the proposed approach.\"\\n}\\n}',\n",
       "  '{\\n    \"Significance and novelty\": {\\n        \"Pre-training mechanism based point clouds completion\": \"The proposed method of using mask-based pre-training for point clouds completion is novel and innovative, inspired by techniques from natural language processing.\"\\n    },\\n    \"Potential reasons for acceptance\": {\\n        \"Innovative approach\": \"The use of mask-based pre-training for point clouds completion shows a unique and creative approach to improving point cloud datasets.\",\\n        \"Improved semantic understanding and generalization\": \"The method demonstrates enhanced semantic understandings and generalization on downstream tasks compared to previous methods.\"\\n    },\\n    \"Potential reasons for rejection\": {\\n        \"Limited experimental validation\": \"The paper may benefit from further experimental validation to ensure the effectiveness of the proposed method.\",\\n        \"Lack of comparison with state-of-the-art methods\": \"Comparative analysis with existing state-of-the-art methods could strengthen the paper.\"\\n    },\\n    \"Suggestions for improvement\": {\\n        \"Additional experiments\": \"Including more experiments to validate the effectiveness of the Occlusion Completion method would strengthen the paper.\",\\n        \"Comparison with existing methods\": \"Providing a detailed comparison with state-of-the-art methods in the field would enhance the contribution of the paper.\"\\n    }\\n}',\n",
       "  '{\\n\"Significance and novelty\": {\\n    \"Mask-based pre-training in the natural language processing community\": \"The paper draws inspiration from techniques used in natural language processing which can bring a new perspective to the field of point cloud completion.\",\\n    \"Occlusion Completion (OcCo)\": \"Introducing a novel approach named Occlusion Completion (OcCo) for pre-training on point clouds, which aims to address the challenges of labeled point cloud datasets.\"\\n},\\n\\n\\'Potential reasons for acceptance\\': {\\n    \"Innovative approach\": \"The proposed Occlusion Completion (OcCo) approach is innovative and addresses an important problem in the field of point cloud completion.\",\\n    \"Improving semantic understanding and generalization\": \"The paper demonstrates that OcCo improves semantic understanding and generalization on downstream tasks compared to prior methods.\",\\n    \"Transferability to different datasets\": \"Showing that the method is able to transfer to different datasets is a strong point for acceptance.\"\\n},\\n\\n\"Potential reasons for rejection\": {},\\n\\n\\'Suggestions for improvement\\': {\\n    \"Empirical evaluation\": \"Conducting more extensive experiments and providing further empirical evidence to support the claims made in the paper.\",\\n    \"Comparison with state-of-the-art methods\": \"Comparing the proposed Occlusion Completion (OcCo) method with current state-of-the-art techniques in the field to showcase its effectiveness.\"\\n}\\n}'],\n",
       " 'gpt-4-full-reviews': ['{\\n  \"Significance and novelty\": {\\n    \"Introduction of Occlusion Completion (OcCo) for point cloud pre-training\": \"The paper introduces a novel pre-training method named Occlusion Completion (OcCo), which enhances point cloud models by learning to reconstruct occluded parts of point clouds. This approach is inspired by mask-based pre-training in natural language processing and adapts it innovatively for 3D point cloud data. The novelty lies in using occlusion as a mechanism for pre-training, aiming to improve semantic understandings and generalization on downstream tasks.\",\\n    \"Leveraging occluded point clouds for learning structural information\": \"The method uniquely leverages the natural occurrence of occlusions in point clouds obtained from different camera viewpoints to generate occluded point clouds. This approach forces the model to learn structural and contextual information about the objects, which is a novel strategy for pre-training point cloud models.\"\\n  },\\n  \"Potential reasons for acceptance\": {\\n    \"Demonstrated improvements over existing methods\": \"OcCo shows significant improvements over prior methods in various downstream tasks such as object classification, part segmentation, and semantic segmentation. These improvements are quantitatively demonstrated through comprehensive experiments.\",\\n    \"Extensive experimental validation\": \"The paper provides extensive experimental results validating the effectiveness of OcCo pre-training across multiple benchmarks and settings. This includes few-shot learning scenarios and different levels of label availability, showcasing the method\\'s versatility and robustness.\"\\n  },\\n  \"Potential reasons for rejection\": {\\n    \"Lack of theoretical analysis\": \"The paper primarily focuses on empirical results and may lack a detailed theoretical analysis explaining why OcCo pre-training leads to better generalization and performance on downstream tasks.\",\\n    \"Comparison with very recent or concurrent works\": \"Depending on the timing and scope of the review, the paper might not compare its approach against the very latest or concurrent works in point cloud processing, which could be seen as a limitation.\"\\n  },\\n  \"Suggestions for improvement\": {\\n    \"Provide more theoretical insights\": \"Enhancing the paper with theoretical insights or analysis on why OcCo pre-training is effective could strengthen the paper. This could include discussions on the nature of occlusions in point clouds and their role in learning robust features.\",\\n    \"Expand comparisons to include more recent methods\": \"Updating the experimental comparisons to include more recent or concurrent works in point cloud pre-training and completion could provide a clearer picture of OcCo\\'s standing in the field.\",\\n    \"Explore limitations and future work\": \"A more detailed discussion on the limitations of the proposed method and potential directions for future work could provide readers with insights into the method\\'s applicability and areas for improvement.\"\\n  }\\n}\\n    ',\n",
       "  '{\\n  \"Significance and novelty\": {\\n    \"Introduction of Occlusion Completion (OcCo) mechanism\": \"The paper proposes a novel pre-training mechanism, Occlusion Completion (OcCo), which innovatively uses the natural occurrence of occlusions in point clouds to generate training data. This mechanism helps in learning robust representations that improve semantic understanding and generalization on downstream tasks.\",\\n    \"Advances in handling sparse and dense point clouds\": \"By addressing the challenges in annotating point clouds due to their sparsity or density, the paper introduces an approach that potentially reduces the need for extensive labeled datasets. This approach is significant for advancing point cloud processing techniques.\"\\n  },\\n  \"Potential reasons for acceptance\": {\\n    \"Comprehensive experimental validation\": \"The paper presents extensive experiments demonstrating the effectiveness of OcCo across multiple benchmarks and tasks, including object classification, part segmentation, and semantic segmentation, showing improvements over existing methods.\",\\n    \"Insightful analysis on learned representations\": \"Through various analyses, including feature visualization and concept detection, the paper provides deep insights into what the pre-trained model learns, highlighting the method\\'s capability to capture useful geometric and semantic information from point clouds.\"\\n  },\\n  \"Potential reasons for rejection\": {\\n    \"Limited theoretical underpinning\": \"The paper\\'s strong empirical results might be seen as lacking a robust theoretical framework explaining why OcCo works effectively, which could be a point of critique.\",\\n    \"Comparison with state-of-the-art methods\": \"Although the paper compares OcCo with existing methods, the rapidly evolving nature of the field might require further comparison with more recent or concurrent works to fully establish its position.\"\\n  },\\n  \"Suggestions for improvement\": {\\n    \"Enhanced theoretical explanation\": \"Providing a more detailed theoretical analysis or justification for the effectiveness of OcCo could strengthen the paper, offering insights into how and why occlusion-based pre-training aids in learning robust point cloud representations.\",\\n    \"Extended comparisons and benchmarks\": \"Expanding the experimental comparisons to include the latest methods in point cloud processing could further validate OcCo\\'s effectiveness. Additionally, exploring its applicability to more varied and challenging datasets could showcase its adaptability and robustness.\"\\n  }\\n}\\n    ',\n",
       "  '{\\n  \"Significance and novelty\": {\\n    \"Novel pre-training mechanism\": \"The paper introduces Occlusion Completion (OcCo), a novel pre-training mechanism for point cloud models, addressing the challenge of sparse and dense point clouds by learning to reconstruct occluded parts.\",\\n    \"Enhanced semantic understanding and generalization\": \"OcCo is shown to enhance semantic understandings and generalization on downstream tasks, offering significant contributions over prior methods by using occlusions naturally occurring in point clouds.\"\\n  },\\n  \"Potential reasons for acceptance\": {\\n    \"Comprehensive experiments and benchmarks\": \"Extensive experimental validation demonstrates the effectiveness of OcCo across multiple benchmarks, including object classification, part segmentation, and semantic segmentation, showing improvements over existing methods.\",\\n    \"Innovative approach to learning from occlusions\": \"The approach to generate occluded point clouds and learning a completion model to reconstruct them provides a fresh perspective on pre-training, potentially inspiring future research in point cloud processing.\"\\n  },\\n  \"Potential reasons for rejection\": {\\n    \"Lack of theoretical foundation\": \"The paper could face criticism for not providing a solid theoretical foundation explaining the effectiveness of OcCo, potentially leaving some questions unanswered regarding the underlying principles.\",\\n    \"Limited comparison with recent methods\": \"Given the rapid advancements in point cloud processing, the paper might be critiqued for not including comparisons with the most recent or concurrent methods in the field.\"\\n  },\\n  \"Suggestions for improvement\": {\\n    \"Strengthen theoretical explanations\": \"Incorporating more detailed theoretical analysis or insights could help in understanding why OcCo outperforms other pre-training methods, providing a stronger foundation for the proposed approach.\",\\n    \"Expand experimental comparisons\": \"Broadening the scope of experimental comparisons to include more recent and varied methods could help in establishing OcCo\\'s position more firmly within the current research landscape.\"\\n  }\\n}\\n    ',\n",
       "  '{\\n  \"Significance and novelty\": {\\n    \"Innovative pre-training approach\": \"The paper introduces Occlusion Completion (OcCo), a novel pre-training method for point cloud models, which enhances model performance by learning to reconstruct occluded parts of point clouds. This approach is inspired by mask-based pre-training in NLP and uniquely adapted for 3D point cloud data, addressing the challenge of sparse and dense point clouds.\",\\n    \"Enhancement in semantic understanding and generalization\": \"OcCo demonstrates significant advancements in improving semantic understandings and generalization across various downstream tasks including object classification, part segmentation, and semantic segmentation, showcasing its ability to transfer to different datasets efficiently.\"\\n  },\\n  \"Potential reasons for acceptance\": {\\n    \"Comprehensive experimental validation\": \"Extensive experiments across multiple benchmarks and settings validate OcCo\\'s effectiveness, showing improvements over existing methods and highlighting its robustness and versatility in handling point cloud data.\",\\n    \"Insightful analysis and interpretation\": \"The paper provides a thorough analysis of what is learned from OcCo pre-training, using visualizations and probe tests, to offer insights into how the pre-trained model captures useful geometric and semantic information from point clouds.\"\\n  },\\n  \"Potential reasons for rejection\": {\\n    \"Lack of theoretical explanation\": \"While the empirical results are strong, the paper might be criticized for not providing a detailed theoretical foundation explaining the effectiveness of OcCo, which could strengthen the paper\\'s claims.\",\\n    \"Limited comparison with state-of-the-art methods\": \"The rapidly evolving field of point cloud processing may have seen new developments since the submission, and the paper could be seen as lacking if it does not include comparisons with the very latest methods.\"\\n  },\\n  \"Suggestions for improvement\": {\\n    \"Strengthen theoretical underpinnings\": \"Enhancing the paper with more detailed theoretical insights or explanations for why OcCo pre-training leads to improved performance on downstream tasks could provide a stronger justification for the approach.\",\\n    \"Broaden comparisons and update benchmarks\": \"Expanding comparisons to include the latest methods in point cloud processing and exploring its applicability to more diverse and challenging datasets could further demonstrate OcCo\\'s effectiveness and adaptability.\"\\n  }\\n}\\n    ']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[titles[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = \"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\"\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_PROMPT = \"\"\"\n",
    "Your goal is to identify the key concerns raised in the review, focusing only on potential\n",
    "reasons for rejection.\n",
    "\n",
    "Please provide your analysis in JSON format, including a concise summary, and the exact\n",
    "wording from the review. \n",
    "    \n",
    "Submission Title: {Title}\n",
    "\n",
    "=====Review:\n",
    "```\n",
    "{Review_Text}\n",
    "```\n",
    "=====\n",
    "\n",
    "Example JSON format:\n",
    "{{\n",
    "    \"1\": {{\"summary\": \"<your concise summary>\", \"verbatim\": \"<concise, copy the exact\n",
    "    wording in the review>\"}},\n",
    "    \"2\": ... \n",
    "}}\n",
    "\n",
    "Analyze the review and provide the key concerns in the format specified above. Ignore minor\n",
    "    issues like typos and clarifications. Output only json.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def clean_json_output(output: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans the JSON output from the OpenAI GPT-4 model by removing unnecessary characters.\n",
    "\n",
    "    This function aims to strip extraneous formatting or characters from the JSON output,\n",
    "    such as backticks or leading 'json' strings that might be present in the formatted output.\n",
    "\n",
    "    Args:\n",
    "        output: A string containing the JSON-formatted output from the GPT-4 model.\n",
    "\n",
    "    Returns:\n",
    "        A string with the JSON output cleaned up.\n",
    "    \"\"\"\n",
    "    # Remove backticks, 'json' literals, and any leading/trailing whitespace\n",
    "    cleaned_output = output.strip('`').replace('json\\n', '').strip()\n",
    "    return cleaned_output\n",
    "\n",
    "\n",
    "def summary_reviews(reviews: List[str], title: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarizes a list of reviews using the OpenAI GPT-4 model.\n",
    "\n",
    "    Args:\n",
    "        reviews: A list of strings containing the reviews to be summarized.\n",
    "        title: The title of the subject to which the reviews pertain.\n",
    "\n",
    "    Returns:\n",
    "        A string representing the JSON-formatted summary of the reviews.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_delimiter = \"\\n<|startofreview|>\\n\"\n",
    "    end_delimiter = \"\\n<|endofreview|>\\n\"\n",
    "    review_messages = end_delimiter.join(start_delimiter + review for review in reviews) + end_delimiter \n",
    "    \n",
    "    prompt = SUMMARY_PROMPT.format(Title=title, Review_Text=review_messages)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    response = clean_json_output(completion.choices[0].message.content)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = titles[0]\n",
    "human_reviews = reviews[title]['human_reviews']\n",
    "gpt_35_reviews = reviews[title]['gpt-3.5-abstract-reviews']\n",
    "gpt_4_reviews = reviews[title]['gpt-4-full-reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_reviews_summary = summary_reviews(human_reviews, title)\n",
    "gpt_35_reviews_summary = summary_reviews(gpt_35_reviews, title)\n",
    "gpt_4_reviews_summary = summary_reviews(gpt_4_reviews, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\\n  \"Significance and novelty\": {\\n    \"Introduction of Occlusion Completion (OcCo) for point cloud pre-training\": \"The paper introduces a novel pre-training method named Occlusion Completion (OcCo), which enhances point cloud models by learning to reconstruct occluded parts of point clouds. This approach is inspired by mask-based pre-training in natural language processing and adapts it innovatively for 3D point cloud data. The novelty lies in using occlusion as a mechanism for pre-training, aiming to improve semantic understandings and generalization on downstream tasks.\",\\n    \"Leveraging occluded point clouds for learning structural information\": \"The method uniquely leverages the natural occurrence of occlusions in point clouds obtained from different camera viewpoints to generate occluded point clouds. This approach forces the model to learn structural and contextual information about the objects, which is a novel strategy for pre-training point cloud models.\"\\n  },\\n  \"Potential reasons for acceptance\": {\\n    \"Demonstrated improvements over existing methods\": \"OcCo shows significant improvements over prior methods in various downstream tasks such as object classification, part segmentation, and semantic segmentation. These improvements are quantitatively demonstrated through comprehensive experiments.\",\\n    \"Extensive experimental validation\": \"The paper provides extensive experimental results validating the effectiveness of OcCo pre-training across multiple benchmarks and settings. This includes few-shot learning scenarios and different levels of label availability, showcasing the method\\'s versatility and robustness.\"\\n  },\\n  \"Potential reasons for rejection\": {\\n    \"Lack of theoretical analysis\": \"The paper primarily focuses on empirical results and may lack a detailed theoretical analysis explaining why OcCo pre-training leads to better generalization and performance on downstream tasks.\",\\n    \"Comparison with very recent or concurrent works\": \"Depending on the timing and scope of the review, the paper might not compare its approach against the very latest or concurrent works in point cloud processing, which could be seen as a limitation.\"\\n  },\\n  \"Suggestions for improvement\": {\\n    \"Provide more theoretical insights\": \"Enhancing the paper with theoretical insights or analysis on why OcCo pre-training is effective could strengthen the paper. This could include discussions on the nature of occlusions in point clouds and their role in learning robust features.\",\\n    \"Expand comparisons to include more recent methods\": \"Updating the experimental comparisons to include more recent or concurrent works in point cloud pre-training and completion could provide a clearer picture of OcCo\\'s standing in the field.\",\\n    \"Explore limitations and future work\": \"A more detailed discussion on the limitations of the proposed method and potential directions for future work could provide readers with insights into the method\\'s applicability and areas for improvement.\"\\n  }\\n}\\n    ', '{\\n  \"Significance and novelty\": {\\n    \"Introduction of Occlusion Completion (OcCo) mechanism\": \"The paper proposes a novel pre-training mechanism, Occlusion Completion (OcCo), which innovatively uses the natural occurrence of occlusions in point clouds to generate training data. This mechanism helps in learning robust representations that improve semantic understanding and generalization on downstream tasks.\",\\n    \"Advances in handling sparse and dense point clouds\": \"By addressing the challenges in annotating point clouds due to their sparsity or density, the paper introduces an approach that potentially reduces the need for extensive labeled datasets. This approach is significant for advancing point cloud processing techniques.\"\\n  },\\n  \"Potential reasons for acceptance\": {\\n    \"Comprehensive experimental validation\": \"The paper presents extensive experiments demonstrating the effectiveness of OcCo across multiple benchmarks and tasks, including object classification, part segmentation, and semantic segmentation, showing improvements over existing methods.\",\\n    \"Insightful analysis on learned representations\": \"Through various analyses, including feature visualization and concept detection, the paper provides deep insights into what the pre-trained model learns, highlighting the method\\'s capability to capture useful geometric and semantic information from point clouds.\"\\n  },\\n  \"Potential reasons for rejection\": {\\n    \"Limited theoretical underpinning\": \"The paper\\'s strong empirical results might be seen as lacking a robust theoretical framework explaining why OcCo works effectively, which could be a point of critique.\",\\n    \"Comparison with state-of-the-art methods\": \"Although the paper compares OcCo with existing methods, the rapidly evolving nature of the field might require further comparison with more recent or concurrent works to fully establish its position.\"\\n  },\\n  \"Suggestions for improvement\": {\\n    \"Enhanced theoretical explanation\": \"Providing a more detailed theoretical analysis or justification for the effectiveness of OcCo could strengthen the paper, offering insights into how and why occlusion-based pre-training aids in learning robust point cloud representations.\",\\n    \"Extended comparisons and benchmarks\": \"Expanding the experimental comparisons to include the latest methods in point cloud processing could further validate OcCo\\'s effectiveness. Additionally, exploring its applicability to more varied and challenging datasets could showcase its adaptability and robustness.\"\\n  }\\n}\\n    ', '{\\n  \"Significance and novelty\": {\\n    \"Novel pre-training mechanism\": \"The paper introduces Occlusion Completion (OcCo), a novel pre-training mechanism for point cloud models, addressing the challenge of sparse and dense point clouds by learning to reconstruct occluded parts.\",\\n    \"Enhanced semantic understanding and generalization\": \"OcCo is shown to enhance semantic understandings and generalization on downstream tasks, offering significant contributions over prior methods by using occlusions naturally occurring in point clouds.\"\\n  },\\n  \"Potential reasons for acceptance\": {\\n    \"Comprehensive experiments and benchmarks\": \"Extensive experimental validation demonstrates the effectiveness of OcCo across multiple benchmarks, including object classification, part segmentation, and semantic segmentation, showing improvements over existing methods.\",\\n    \"Innovative approach to learning from occlusions\": \"The approach to generate occluded point clouds and learning a completion model to reconstruct them provides a fresh perspective on pre-training, potentially inspiring future research in point cloud processing.\"\\n  },\\n  \"Potential reasons for rejection\": {\\n    \"Lack of theoretical foundation\": \"The paper could face criticism for not providing a solid theoretical foundation explaining the effectiveness of OcCo, potentially leaving some questions unanswered regarding the underlying principles.\",\\n    \"Limited comparison with recent methods\": \"Given the rapid advancements in point cloud processing, the paper might be critiqued for not including comparisons with the most recent or concurrent methods in the field.\"\\n  },\\n  \"Suggestions for improvement\": {\\n    \"Strengthen theoretical explanations\": \"Incorporating more detailed theoretical analysis or insights could help in understanding why OcCo outperforms other pre-training methods, providing a stronger foundation for the proposed approach.\",\\n    \"Expand experimental comparisons\": \"Broadening the scope of experimental comparisons to include more recent and varied methods could help in establishing OcCo\\'s position more firmly within the current research landscape.\"\\n  }\\n}\\n    ', '{\\n  \"Significance and novelty\": {\\n    \"Innovative pre-training approach\": \"The paper introduces Occlusion Completion (OcCo), a novel pre-training method for point cloud models, which enhances model performance by learning to reconstruct occluded parts of point clouds. This approach is inspired by mask-based pre-training in NLP and uniquely adapted for 3D point cloud data, addressing the challenge of sparse and dense point clouds.\",\\n    \"Enhancement in semantic understanding and generalization\": \"OcCo demonstrates significant advancements in improving semantic understandings and generalization across various downstream tasks including object classification, part segmentation, and semantic segmentation, showcasing its ability to transfer to different datasets efficiently.\"\\n  },\\n  \"Potential reasons for acceptance\": {\\n    \"Comprehensive experimental validation\": \"Extensive experiments across multiple benchmarks and settings validate OcCo\\'s effectiveness, showing improvements over existing methods and highlighting its robustness and versatility in handling point cloud data.\",\\n    \"Insightful analysis and interpretation\": \"The paper provides a thorough analysis of what is learned from OcCo pre-training, using visualizations and probe tests, to offer insights into how the pre-trained model captures useful geometric and semantic information from point clouds.\"\\n  },\\n  \"Potential reasons for rejection\": {\\n    \"Lack of theoretical explanation\": \"While the empirical results are strong, the paper might be criticized for not providing a detailed theoretical foundation explaining the effectiveness of OcCo, which could strengthen the paper\\'s claims.\",\\n    \"Limited comparison with state-of-the-art methods\": \"The rapidly evolving field of point cloud processing may have seen new developments since the submission, and the paper could be seen as lacking if it does not include comparisons with the very latest methods.\"\\n  },\\n  \"Suggestions for improvement\": {\\n    \"Strengthen theoretical underpinnings\": \"Enhancing the paper with more detailed theoretical insights or explanations for why OcCo pre-training leads to improved performance on downstream tasks could provide a stronger justification for the approach.\",\\n    \"Broaden comparisons and update benchmarks\": \"Expanding comparisons to include the latest methods in point cloud processing and exploring its applicability to more diverse and challenging datasets could further demonstrate OcCo\\'s effectiveness and adaptability.\"\\n  }\\n}\\n    ']\n"
     ]
    }
   ],
   "source": [
    "print(gpt_4_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Reviews Summary: \n",
      "{\n",
      "    \"1\": {\n",
      "        \"summary\": \"Incremental improvements and lack of in-depth analysis on the effectiveness of the pre-training mechanism.\",\n",
      "        \"verbatim\": \"The improvement, as shown in the statistics, is very incremental in most cases. [...] I would appreciate it if a more in-depth analysis of why such a pre-training mechanism could work is provided.\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"summary\": \"Overselling the novelty, inadequate experimental details, and missing crucial information for understanding the results.\",\n",
      "        \"verbatim\": \"I feel that the paper oversells the novelty of the OcCo task [...] misses relevant work [...] and misses crucial details necessary to understand the experimental results.\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"summary\": \"Limited novelty and experimental reliability.\",\n",
      "        \"verbatim\": \"The novelty of the paper seems rather weak. [...] The experimental results seem weak as well.\"\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"summary\": \"Need for deeper analysis on why the initialization is effective and questions on the selection and effectiveness of the completion task as the initialization strategy.\",\n",
      "        \"verbatim\": \"In addition to verify the effectiveness of OcCo-initialization, more analysis on why this simple idea can take effect should also be given. [...] So why the author only chooses the completion task as the initialization strategy, or if task oriented initialization can be considered as a universal strategy in point cloud processing?\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Human Reviews Summary: \\n\" + human_reviews_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5 Reviews Summary: \n",
      "{\n",
      "    \"1\": {\n",
      "        \"summary\": \"The paper lacks a detailed comparative analysis with existing methods and needs more extensive experimental results.\",\n",
      "        \"verbatim\": \"The paper should provide a more detailed comparative analysis with existing methods in the field to further validate the effectiveness of the OcCo method. More extensive experimental results and evaluation on various datasets are needed to fully demonstrate the effectiveness of the proposed method.\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"summary\": \"The paper may benefit from further experimental validation and lacks comparison with state-of-the-art methods.\",\n",
      "        \"verbatim\": \"The paper may benefit from further experimental validation to ensure the effectiveness of the proposed method. Comparative analysis with existing state-of-the-art methods could strengthen the paper.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"GPT-3.5 Reviews Summary: \\n\" + gpt_35_reviews_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 Reviews Summary: \n",
      "{\n",
      "    \"1\": {\n",
      "        \"summary\": \"The paper lacks a detailed theoretical analysis explaining why OcCo pre-training improves generalization and performance on downstream tasks.\",\n",
      "        \"verbatim\": \"The paper primarily focuses on empirical results and may lack a detailed theoretical analysis explaining why OcCo pre-training leads to better generalization and performance on downstream tasks.\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"summary\": \"The paper might not compare its approach against very recent or concurrent works in point cloud processing.\",\n",
      "        \"verbatim\": \"Depending on the timing and scope of the review, the paper might not compare its approach against the very latest or concurrent works in point cloud processing, which could be seen as a limitation.\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"summary\": \"Lacks a robust theoretical framework explaining why OcCo works effectively.\",\n",
      "        \"verbatim\": \"The paper's strong empirical results might be seen as lacking a robust theoretical framework explaining why OcCo works effectively, which could be a point of critique.\"\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"summary\": \"Might require further comparison with more recent or concurrent works to establish its position.\",\n",
      "        \"verbatim\": \"Although the paper compares OcCo with existing methods, the rapidly evolving nature of the field might require further comparison with more recent or concurrent works to fully establish its position.\"\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"summary\": \"The paper could face criticism for not providing a solid theoretical foundation explaining the effectiveness of OcCo.\",\n",
      "        \"verbatim\": \"The paper could face criticism for not providing a solid theoretical foundation explaining the effectiveness of OcCo, potentially leaving some questions unanswered regarding the underlying principles.\"\n",
      "    },\n",
      "    \"6\": {\n",
      "        \"summary\": \"Critiqued for not including comparisons with the most recent or concurrent methods in the field.\",\n",
      "        \"verbatim\": \"Given the rapid advancements in point cloud processing, the paper might be critiqued for not including comparisons with the most recent or concurrent methods in the field.\"\n",
      "    },\n",
      "    \"7\": {\n",
      "        \"summary\": \"Might be criticized for not providing a detailed theoretical foundation explaining the effectiveness of OcCo.\",\n",
      "        \"verbatim\": \"While the empirical results are strong, the paper might be criticized for not providing a detailed theoretical foundation explaining the effectiveness of OcCo, which could strengthen the paper's claims.\"\n",
      "    },\n",
      "    \"8\": {\n",
      "        \"summary\": \"Could be seen as lacking if it does not include comparisons with the very latest methods.\",\n",
      "        \"verbatim\": \"The rapidly evolving field of point cloud processing may have seen new developments since the submission, and the paper could be seen as lacking if it does not include comparisons with the very latest methods.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"GPT-4 Reviews Summary: \\n\" + gpt_4_reviews_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEW_COMPARISON_RPOMPT = \"\"\"\n",
    "Your task is to carefully analyze and accurately match the key concerns raised in two reviews, \n",
    "ensuring a strong correspondence between the matched points. Examine the verbatim closely.\n",
    "\n",
    "=====Review A: \n",
    "{Review_A}\n",
    "\n",
    "===== \n",
    "\n",
    "=====Review B: \n",
    "{Review_B}\n",
    "\n",
    "===== \n",
    "\n",
    "Please follow the example JSON format below for matching points. For instance, if point from review A is nearly identical to point from review B, it should look like this:\n",
    "{{ \n",
    "    \"A3-B2\": {{\"rationale\": \"<explain why A3 and B2 are nearly identical>\",\"similarity\": \"<5-10, only an integer>\"}},\n",
    "    ...\n",
    "}}\n",
    "\n",
    "**Note that you should only match points with a significant degree of similarity in their concerns. Refrain from matching points with only superficial similarities or weak connections.** For each matched pair, rate the similarity on a scale of 5-10:\n",
    "- 5 Somewhat Related: Points address similar themes but from different angles.\n",
    "- 6 Moderately Related: Points share a common theme but with different perspectives or suggestions.\n",
    "- 7 Strongly Related: Points are largely aligned but differ in some details or nuances.\n",
    "- 8 Very Strongly Related: Points offer similar suggestions or concerns, with slight differences.\n",
    "- 9 Almost Identical: Points are nearly the same, with minor differences in wording or presentation.\n",
    "- 10 Identical: Points are exactly the same in terms of concerns, suggestions, or praises.\n",
    "\n",
    "If no match is found, output an empty JSON object. Provide your output as JSON only.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_reviews(human_reviews: str, gpt_reviews: str) -> str:\n",
    "    \"\"\"\n",
    "    Compares two sets of reviews and identifies matching points between them.\n",
    "\n",
    "    Args:\n",
    "        human_reviews: A string containing the JSON summary of human-written reviews.\n",
    "        gpt_reviews: A string containing the JSON summary of reviews generated by GPT-4.\n",
    "\n",
    "    Returns:\n",
    "        A string representing the JSON-formatted comparison of the reviews.\n",
    "    \"\"\"\n",
    "    prompt = REVIEW_COMPARISON_RPOMPT.format(\n",
    "        Review_A=human_reviews,\n",
    "        Review_B=gpt_reviews\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    response = clean_json_output(completion.choices[0].message.content)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_vs_gpt_35 = compare_reviews(human_reviews_summary, gpt_35_reviews_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human vs. GPT-3.5 Reviews Comparison: \n",
      "{\n",
      "    \"A1-B1\": {\n",
      "        \"rationale\": \"Both points express concerns about the lack of extensive experimental validation and comparative analysis with other methods to demonstrate the effectiveness of the OcCo method. While A1 emphasizes the need for a deeper analysis on the effectiveness of the pre-training mechanism, B1 specifically mentions the need for more detailed comparative analysis and extensive experimental results. The core concern in both cases is the necessity to better establish the effectiveness of the method through comparison and analysis.\",\n",
      "        \"similarity\": \"7\"\n",
      "    },\n",
      "    \"A2-B2\": {\n",
      "        \"rationale\": \"Both points critique the paper for not providing enough experimental validation and lack of comparison with state-of-the-art methods. A2 discusses overselling the novelty and missing details necessary for understanding the experimental results, while B2 emphasizes the need for further experimental validation and comparative analysis with existing state-of-the-art methods to ensure the paper's contribution is adequately substantiated.\",\n",
      "        \"similarity\": \"7\"\n",
      "    },\n",
      "    \"A3-B2\": {\n",
      "        \"rationale\": \"The points from both reviews express concerns regarding the novelty of the paper's contribution and the robustness of the experimental results. A3 directly comments on the perceived weak novelty and experimental results, while B2 suggests that further experimental validation and comparison with state-of-the-art methods could strengthen the paper, implying concerns about the paper's novelty and the reliability of its results.\",\n",
      "        \"similarity\": \"7\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Human vs. GPT-3.5 Reviews Comparison: \\n\" + human_vs_gpt_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human vs. GPT-4 Reviews Comparison: \n",
      "{\n",
      "    \"A1-B1\": {\n",
      "        \"rationale\": \"Both points criticize the lack of detailed theoretical analysis to explain why the OcCo pre-training mechanism improves generalization and performance. While A focuses on the incremental improvements and seeks more in-depth analysis, B emphasizes the absence of a detailed theoretical groundwork that explains the performance improvements.\",\n",
      "        \"similarity\": \"7\"\n",
      "    },\n",
      "    \"A1-B3\": {\n",
      "        \"rationale\": \"Both points share concerns about the lack of theoretical framework or detailed analysis explaining the effectiveness of the OcCo pre-training mechanism. The essence of both criticisms is the need for a deeper understanding or explanation beyond empirical results.\",\n",
      "        \"similarity\": \"8\"\n",
      "    },\n",
      "    \"A1-B5\": {\n",
      "        \"rationale\": \"Both points express a desire for a solid theoretical foundation to explain the effectiveness of the OcCo method. They both highlight a gap in understanding 'why' the method works, despite empirical evidence.\",\n",
      "        \"similarity\": \"9\"\n",
      "    },\n",
      "    \"A1-B7\": {\n",
      "        \"rationale\": \"Both points are focused on the paper's lack of a detailed theoretical foundation explaining why the OcCo approach is effective, stressing the need for theoretical backing to support empirical results.\",\n",
      "        \"similarity\": \"9\"\n",
      "    },\n",
      "    \"A2-B2\": {\n",
      "        \"rationale\": \"These points address the paper's potential oversight in comparing its approach against the most recent or concurrent works in point cloud processing. They both highlight a concern about the novelty and thoroughness of the comparative analysis.\",\n",
      "        \"similarity\": \"8\"\n",
      "    },\n",
      "    \"A2-B4\": {\n",
      "        \"rationale\": \"Both points raise concerns regarding the adequacy of the paper’s comparison with newer or concurrent work in the field, suggesting this as a limitation or an area for improvement.\",\n",
      "        \"similarity\": \"8\"\n",
      "    },\n",
      "    \"A2-B6\": {\n",
      "        \"rationale\": \"Both points critique the paper for potentially not including sufficient comparisons with the most recent or concurrent methods in the field, highlighting a concern with keeping the research up-to-date.\",\n",
      "        \"similarity\": \"8\"\n",
      "    },\n",
      "    \"A2-B8\": {\n",
      "        \"rationale\": \"These points share concerns about the paper's potential lack of comparison with the very latest methods in point cloud processing, suggesting a need to ensure the research is current and comprehensive.\",\n",
      "        \"similarity\": \"8\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "human_vs_gpt_4 = compare_reviews(human_reviews_summary, gpt_4_reviews_summary)\n",
    "print(\"Human vs. GPT-4 Reviews Comparison: \\n\" + human_vs_gpt_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hits(reviews_comparison: str, threshold: int=7) -> int:\n",
    "    \"\"\"\n",
    "    Counts the number of unique high-similarity hits in the reviews comparison.\n",
    "\n",
    "    This function parses a JSON-formatted string of reviews comparison,\n",
    "    checks each item for a similarity score of the threshold or higher.\n",
    "\n",
    "    Args:\n",
    "        reviews_comparison: A string containing the JSON-formatted comparison data.\n",
    "        threshold: An integer representing the minimum similarity score for a hit. Default is 7.\n",
    "\n",
    "    Returns:\n",
    "        The count of unique high-similarity hits based on the specified threshold.\n",
    "    \"\"\"\n",
    "    comparison = json.loads(reviews_comparison)\n",
    "    prefixes = set()\n",
    "    hit_count = 0\n",
    "\n",
    "    for key, value in comparison.items():\n",
    "        similarity = int(value['similarity'])\n",
    "        prefix = key[:2].lower()\n",
    "        if similarity >= threshold and prefix.startswith('a') and prefix not in prefixes:\n",
    "            prefixes.add(prefix)\n",
    "            hit_count += 1\n",
    "\n",
    "    return hit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hits between human and GPT-3.5 reviews: 3\n"
     ]
    }
   ],
   "source": [
    "gpt35_hit = count_hits(human_vs_gpt_35)\n",
    "print(\"Number of hits between human and GPT-3.5 reviews:\", gpt35_hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hits between human and GPT-4 reviews: 2\n"
     ]
    }
   ],
   "source": [
    "gpt4_hit = count_hits(human_vs_gpt_4)\n",
    "print(\"Number of hits between human and GPT-4 reviews:\", gpt4_hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def calculate_hit_rates(title: str, human_reviews: List[str], gpt_reviews: List[str]) -> Tuple[int, float]:\n",
    "    \"\"\"\n",
    "    Calculates the hit rate based on the similarity scores between human and GPT-generated reviews.\n",
    "\n",
    "    The hit rate is the proportion of high-similarity hits in the human reviews when compared\n",
    "    to the GPT-generated reviews, where a \"hit\" is defined by the `count_hits` function logic.\n",
    "\n",
    "    Args:\n",
    "        title: The title of the paper being reviewed.\n",
    "        human_reviews: A list of strings containing human-written review messages.\n",
    "        gpt_reviews: A list of strings containing GPT-generated review messages.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the total number of high-similarity hits and the hit rate.\n",
    "    \"\"\"\n",
    "    human_reviews_summary = summary_reviews(human_reviews, title)\n",
    "    gpt_reviews_summary = summary_reviews(gpt_reviews, title)\n",
    "    comparison = compare_reviews(human_reviews_summary, gpt_reviews_summary)\n",
    "\n",
    "    hit_cnt = count_hits(comparison)\n",
    "    total_human_reviews = len(human_reviews)  # Counting the original reviews instead of the summary\n",
    "\n",
    "    hit_rate = hit_cnt / total_human_reviews if total_human_reviews > 0 else 0\n",
    "\n",
    "    return hit_cnt, hit_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pre-Training by Completing Point Clouds',\n",
       " 'GamePad: A Learning Environment for Theorem Proving',\n",
       " 'Generalisation and the Geometry of Class Separability',\n",
       " 'Using Anomaly Feature Vectors for Detecting, Classifying and Warning of Outlier Adversarial Examples',\n",
       " 'PERIL: Probabilistic Embeddings for hybrid Meta-Reinforcement and Imitation Learning',\n",
       " 'C-Learning: Learning to Achieve Goals via Recursive Classification',\n",
       " 'Unsupervised Learning of Node Embeddings by Detecting Communities']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pre-Training by Completing Point Clouds\n",
      "GPT-3.5 Hit Count: 2, Hit Rate: 0.5\n",
      "GPT-4 Hit Count: 1, Hit Rate: 0.25\n",
      "=====================================\n",
      "Title: GamePad: A Learning Environment for Theorem Proving\n",
      "GPT-3.5 Hit Count: 2, Hit Rate: 0.6666666666666666\n",
      "GPT-4 Hit Count: 1, Hit Rate: 0.3333333333333333\n",
      "=====================================\n",
      "Title: Generalisation and the Geometry of Class Separability\n",
      "GPT-3.5 Hit Count: 1, Hit Rate: 0.5\n",
      "GPT-4 Hit Count: 1, Hit Rate: 0.5\n",
      "=====================================\n",
      "Title: Using Anomaly Feature Vectors for Detecting, Classifying and Warning of Outlier Adversarial Examples\n",
      "GPT-3.5 Hit Count: 0, Hit Rate: 0.0\n",
      "GPT-4 Hit Count: 0, Hit Rate: 0.0\n",
      "=====================================\n",
      "Title: PERIL: Probabilistic Embeddings for hybrid Meta-Reinforcement and Imitation Learning\n",
      "GPT-3.5 Hit Count: 4, Hit Rate: 1.0\n",
      "GPT-4 Hit Count: 2, Hit Rate: 0.5\n",
      "=====================================\n",
      "Title: C-Learning: Learning to Achieve Goals via Recursive Classification\n",
      "GPT-3.5 Hit Count: 0, Hit Rate: 0.0\n",
      "GPT-4 Hit Count: 2, Hit Rate: 0.4\n",
      "=====================================\n",
      "Title: Unsupervised Learning of Node Embeddings by Detecting Communities\n",
      "GPT-3.5 Hit Count: 1, Hit Rate: 0.3333333333333333\n",
      "GPT-4 Hit Count: 1, Hit Rate: 0.3333333333333333\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "eval_result = []\n",
    "\n",
    "for title in titles:\n",
    "    human_reviews = reviews[title]['human_reviews']\n",
    "    gpt_35_reviews = reviews[title]['gpt-3.5-abstract-reviews']\n",
    "    gpt_4_reviews = reviews[title]['gpt-4-full-reviews']\n",
    "\n",
    "    hit_cnt_35, hit_rate_35 = calculate_hit_rates(title, human_reviews, gpt_35_reviews)\n",
    "    hit_cnt_4, hit_rate_4 = calculate_hit_rates(title, human_reviews, gpt_4_reviews)\n",
    "    \n",
    "    eval_result.append({\n",
    "        'title': title,\n",
    "        'hit_cnt_35': hit_cnt_35,\n",
    "        'hit_rate_35': hit_rate_35,\n",
    "        'hit_cnt_4': hit_cnt_4,\n",
    "        'hit_rate_4': hit_rate_4\n",
    "    })\n",
    "\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"GPT-3.5 Hit Count: {hit_cnt_35}, Hit Rate: {hit_rate_35}\")\n",
    "    print(f\"GPT-4 Hit Count: {hit_cnt_4}, Hit Rate: {hit_rate_4}\")\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>hit_cnt_35</th>\n",
       "      <th>hit_rate_35</th>\n",
       "      <th>hit_cnt_4</th>\n",
       "      <th>hit_rate_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GamePad: A Learning Environment for Theorem Pr...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generalisation and the Geometry of Class Separ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Using Anomaly Feature Vectors for Detecting, C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PERIL: Probabilistic Embeddings for hybrid Met...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C-Learning: Learning to Achieve Goals via Recu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Unsupervised Learning of Node Embeddings by De...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  hit_cnt_35  hit_rate_35  \\\n",
       "0            Pre-Training by Completing Point Clouds           2     0.500000   \n",
       "1  GamePad: A Learning Environment for Theorem Pr...           2     0.666667   \n",
       "2  Generalisation and the Geometry of Class Separ...           1     0.500000   \n",
       "3  Using Anomaly Feature Vectors for Detecting, C...           0     0.000000   \n",
       "4  PERIL: Probabilistic Embeddings for hybrid Met...           4     1.000000   \n",
       "5  C-Learning: Learning to Achieve Goals via Recu...           0     0.000000   \n",
       "6  Unsupervised Learning of Node Embeddings by De...           1     0.333333   \n",
       "\n",
       "   hit_cnt_4  hit_rate_4  \n",
       "0          1    0.250000  \n",
       "1          1    0.333333  \n",
       "2          1    0.500000  \n",
       "3          0    0.000000  \n",
       "4          2    0.500000  \n",
       "5          2    0.400000  \n",
       "6          1    0.333333  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result_df = pd.DataFrame(eval_result)\n",
    "eval_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>GPT-4 Abstract Hit Count</th>\n",
       "      <th>GPT-4 Abstract Hit Rate</th>\n",
       "      <th>GPT-4 Full Content Hit Count</th>\n",
       "      <th>GPT-4 Full Content Hit Rate</th>\n",
       "      <th>Number of Human Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pre-Training by Completing Point Clouds</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GamePad: A Learning Environment for Theorem Pr...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generalisation and the Geometry of Class Separ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Using Anomaly Feature Vectors for Detecting, C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PERIL: Probabilistic Embeddings for hybrid Met...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C-Learning: Learning to Achieve Goals via Recu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Unsupervised Learning of Node Embeddings by De...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Paper Title  \\\n",
       "0            Pre-Training by Completing Point Clouds   \n",
       "1  GamePad: A Learning Environment for Theorem Pr...   \n",
       "2  Generalisation and the Geometry of Class Separ...   \n",
       "3  Using Anomaly Feature Vectors for Detecting, C...   \n",
       "4  PERIL: Probabilistic Embeddings for hybrid Met...   \n",
       "5  C-Learning: Learning to Achieve Goals via Recu...   \n",
       "6  Unsupervised Learning of Node Embeddings by De...   \n",
       "\n",
       "   GPT-4 Abstract Hit Count  GPT-4 Abstract Hit Rate  \\\n",
       "0                         2                 0.500000   \n",
       "1                         2                 0.666667   \n",
       "2                         1                 0.500000   \n",
       "3                         0                 0.000000   \n",
       "4                         4                 1.000000   \n",
       "5                         0                 0.000000   \n",
       "6                         1                 0.333333   \n",
       "\n",
       "   GPT-4 Full Content Hit Count  GPT-4 Full Content Hit Rate  \\\n",
       "0                             1                     0.250000   \n",
       "1                             1                     0.333333   \n",
       "2                             1                     0.500000   \n",
       "3                             0                     0.000000   \n",
       "4                             2                     0.500000   \n",
       "5                             2                     0.400000   \n",
       "6                             1                     0.333333   \n",
       "\n",
       "   Number of Human Reviews  \n",
       "0                        4  \n",
       "1                        3  \n",
       "2                        2  \n",
       "3                        1  \n",
       "4                        4  \n",
       "5                        5  \n",
       "6                        3  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result_df['Number of Human Reviews'] = [len(reviews[title]['human_reviews']) for title in titles]\n",
    "eval_result_df['Number of Human Reviews'] = eval_result_df['Number of Human Reviews'].apply(lambda x: int(x) if not pd.isnull(x) else 0)\n",
    "eval_result_df.columns = ['Paper Title', 'GPT-4 Abstract Hit Count', 'GPT-4 Abstract Hit Rate', 'GPT-4 Full Content Hit Count', 'GPT-4 Full Content Hit Rate', 'Number of Human Reviews']\n",
    "eval_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average GPT-4 Abstract Hit Rate: 0.42857142857142855\n",
      "Average GPT-4 Full Content Hit Rate: 0.330952380952381\n"
     ]
    }
   ],
   "source": [
    "print('Average GPT-4 Abstract Hit Rate:', eval_result_df['GPT-4 Abstract Hit Rate'].mean())\n",
    "print('Average GPT-4 Full Content Hit Rate:', eval_result_df['GPT-4 Full Content Hit Rate'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
